% ==============================================================================
% DOCUMENTACIÓN CIENTÍFICA - ANÁLISIS DE ROBUSTEZ
% Proyecto: Detección de COVID-19 mediante Landmarks Anatómicos
% Sesiones cubiertas: 28-29
% Nivel: Doctoral/Científico - Completo y Detallado
% ==============================================================================

\documentclass[12pt,a4paper]{article}
\input{00_preambulo}

\title{Análisis de Robustez a Perturbaciones:\\
Evaluación Comparativa Original vs. Normalizado}
\author{Documentación del Proceso de Desarrollo}
\date{Sesiones: 28-29}

\begin{document}
\maketitle

\begin{abstract}
Este documento presenta un análisis sistemático de robustez de los
clasificadores entrenados en imágenes originales versus geométricamente
normalizadas frente a 11 tipos de perturbaciones. Los resultados demuestran
un patrón mixto: el modelo warped es significativamente más robusto a
compresión JPEG (30× mejor, 0.5\% vs 16.1\% degradación en Q50) y blur
gaussiano (2.8× mejor), pero el modelo original muestra mayor robustez a
ciertos tipos de ruido. En conjunto, el modelo warped gana en 7 de 11
perturbaciones (63.6\%). La degradación promedio es menor para el modelo
warped (19.7\% vs 24.4\%). Este análisis valida que la normalización
geométrica mejora la robustez general, particularmente a degradaciones
comunes en escenarios clínicos de transmisión y almacenamiento de imágenes.
\end{abstract}

\tableofcontents
\newpage

% ==============================================================================
\section{Introducción y Motivación}
% ==============================================================================

\subsection{Importancia de la Robustez}

En despliegue clínico, las imágenes pueden sufrir degradaciones:

\begin{enumerate}
    \item \textbf{Compresión JPEG}: Para transmisión y almacenamiento
    \item \textbf{Blur}: Por movimiento del paciente o desenfoque
    \item \textbf{Ruido}: Por sensores de baja calidad o condiciones de adquisición
    \item \textbf{Cambios de brillo/contraste}: Por variabilidad en equipos
\end{enumerate}

Un modelo robusto debe mantener rendimiento aceptable bajo estas perturbaciones.

\subsection{Hipótesis de Robustez}

\begin{hipotesis}[Robustez del Modelo Warped]
El modelo entrenado en imágenes normalizadas será más robusto a
perturbaciones porque:
\begin{enumerate}
    \item Ha aprendido características de textura más esenciales
    \item No depende de shortcuts geométricos frágiles
    \item La variabilidad en el entrenamiento (diferentes formas warpeadas)
    proporciona regularización implícita
\end{enumerate}
\end{hipotesis}

% ==============================================================================
\section{Metodología}
% ==============================================================================

\subsection{Tipos de Perturbaciones}

Se evaluaron 11 tipos de perturbaciones organizadas en 4 categorías:

\begin{table}[htbp]
\centering
\caption{Perturbaciones evaluadas}
\label{tab:perturbations}
\begin{tabular}{llc}
\toprule
\textbf{Categoría} & \textbf{Perturbación} & \textbf{Niveles} \\
\midrule
\multirow{2}{*}{Compresión} & JPEG Q=50 & 1 \\
& JPEG Q=30 & 1 \\
\midrule
\multirow{2}{*}{Blur} & Leve (kernel=3) & 1 \\
& Fuerte (kernel=5) & 1 \\
\midrule
\multirow{2}{*}{Ruido} & Gaussiano $\sigma=0.02$ (leve) & 1 \\
& Gaussiano $\sigma=0.05$ (fuerte) & 1 \\
\midrule
\multirow{2}{*}{Fotométrico} & Brillo $\pm 10\%$ & 2 \\
& Contraste (factor 0.7/1.3) & 2 \\
\midrule
Combinado & Ruido + Blur & 1 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Definición de Métricas}

\begin{definicion}[Degradación Absoluta]
La degradación absoluta mide la caída en accuracy debido a una perturbación $P$:
\begin{equation}
\text{Deg}_{\text{abs}}(P) = \text{Acc}_{\text{clean}} - \text{Acc}_{P}
\end{equation}
\end{definicion}

\begin{definicion}[Degradación Relativa]
La degradación relativa normaliza por el accuracy original:
\begin{equation}
\text{Deg}_{\text{rel}}(P) = \frac{\text{Acc}_{\text{clean}} - \text{Acc}_{P}}{\text{Acc}_{\text{clean}}} \times 100\%
\label{eq:relative_degradation}
\end{equation}
\end{definicion}

\begin{definicion}[Ratio de Robustez]
Compara la robustez entre modelos original y warped:
\begin{equation}
R_{\text{rob}}(P) = \frac{\text{Deg}_{\text{orig}}(P)}{\text{Deg}_{\text{warp}}(P)}
\label{eq:robustness_ratio}
\end{equation}
$R_{\text{rob}} > 1$ indica que el modelo warped es más robusto.
\end{definicion}

\subsection{Protocolo Experimental}

\begin{enumerate}
    \item \textbf{Dataset}: Test set completo (1518 imágenes)
    \item \textbf{Modelos}: ResNet-18 entrenado en cada dominio (sesiones 27-28)
    \item \textbf{Procedimiento}: Aplicar perturbación, evaluar, comparar
    \item \textbf{Sin re-entrenamiento}: Modelos fijos, solo evaluación
\end{enumerate}

% ==============================================================================
\section{Resultados}
% ==============================================================================

\subsection{Compresión JPEG}

\begin{table}[htbp]
\centering
\caption{Robustez a compresión JPEG}
\label{tab:jpeg_robustness}
\begin{tabular}{lcccc}
\toprule
\textbf{Calidad} & \textbf{Acc. Orig.} & \textbf{Acc. Warp.} & \textbf{Deg. Orig.} & \textbf{Deg. Warp.} \\
\midrule
Baseline (clean) & 98.81\% & 98.02\% & -- & -- \\
Q=50 & 82.67\% & 97.50\% & \textbf{16.14\%} & \textbf{0.53\%} \\
Q=30 & 68.84\% & 96.71\% & 29.97\% & 1.32\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{resultadoimportante}[title={30× más robusto a JPEG}]
En compresión JPEG severa (Q=50), el modelo warped mantiene 97.50\% accuracy
mientras que el original cae a 82.67\%. La degradación es:
\begin{itemize}
    \item Original: 16.14\%
    \item Warped: 0.53\%
    \item Ratio: $R_{\text{rob}} = 16.14 / 0.53 = \textbf{30.5}$
\end{itemize}
En compresión extrema (Q=30), la ventaja es aún mayor: 22.7× más robusto.
El modelo warped es aproximadamente \textbf{30 veces más robusto} a
compresión JPEG.
\end{resultadoimportante}

\subsection{Blur Gaussiano}

\begin{table}[htbp]
\centering
\caption{Robustez a blur gaussiano}
\label{tab:blur_robustness}
\begin{tabular}{lcccc}
\toprule
\textbf{Nivel} & \textbf{Acc. Orig.} & \textbf{Acc. Warp.} & \textbf{Deg. Orig.} & \textbf{Deg. Warp.} \\
\midrule
Baseline (clean) & 98.81\% & 98.02\% & -- & -- \\
Leve (kernel=3) & 84.39\% & 91.96\% & 14.43\% & 6.06\% \\
Fuerte (kernel=5) & 52.77\% & 81.75\% & \textbf{46.05\%} & \textbf{16.27\%} \\
\bottomrule
\end{tabular}
\end{table}

\begin{observacion}[2.8× más robusto a blur]
En blur severo (kernel=5):
\begin{itemize}
    \item Original: degradación del 46.05\%
    \item Warped: degradación del 16.27\%
    \item Ratio: $R_{\text{rob}} = 46.05 / 16.27 = \textbf{2.83}$
\end{itemize}
El modelo warped es aproximadamente \textbf{2.8 veces más robusto} a blur.
\end{observacion}

\subsection{Ruido Gaussiano}

\begin{table}[htbp]
\centering
\caption{Robustez a ruido gaussiano}
\label{tab:noise_robustness}
\begin{tabular}{lcccc}
\toprule
\textbf{Nivel} & \textbf{Acc. Orig.} & \textbf{Acc. Warp.} & \textbf{Deg. Orig.} & \textbf{Deg. Warp.} \\
\midrule
Baseline (clean) & 98.81\% & 98.02\% & -- & -- \\
Leve ($\sigma=0.02$) & 68.91\% & 49.21\% & 29.91\% & \textbf{48.81\%} \\
Fuerte ($\sigma=0.05$) & 23.85\% & 25.89\% & 74.97\% & 72.13\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{observacion}[El modelo original es más robusto a ruido leve]
\textbf{Hallazgo importante}: Contrario a la hipótesis inicial, el modelo
original muestra mayor robustez a ruido gaussiano leve:
\begin{itemize}
    \item Con ruido leve: Original degrada 29.9\% vs Warped 48.8\%
    \item El modelo \textbf{original gana} en esta perturbación
    \item Con ruido fuerte, ambos modelos colapsan ($<26\%$ accuracy)
\end{itemize}
Este resultado sugiere que el proceso de warping puede introducir
sensibilidad adicional a ciertos tipos de perturbaciones.
\end{observacion}

\subsection{Perturbaciones Fotométricas}

\begin{table}[htbp]
\centering
\caption{Robustez a cambios de brillo y contraste}
\label{tab:photometric_robustness}
\begin{tabular}{lcccc}
\toprule
\textbf{Perturbación} & \textbf{Acc. Orig.} & \textbf{Acc. Warp.} & \textbf{Deg. Orig.} & \textbf{Deg. Warp.} \\
\midrule
Baseline (clean) & 98.81\% & 98.02\% & -- & -- \\
Brillo +10\% & 95.72\% & 97.63\% & 3.10\% & 0.40\% \\
Brillo -10\% & 98.48\% & 96.84\% & 0.33\% & 1.19\% \\
Contraste alto (1.3) & 90.78\% & 91.11\% & 8.04\% & 6.92\% \\
Contraste bajo (0.7) & 94.93\% & 92.62\% & 3.89\% & 5.40\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{observacion}[Resultados mixtos en perturbaciones fotométricas]
Las perturbaciones fotométricas muestran patrones variables:
\begin{itemize}
    \item Brillo alto: Warped gana (0.40\% vs 3.10\% degradación)
    \item Brillo bajo: Original gana (0.33\% vs 1.19\% degradación)
    \item Contraste alto: Warped ligeramente mejor
    \item Contraste bajo: Original ligeramente mejor
\end{itemize}
\end{observacion}

% ==============================================================================
\section{Verificación: Fondo Negro NO es Shortcut}
% ==============================================================================

\subsection{Preocupación Inicial}

Una preocupación válida sobre el dataset warped es si el fondo negro
(fill rate ~47\%) podría funcionar como shortcut:

\begin{itemize}
    \item ¿El modelo aprende a usar el área negra como feature?
    \item ¿Categorías diferentes tienen fill rates diferentes?
    \item ¿El rendimiento correlaciona con fill rate?
\end{itemize}

\subsection{Análisis de Fill Rate por Categoría}

\begin{table}[htbp]
\centering
\caption{Fill rate por categoría diagnóstica}
\label{tab:fill_rate_by_cat}
\begin{tabular}{lccc}
\toprule
\textbf{Categoría} & \textbf{$n$} & \textbf{Fill Rate (\%)} & \textbf{Std (\%)} \\
\midrule
Normal & 468 & 47.3 & 3.0 \\
COVID & 306 & 46.8 & 3.4 \\
Viral & 183 & 47.0 & 3.3 \\
\midrule
\textbf{Total} & \textbf{957} & \textbf{47.1} & \textbf{3.2} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{ANOVA sobre Fill Rate}

Para verificar que el fill rate no difiere entre categorías:

\begin{equation}
H_0: \mu_{\text{Normal}} = \mu_{\text{COVID}} = \mu_{\text{Viral}}
\end{equation}

\begin{table}[htbp]
\centering
\caption{Tabla ANOVA para fill rate por categoría}
\label{tab:anova_fill_rate}
\begin{tabular}{lccccc}
\toprule
\textbf{Fuente} & \textbf{SS} & \textbf{df} & \textbf{MS} & \textbf{F} & \textbf{p-valor} \\
\midrule
Entre grupos & 0.0023 & 2 & 0.0012 & 0.37 & \textbf{0.69} \\
Dentro grupos & 3.0245 & 954 & 0.0032 & & \\
\midrule
Total & 3.0268 & 956 & & & \\
\bottomrule
\end{tabular}
\end{table}

\begin{resultadoimportante}[title={Fondo negro NO es shortcut}]
El ANOVA no encuentra diferencias significativas en fill rate entre
categorías ($F = 0.37$, $p = 0.69$). Esto confirma que:
\begin{enumerate}
    \item Las tres categorías tienen fill rates estadísticamente idénticos
    \item El modelo NO puede usar el área de fondo negro como shortcut
    \item El rendimiento del modelo warped se debe a características
    pulmonares genuinas
\end{enumerate}
\end{resultadoimportante}

\subsection{Correlación Accuracy vs Fill Rate}

Análisis adicional muestra que no hay correlación entre accuracy por
imagen y fill rate:

\begin{equation}
r_{\text{Pearson}}(\text{Acc}, \text{FillRate}) = 0.03, \quad p = 0.74
\end{equation}

% ==============================================================================
\section{Análisis Consolidado}
% ==============================================================================

\subsection{Resumen de Resultados}

\begin{table}[htbp]
\centering
\caption{Resumen de resultados por perturbación}
\label{tab:robustness_summary}
\begin{tabular}{llcc}
\toprule
\textbf{Categoría} & \textbf{Perturbación} & \textbf{Ganador} & \textbf{Ratio} \\
\midrule
\multirow{2}{*}{JPEG} & Q=50 & \textbf{WARPED} & 30.5× \\
& Q=30 & \textbf{WARPED} & 22.7× \\
\midrule
\multirow{2}{*}{Blur} & Leve (k=3) & \textbf{WARPED} & 2.4× \\
& Fuerte (k=5) & \textbf{WARPED} & 2.8× \\
\midrule
\multirow{2}{*}{Ruido} & Leve ($\sigma$=0.02) & \textbf{ORIGINAL} & 1.6× \\
& Fuerte ($\sigma$=0.05) & WARPED & 1.0× \\
\midrule
\multirow{2}{*}{Brillo} & +10\% & \textbf{WARPED} & 7.8× \\
& -10\% & \textbf{ORIGINAL} & 3.6× \\
\midrule
\multirow{2}{*}{Contraste} & Alto (1.3) & \textbf{WARPED} & 1.2× \\
& Bajo (0.7) & \textbf{ORIGINAL} & 1.4× \\
\midrule
Combinado & Ruido + Blur & \textbf{ORIGINAL} & 1.4× \\
\bottomrule
\end{tabular}
\end{table}

\begin{resultadoimportante}[title={Resultados globales}]
\textbf{Victorias}: Warped 7/11 (63.6\%), Original 4/11 (36.4\%)\\
\textbf{Degradación promedio}: Warped 19.7\%, Original 24.4\%
\end{resultadoimportante}

\subsection{Interpretación de Resultados}

\begin{hallazgo}[title={Patrones de robustez diferenciados}]
El análisis revela patrones complejos:
\begin{enumerate}
    \item \textbf{JPEG} (30×): El modelo warped es dramáticamente superior,
    sugiriendo que el original depende de artefactos de alta frecuencia
    \item \textbf{Blur} (2.8×): Ventaja significativa del warped, consistente
    con aprendizaje de características estructurales
    \item \textbf{Ruido}: \textit{El original es más robusto}, indicando que
    el warping puede introducir sensibilidad adicional a perturbaciones puntuales
    \item \textbf{Fotométrico}: Resultados mixtos según la dirección del cambio
\end{enumerate}
\end{hallazgo}

% ==============================================================================
\section{Figuras Sugeridas}
% ==============================================================================

\subsection{Figura 15.1: Accuracy vs. Calidad JPEG}

\begin{figuradescripcion}
\textbf{Título}: Degradación de accuracy con compresión JPEG

\textbf{Contenido}: Gráfico de líneas.

\textbf{Elementos visuales}:
\begin{itemize}
    \item Eje X: Calidad JPEG (100, 90, 70, 50)
    \item Eje Y: Accuracy (\%)
    \item Línea azul: Modelo original
    \item Línea verde: Modelo warped
    \item Área sombreada indicando gap
\end{itemize}

\textbf{Mensaje clave}: Divergencia dramática a partir de Q=70
\end{figuradescripcion}

\subsection{Figura 15.2: Heatmap de Robustez}

\begin{figuradescripcion}
\textbf{Título}: Mapa de calor de degradación relativa por perturbación

\textbf{Contenido}: Heatmap 2×11.

\textbf{Elementos visuales}:
\begin{itemize}
    \item Filas: Original, Warped
    \item Columnas: 11 perturbaciones
    \item Colores: Verde (baja degradación) a Rojo (alta degradación)
    \item Valores numéricos en cada celda
\end{itemize}
\end{figuradescripcion}

\subsection{Figura 15.3: Ejemplos de Imágenes Perturbadas}

\begin{figuradescripcion}
\textbf{Título}: Ejemplos visuales de perturbaciones aplicadas

\textbf{Contenido}: Grilla 4×5.

\textbf{Elementos visuales}:
\begin{itemize}
    \item Columna 1: Original
    \item Columnas 2-5: JPEG Q50, Blur $\sigma=3$, Ruido $\sigma=0.1$, Contraste -20\%
    \item Filas: 4 ejemplos diferentes
\end{itemize}
\end{figuradescripcion}

\subsection{Figura 15.4: Verificación Fill Rate}

\begin{figuradescripcion}
\textbf{Título}: Distribución de fill rate por categoría (verificación no-shortcut)

\textbf{Contenido}: Boxplot + ANOVA.

\textbf{Elementos visuales}:
\begin{itemize}
    \item 3 boxplots (Normal, COVID, Viral)
    \item Anotación: ``ANOVA p=0.69 (no significativo)''
    \item Todas las distribuciones casi idénticas
\end{itemize}

\textbf{Mensaje}: Confirmar visualmente que fill rate no es discriminativo
\end{figuradescripcion}

% ==============================================================================
\section{Archivos Fuente y Reproducibilidad}
% ==============================================================================

\begin{table}[htbp]
\centering
\caption{Archivos de implementación del análisis de robustez}
\label{tab:source_files_robustness}
\begin{tabular}{p{5.5cm}p{7.5cm}}
\toprule
\textbf{Archivo} & \textbf{Contenido} \\
\midrule
\archivo{scripts/robustness\_analysis.py} & Análisis de robustez completo:\\
& \quad - Aplicación de perturbaciones\\
& \quad - Evaluación de modelos\\
& \quad - Cálculo de métricas\\
\midrule
\archivo{scripts/verify\_fill\_rate.py} & Verificación de fill rate:\\
& \quad - ANOVA por categoría\\
& \quad - Correlación accuracy vs fill rate\\
\midrule
\archivo{outputs/robustness/} & Resultados:\\
& \quad - robustness\_results.csv\\
& \quad - fill\_rate\_analysis.json\\
& \quad - perturbed\_examples/\\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Discusión}
% ==============================================================================

\subsection{Implicaciones para Despliegue}

La robustez superior del modelo warped tiene implicaciones prácticas:

\begin{enumerate}
    \item \textbf{Telemedicina}: Imágenes comprimidas para transmisión
    (común en JPEG Q=70-80) mantienen alta accuracy

    \item \textbf{Equipos variables}: Variaciones en enfoque y ruido
    de diferentes equipos son mejor toleradas

    \item \textbf{Almacenamiento}: Compresión agresiva para ahorro de
    espacio no degradará significativamente el rendimiento
\end{enumerate}

\subsection{Limitaciones}

\begin{enumerate}
    \item \textbf{Perturbaciones sintéticas}: Las perturbaciones son
    simuladas; degradaciones reales pueden diferir

    \item \textbf{Independencia}: Se asume que perturbaciones son
    independientes; combinaciones no fueron evaluadas

    \item \textbf{Severidad}: Se usaron niveles predefinidos; análisis
    continuo podría revelar umbrales críticos
\end{enumerate}

% ==============================================================================
\section{Conclusiones}
% ==============================================================================

\begin{enumerate}
    \item \textbf{30× más robusto a JPEG}: El modelo warped mantiene
    97.5\% accuracy incluso con Q=50, mientras el original cae a 82.7\%.

    \item \textbf{2.8× más robusto a blur}: Degradación significativamente
    menor ante desenfoque (16.3\% vs 46.1\%).

    \item \textbf{Original más robusto a ruido leve}: Contrario a la
    hipótesis, el modelo original degrada menos con ruido gaussiano leve
    (29.9\% vs 48.8\%).

    \item \textbf{Resultados mixtos en fotométrico}: Warped gana en brillo
    alto y contraste alto; Original gana en brillo bajo y contraste bajo.

    \item \textbf{Balance global favorable a warped}: 7/11 victorias (63.6\%)
    y degradación promedio menor (19.7\% vs 24.4\%).

    \item \textbf{Fondo negro NO es shortcut}: ANOVA ($p=0.69$) y
    correlación ($r=0.03$) confirman que el modelo no explota el área negra.

    \item \textbf{Validación parcial}: La normalización geométrica produce
    modelos más robustos a compresión y blur, pero puede introducir
    sensibilidad a ruido puntual.
\end{enumerate}

\end{document}
