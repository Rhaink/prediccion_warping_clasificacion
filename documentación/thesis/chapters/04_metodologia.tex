% =============================================================================
% CAPITULO 4: METODOLOGIA
% =============================================================================

\chapter{Metodologia}
\label{ch:metodologia}

Este capitulo describe en detalle la metodologia desarrollada para la deteccion de landmarks anatomicos en radiografias de torax. Se presenta la descripcion del dataset, la arquitectura propuesta, el pipeline de preprocesamiento, la estrategia de entrenamiento y las metricas de evaluacion.

% -----------------------------------------------------------------------------
\section{Descripcion del Dataset}
\label{sec:dataset}
% -----------------------------------------------------------------------------

\subsection{Origen y Caracteristicas}

El dataset utilizado en este trabajo consiste en 957 radiografias de torax en proyeccion posteroanterior (PA), provenientes de tres categorias diagnosticas:

\begin{table}[htbp]
    \centering
    \caption{Distribucion del dataset por categoria diagnostica}
    \label{tab:dataset_distribution}
    \begin{tabular}{@{}lccc@{}}
        \toprule
        \textbf{Categoria} & \textbf{Muestras} & \textbf{Porcentaje} & \textbf{Descripcion} \\
        \midrule
        Normal & 468 & 48.9\% & Radiografias sin hallazgos patologicos \\
        COVID-19 & 306 & 32.0\% & Pacientes con PCR positiva \\
        Neumonia Viral & 183 & 19.1\% & Neumonia viral no-COVID \\
        \midrule
        \textbf{Total} & \textbf{957} & \textbf{100\%} & \\
        \bottomrule
    \end{tabular}
\end{table}

Las caracteristicas tecnicas de las imagenes son:
\begin{itemize}
    \item \textbf{Formato}: PNG, escala de grises convertida a RGB
    \item \textbf{Resolucion original}: $299 \times 299$ pixeles
    \item \textbf{Resolucion de entrada al modelo}: $224 \times 224$ pixeles
    \item \textbf{Profundidad de bits}: 8 bits por canal
\end{itemize}

\subsection{Anotaciones de Landmarks}

Cada imagen cuenta con anotaciones de 15 landmarks anatomicos, etiquetados manualmente por expertos. Las coordenadas estan almacenadas en un archivo CSV maestro con el formato:

\begin{lstlisting}[caption={Formato de coordenadas (ejemplo)},label={lst:coords_format}]
nombre_imagen, L1_x, L1_y, L2_x, L2_y, ..., L15_x, L15_y
COVID_001.png, 149, 45, 148, 254, ..., 95, 235
\end{lstlisting}

La \cref{tab:landmarks_descripcion} describe cada landmark anatomico:

\begin{table}[htbp]
    \centering
    \caption{Descripcion de los 15 landmarks anatomicos}
    \label{tab:landmarks_descripcion}
    \begin{tabular}{@{}clp{6cm}@{}}
        \toprule
        \textbf{ID} & \textbf{Nombre} & \textbf{Descripcion Anatomica} \\
        \midrule
        L1 & Superior & Mediastino superior, cerca de la traquea \\
        L2 & Inferior & Mediastino inferior, region vertebral \\
        L3 & Apex Izquierdo & Vertice del pulmon izquierdo \\
        L4 & Apex Derecho & Vertice del pulmon derecho \\
        L5 & Hilio Izquierdo & Region hiliar izquierda \\
        L6 & Hilio Derecho & Region hiliar derecha \\
        L7 & Base Izquierda & Base del pulmon izquierdo \\
        L8 & Base Derecha & Base del pulmon derecho \\
        L9 & Centro Superior & Punto central, 1/4 del eje \\
        L10 & Centro Medio & Punto central, 1/2 del eje \\
        L11 & Centro Inferior & Punto central, 3/4 del eje \\
        L12 & Borde Superior Izq & Borde superior izquierdo \\
        L13 & Borde Superior Der & Borde superior derecho \\
        L14 & Seno Costofrenico Izq & Angulo costofrenico izquierdo \\
        L15 & Seno Costofrenico Der & Angulo costofrenico derecho \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Division de Datos}

El dataset se dividio estratificadamente para mantener las proporciones de cada categoria:

\begin{table}[htbp]
    \centering
    \caption{Division del dataset en conjuntos de entrenamiento, validacion y prueba}
    \label{tab:data_split}
    \begin{tabular}{@{}lcccc@{}}
        \toprule
        \textbf{Conjunto} & \textbf{Total} & \textbf{Normal} & \textbf{COVID-19} & \textbf{Neumonia V.} \\
        \midrule
        Entrenamiento & 717 (74.9\%) & 351 & 229 & 137 \\
        Validacion & 144 (15.0\%) & 70 & 46 & 28 \\
        Prueba & 96 (10.0\%) & 47 & 31 & 18 \\
        \midrule
        \textbf{Total} & \textbf{957} & \textbf{468} & \textbf{306} & \textbf{183} \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{nota}
Se verifico rigurosamente que no existe solapamiento entre conjuntos (data leakage). Ninguna imagen aparece en mas de un conjunto.
\end{nota}

% -----------------------------------------------------------------------------
\section{Analisis Exploratorio de Datos}
\label{sec:eda}
% -----------------------------------------------------------------------------

\subsection{Variabilidad por Landmark}

El analisis de la variabilidad (desviacion estandar) de cada landmark revela diferencias significativas en dificultad:

\begin{table}[htbp]
    \centering
    \caption{Variabilidad de landmarks en el ground truth}
    \label{tab:landmark_variability}
    \begin{tabular}{@{}lccl@{}}
        \toprule
        \textbf{Landmark} & \textbf{$\sigma_x$ (px)} & \textbf{$\sigma_y$ (px)} & \textbf{Dificultad} \\
        \midrule
        L14 (Costofrenico Izq) & 18.7 & 30.2 & Alta \\
        L15 (Costofrenico Der) & 17.9 & 29.5 & Alta \\
        L2 (Inferior) & 15.3 & 27.8 & Alta \\
        L7 (Base Izq) & 24.1 & 17.3 & Media-Alta \\
        L8 (Base Der) & 23.5 & 16.8 & Media-Alta \\
        L3-L6 (Apices, Hilios) & 12-16 & 10-14 & Media \\
        L9 (Centro Superior) & 8.4 & 17.8 & \textbf{Baja} \\
        L10 (Centro Medio) & 9.1 & 18.2 & \textbf{Baja} \\
        L1 (Superior) & 10.2 & 19.1 & Baja \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Observaciones clave}:
\begin{itemize}
    \item Los landmarks centrales (L9, L10, L11) tienen menor variabilidad debido a su posicion sobre el eje mediastinico.
    \item Los senos costofrenicos (L14, L15) son los mas variables, reflejando la diversidad anatomica natural.
    \item La variabilidad en $y$ tiende a ser mayor que en $x$ para landmarks del eje central.
\end{itemize}

\subsection{Descubrimientos Geometricos del Etiquetado}
\label{subsec:geometria}

Un analisis detallado del proceso de etiquetado revelo una estructura geometrica subyacente:

\begin{resultadoclave}
Los landmarks centrales L9, L10, L11 dividen el eje L1-L2 en exactamente 4 partes iguales:
\begin{equation}
    L_i = L_1 + t_i \cdot (L_2 - L_1), \quad t_i \in \{0.25, 0.50, 0.75\}
    \label{eq:eje_parametrico}
\end{equation}
El error de alineacion medido es de solo \textbf{1.34 pixeles}.
\end{resultadoclave}

Esta estructura perfecta se debe al proceso de etiquetado manual:
\begin{enumerate}
    \item Primero se identifican L1 (superior) y L2 (inferior)
    \item Se traza una linea recta entre ellos (eje central)
    \item L9, L10, L11 se colocan automaticamente dividiendo el eje en 4 partes
    \item Los landmarks laterales se marcan desplazandose horizontalmente desde el eje
\end{enumerate}

\subsection{Asimetria en el Ground Truth}

Contraintuitivamente, los pares simetricos en el ground truth no son perfectamente simetricos:

\begin{table}[htbp]
    \centering
    \caption{Asimetria de pares bilaterales en el ground truth}
    \label{tab:asymmetry}
    \begin{tabular}{@{}lcc@{}}
        \toprule
        \textbf{Par} & \textbf{Error X (px)} & \textbf{Diferencia Y (px)} \\
        \midrule
        L3-L4 (Apices) & 4.8 & 7.9 \\
        L5-L6 (Hilios) & 2.9 & 9.0 \\
        L7-L8 (Bases) & 5.1 & 9.7 \\
        L12-L13 (Bordes Sup) & 9.5 & 4.2 \\
        L14-L15 (Costofrenicos) & 8.4 & 10.2 \\
        \midrule
        \textbf{Promedio} & 6.1 & 8.2 \\
        \bottomrule
    \end{tabular}
\end{table}

Esta asimetria refleja la combinacion de anatomia real asimetrica y variabilidad del etiquetado manual. Es crucial \textbf{no forzar simetria perfecta} en el modelo.

% -----------------------------------------------------------------------------
\section{Arquitectura Propuesta}
\label{sec:arquitectura}
% -----------------------------------------------------------------------------

\subsection{Vision General}

La arquitectura propuesta consiste en cuatro componentes principales:

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{model_architecture.png}
    \caption{Arquitectura completa del modelo propuesto. La imagen de entrada pasa por ResNet-18 (backbone), Coordinate Attention, y una cabeza de regresion profunda para producir 30 coordenadas normalizadas.}
    \label{fig:arquitectura_completa}
\end{figure}

\begin{enumerate}
    \item \textbf{Backbone}: ResNet-18 preentrenado en ImageNet
    \item \textbf{Modulo de Atencion}: Coordinate Attention
    \item \textbf{Cabeza de Regresion}: Deep Head con GroupNorm
    \item \textbf{Activacion de Salida}: Sigmoid para normalizar a $[0, 1]$
\end{enumerate}

\subsection{Backbone: ResNet-18}

Se selecciono ResNet-18 como backbone por:

\begin{itemize}
    \item \textbf{Balance precision-eficiencia}: 11.7M parametros, suficiente capacidad sin overfitting
    \item \textbf{Pesos preentrenados}: Aprovecha features aprendidos en ImageNet
    \item \textbf{Conexiones residuales}: Facilitan el flujo de gradiente
    \item \textbf{Amplio soporte}: Implementacion optimizada en PyTorch
\end{itemize}

La capa fully connected final de ResNet-18 se reemplaza por \texttt{nn.Identity()}, extrayendo el vector de features de dimension 512.

\subsection{Coordinate Attention}

El modulo de Coordinate Attention se inserta despues del backbone:

\begin{lstlisting}[caption={Implementacion de Coordinate Attention},label={lst:coord_attn}]
class CoordinateAttention(nn.Module):
    def __init__(self, in_channels, reduction=32):
        super().__init__()
        mip = max(8, in_channels // reduction)

        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))
        self.pool_w = nn.AdaptiveAvgPool2d((1, None))

        self.conv1 = nn.Conv2d(in_channels, mip, 1)
        self.bn1 = nn.BatchNorm2d(mip)
        self.act = nn.Hardswish()

        self.conv_h = nn.Conv2d(mip, in_channels, 1)
        self.conv_w = nn.Conv2d(mip, in_channels, 1)

    def forward(self, x):
        identity = x
        n, c, h, w = x.size()

        # Pooling direccional
        x_h = self.pool_h(x)  # (n, c, h, 1)
        x_w = self.pool_w(x).permute(0, 1, 3, 2)  # (n, c, w, 1)

        # Codificacion conjunta
        y = torch.cat([x_h, x_w], dim=2)
        y = self.conv1(y)
        y = self.bn1(y)
        y = self.act(y)

        # Separacion y generacion de mapas
        x_h, x_w = torch.split(y, [h, w], dim=2)
        x_w = x_w.permute(0, 1, 3, 2)

        a_h = self.conv_h(x_h).sigmoid()
        a_w = self.conv_w(x_w).sigmoid()

        return identity * a_w * a_h
\end{lstlisting}

\subsection{Deep Head con GroupNorm}

La cabeza de regresion utiliza GroupNorm para mayor estabilidad:

\begin{lstlisting}[caption={Cabeza de regresion profunda},label={lst:deep_head}]
self.deep_head = nn.Sequential(
    nn.Linear(512, 768),
    nn.GroupNorm(32, 768),
    nn.ReLU(inplace=True),
    nn.Dropout(0.3),

    nn.Linear(768, 256),
    nn.GroupNorm(16, 256),
    nn.ReLU(inplace=True),
    nn.Dropout(0.3),

    nn.Linear(256, 30),
    nn.Sigmoid()
)
\end{lstlisting}

\textbf{Justificacion de hiperparametros}:
\begin{itemize}
    \item \textbf{hidden\_dim=768}: Determinado experimentalmente como optimo (ver Sesion 9)
    \item \textbf{dropout=0.3}: Balance entre regularizacion y capacidad
    \item \textbf{GroupNorm}: Mas estable que BatchNorm con batch size pequeno
\end{itemize}

\subsection{Resumen de Parametros}

\begin{table}[htbp]
    \centering
    \caption{Parametros del modelo por componente}
    \label{tab:model_params}
    \begin{tabular}{@{}lrr@{}}
        \toprule
        \textbf{Componente} & \textbf{Parametros} & \textbf{Entrenables (Phase 1)} \\
        \midrule
        ResNet-18 Backbone & 11,176,512 & 0 (congelado) \\
        Coordinate Attention & 54,784 & 0 (congelado) \\
        Deep Head & 611,038 & 611,038 \\
        \midrule
        \textbf{Total} & \textbf{11,842,334} & \textbf{611,038} \\
        \bottomrule
    \end{tabular}
\end{table}

% -----------------------------------------------------------------------------
\section{Pipeline de Preprocesamiento}
\label{sec:preprocesamiento_pipeline}
% -----------------------------------------------------------------------------

\subsection{Flujo de Preprocesamiento}

\begin{algorithm}[H]
\caption{Pipeline de Preprocesamiento}
\label{alg:preprocessing}
\begin{algorithmic}[1]
    \Require Imagen $I$ (299$\times$299), Coordenadas $C$ (15$\times$2)
    \Ensure Tensor normalizado $\hat{I}$, Coordenadas normalizadas $\hat{C}$

    \State \textbf{// CLAHE en espacio LAB}
    \State $I_{\text{LAB}} \leftarrow \text{RGB2LAB}(I)$
    \State $I_{\text{LAB}}[:,:,0] \leftarrow \text{CLAHE}(I_{\text{LAB}}[:,:,0], \text{clip}=2.0, \text{tile}=4)$
    \State $I \leftarrow \text{LAB2RGB}(I_{\text{LAB}})$

    \State \textbf{// Normalizacion de coordenadas}
    \State $\hat{C} \leftarrow C / 299$ \Comment{Normalizar a [0, 1]}

    \State \textbf{// Resize}
    \State $I \leftarrow \text{Resize}(I, 224 \times 224)$

    \State \textbf{// Augmentation (solo entrenamiento)}
    \If{training}
        \State $I, \hat{C} \leftarrow \text{RandomHorizontalFlip}(I, \hat{C}, p=0.5)$
        \State $I, \hat{C} \leftarrow \text{RandomRotation}(I, \hat{C}, \pm 10\degree)$
        \State $I \leftarrow \text{ColorJitter}(I, \text{brightness}=0.2, \text{contrast}=0.2)$
    \EndIf

    \State \textbf{// Conversion a tensor y normalizacion ImageNet}
    \State $\hat{I} \leftarrow \text{ToTensor}(I)$
    \State $\hat{I} \leftarrow \text{Normalize}(\hat{I}, \mu_{\text{ImageNet}}, \sigma_{\text{ImageNet}})$

    \State \Return $\hat{I}$, $\hat{C}$
\end{algorithmic}
\end{algorithm}

\subsection{CLAHE: Parametros Optimizados}

Los parametros de CLAHE fueron optimizados experimentalmente:

\begin{table}[htbp]
    \centering
    \caption{Comparacion de configuraciones CLAHE}
    \label{tab:clahe_params}
    \begin{tabular}{@{}cccc@{}}
        \toprule
        \textbf{clip\_limit} & \textbf{tile\_size} & \textbf{Error (px)} & \textbf{Observacion} \\
        \midrule
        Sin CLAHE & - & 8.93 & Baseline \\
        2.0 & 8 & 8.18 & Mejora general \\
        2.0 & 16 & 8.82 & Tiles muy grandes \\
        1.5 & 4 & 8.12 & Bueno \\
        \textbf{2.0} & \textbf{4} & \textbf{7.84} & \textbf{Optimo} \\
        3.0 & 4 & 8.23 & Demasiado contraste \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Insight clave}: Tiles mas pequenos (4) proporcionan mejor realce local de bordes, crucial para detectar landmarks en zonas con consolidaciones pulmonares.

\subsection{Data Augmentation con Landmarks}

El flip horizontal requiere manejo especial de landmarks simetricos:

\begin{lstlisting}[caption={Flip horizontal con intercambio de pares},label={lst:flip}]
SYMMETRIC_PAIRS = [(2, 3), (4, 5), (6, 7), (11, 12), (13, 14)]

def flip_horizontal(image, landmarks):
    # Flip imagen
    image = torch.flip(image, dims=[2])

    # Invertir coordenada X
    landmarks = landmarks.clone()
    landmarks[:, 0] = 1.0 - landmarks[:, 0]

    # Intercambiar pares simetricos
    for left, right in SYMMETRIC_PAIRS:
        landmarks[[left, right]] = landmarks[[right, left]].clone()

    return image, landmarks
\end{lstlisting}

% -----------------------------------------------------------------------------
\section{Funcion de Perdida}
\label{sec:loss_function}
% -----------------------------------------------------------------------------

\subsection{Wing Loss Normalizada}

Se utiliza Wing Loss adaptada para coordenadas normalizadas:

\begin{equation}
    \mathcal{L}_{\text{wing}}(x) = \begin{cases}
        \omega' \ln(1 + |x|/\epsilon') & \text{si } |x| < \omega' \\
        |x| - C' & \text{en otro caso}
    \end{cases}
    \label{eq:wing_normalized}
\end{equation}

donde $\omega' = 10/224 \approx 0.0446$ y $\epsilon' = 2/224 \approx 0.0089$.

\begin{lstlisting}[caption={Implementacion de Wing Loss normalizada},label={lst:wing_loss}]
class WingLoss(nn.Module):
    def __init__(self, omega=10, epsilon=2, normalized=True):
        super().__init__()
        scale = 224.0 if normalized else 1.0
        self.omega = omega / scale
        self.epsilon = epsilon / scale
        self.C = self.omega - self.omega * math.log(1 + self.omega / self.epsilon)

    def forward(self, pred, target):
        diff = torch.abs(pred - target)
        loss = torch.where(
            diff < self.omega,
            self.omega * torch.log(1 + diff / self.epsilon),
            diff - self.C
        )
        return loss.mean()
\end{lstlisting}

\subsection{Comparacion con Alternativas}

Se evaluaron otras funciones de perdida durante el desarrollo:

\begin{table}[htbp]
    \centering
    \caption{Comparacion de funciones de perdida}
    \label{tab:loss_comparison}
    \begin{tabular}{@{}lcc@{}}
        \toprule
        \textbf{Loss Function} & \textbf{Error Test (px)} & \textbf{Observacion} \\
        \midrule
        MSE & 11.34 & Baseline, sensible a outliers \\
        Smooth L1 & 10.45 & Mejor que MSE \\
        \textbf{Wing Loss} & \textbf{9.08} & \textbf{Mejor resultado} \\
        Combined Loss* & 10.52 & Geometria no ayuda \\
        \bottomrule
    \end{tabular}
    \begin{tablenotes}
        \small
        \item * Combined Loss = Wing + Central Alignment + Soft Symmetry
    \end{tablenotes}
\end{table}

% -----------------------------------------------------------------------------
\section{Estrategia de Entrenamiento}
\label{sec:entrenamiento}
% -----------------------------------------------------------------------------

\subsection{Entrenamiento en Dos Fases}

El entrenamiento sigue un esquema de dos fases:

\begin{table}[htbp]
    \centering
    \caption{Configuracion del entrenamiento por fase}
    \label{tab:training_phases}
    \begin{tabular}{@{}lcc@{}}
        \toprule
        \textbf{Parametro} & \textbf{Fase 1} & \textbf{Fase 2} \\
        \midrule
        Epocas & 15 & 100 \\
        Backbone & Congelado & Descongelado \\
        LR Backbone & N/A & $2 \times 10^{-5}$ \\
        LR Head & $1 \times 10^{-3}$ & $2 \times 10^{-4}$ \\
        Batch Size & 16 & 8 \\
        Scheduler & StepLR & CosineAnnealing \\
        Early Stopping & 5 epocas & 15 epocas \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Justificacion}:
\begin{itemize}
    \item \textbf{Fase 1}: Inicializa la cabeza sin destruir features preentrenados
    \item \textbf{Fase 2}: Fine-tuning con LR diferenciado permite ajuste fino del backbone
    \item \textbf{Batch size menor en Fase 2}: Mejora estabilidad del fine-tuning
\end{itemize}

\subsection{Optimizador}

Se utiliza Adam con grupos de parametros:

\begin{lstlisting}[caption={Configuracion del optimizador},label={lst:optimizer}]
optimizer = torch.optim.Adam([
    {'params': backbone_params, 'lr': 2e-5},
    {'params': attention_params, 'lr': 2e-5},
    {'params': head_params, 'lr': 2e-4}
])

scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer, T_max=100, eta_min=1e-6
)
\end{lstlisting}

\subsection{Early Stopping}

Se implementa early stopping basado en el error de validacion en pixeles:

\begin{lstlisting}[caption={Early Stopping callback},label={lst:early_stopping}]
class EarlyStopping:
    def __init__(self, patience=15, min_delta=0.01):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = float('inf')

    def __call__(self, val_error):
        if val_error < self.best_score - self.min_delta:
            self.best_score = val_error
            self.counter = 0
            return False  # Continuar
        else:
            self.counter += 1
            return self.counter >= self.patience  # Detener
\end{lstlisting}

% -----------------------------------------------------------------------------
\section{Ensemble de Modelos}
\label{sec:ensemble_metodologia}
% -----------------------------------------------------------------------------

\subsection{Estrategia de Diversificacion}

Se entrenan 4 modelos con la misma arquitectura pero diferentes seeds de inicializacion:

\begin{table}[htbp]
    \centering
    \caption{Modelos del ensemble final}
    \label{tab:ensemble_models}
    \begin{tabular}{@{}lccc@{}}
        \toprule
        \textbf{Modelo} & \textbf{Seed} & \textbf{Error Individual} & \textbf{En Ensemble} \\
        \midrule
        Modelo A & 42 & 6.75 px & No* \\
        Modelo B & 123 & 4.05 px & Si \\
        Modelo C & 456 & 4.04 px & Si \\
        Modelo D & 321 & 4.23 px & Si \\
        Modelo E & 789 & 4.37 px & Si \\
        \bottomrule
    \end{tabular}
    \begin{tablenotes}
        \small
        \item * Excluido por rendimiento significativamente inferior
    \end{tablenotes}
\end{table}

\subsection{Metodo de Agregacion}

Las predicciones se combinan mediante promedio simple:

\begin{equation}
    \hat{y}_{\text{ensemble}} = \frac{1}{M} \sum_{m=1}^{M} f_m(x)
    \label{eq:ensemble_avg}
\end{equation}

\begin{nota}
Se probaron esquemas de ponderacion (pesos inversamente proporcionales al error de validacion), pero no mejoraron sobre el promedio simple. La clave fue excluir modelos de bajo rendimiento.
\end{nota}

% -----------------------------------------------------------------------------
\section{Test-Time Augmentation}
\label{sec:tta_metodologia}
% -----------------------------------------------------------------------------

Durante la inferencia, se aplica \TTA con flip horizontal:

\begin{algorithm}[H]
\caption{Inferencia con TTA y Ensemble}
\label{alg:inference_tta}
\begin{algorithmic}[1]
    \Require Imagen $I$, Modelos $\{f_1, ..., f_M\}$
    \Ensure Prediccion final $\hat{L}$

    \State $\text{predictions} \leftarrow []$
    \For{$m = 1$ to $M$}
        \State \textbf{// Prediccion original}
        \State $p_1 \leftarrow f_m(I)$
        \State $\text{predictions}.\text{append}(p_1)$

        \State \textbf{// Prediccion con flip}
        \State $I_{\text{flip}} \leftarrow \text{HorizontalFlip}(I)$
        \State $p_2 \leftarrow f_m(I_{\text{flip}})$
        \State $p_2 \leftarrow \text{InverseFlipLandmarks}(p_2)$
        \State $\text{predictions}.\text{append}(p_2)$
    \EndFor

    \State $\hat{L} \leftarrow \text{mean}(\text{predictions})$ \Comment{4 modelos $\times$ 2 = 8 predicciones}
    \State \Return $\hat{L}$
\end{algorithmic}
\end{algorithm}

% -----------------------------------------------------------------------------
\section{Metricas de Evaluacion}
\label{sec:metricas_metodologia}
% -----------------------------------------------------------------------------

\subsection{Metrica Principal: Error Euclidiano}

El error se calcula como la distancia euclidiana entre prediccion y ground truth:

\begin{equation}
    e_i = \sqrt{(\hat{x}_i - x_i)^2 + (\hat{y}_i - y_i)^2} \times 224
    \label{eq:error_px}
\end{equation}

donde el factor 224 convierte de coordenadas normalizadas a pixeles.

\subsection{Metricas Reportadas}

Para cada experimento se reportan:

\begin{itemize}
    \item \textbf{Error medio}: $\bar{e} = \frac{1}{N \times K} \sum_{n,k} e_{n,k}$
    \item \textbf{Desviacion estandar}: $\sigma_e$
    \item \textbf{Mediana}: $\tilde{e}$
    \item \textbf{Percentiles}: $P_{90}$, $P_{95}$
    \item \textbf{Error por landmark}: $\bar{e}_k$ para $k = 1, ..., 15$
    \item \textbf{Error por categoria}: $\bar{e}_c$ para $c \in \{\text{Normal}, \text{COVID}, \text{Viral}\}$
\end{itemize}

% -----------------------------------------------------------------------------
\section{Implementacion Tecnica}
\label{sec:implementacion}
% -----------------------------------------------------------------------------

\subsection{Hardware}

\begin{table}[htbp]
    \centering
    \caption{Especificaciones de hardware}
    \label{tab:hardware}
    \begin{tabular}{@{}ll@{}}
        \toprule
        \textbf{Componente} & \textbf{Especificacion} \\
        \midrule
        GPU & AMD Radeon RX 6600 (8 GB VRAM) \\
        Framework & PyTorch 2.0+ con ROCm \\
        CPU & AMD Ryzen (detalles omitidos) \\
        RAM & 32 GB DDR4 \\
        Almacenamiento & SSD NVMe \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Dependencias Principales}

\begin{lstlisting}[caption={Dependencias del proyecto},label={lst:dependencies},language={}]
torch>=2.0.0
torchvision>=0.15.0
numpy>=1.24.0
opencv-python>=4.8.0
Pillow>=10.0.0
matplotlib>=3.7.0
pandas>=2.0.0
tqdm>=4.65.0
\end{lstlisting}

\subsection{Tiempo de Entrenamiento}

\begin{table}[htbp]
    \centering
    \caption{Tiempos de entrenamiento}
    \label{tab:training_times}
    \begin{tabular}{@{}lcc@{}}
        \toprule
        \textbf{Fase} & \textbf{Epocas} & \textbf{Tiempo} \\
        \midrule
        Fase 1 (backbone congelado) & 15 & $\sim$10 min \\
        Fase 2 (fine-tuning) & 100 & $\sim$2 horas \\
        \midrule
        \textbf{Total por modelo} & 115 & $\sim$2.2 horas \\
        \textbf{Ensemble (4 modelos)} & 460 & $\sim$9 horas \\
        \bottomrule
    \end{tabular}
\end{table}

% -----------------------------------------------------------------------------
\section{Estructura del Proyecto}
\label{sec:estructura_proyecto}
% -----------------------------------------------------------------------------

\begin{lstlisting}[caption={Estructura de directorios del proyecto},label={lst:project_structure},language={}]
prediccion_coordenadas/
|-- data/
|   |-- coordenadas/coordenadas_maestro.csv
|   |-- COVID/
|   |-- Normal/
|   |-- Viral_Pneumonia/
|
|-- src_v2/
|   |-- data/
|   |   |-- dataset.py          # LandmarkDataset
|   |   |-- transforms.py       # Augmentations, CLAHE
|   |-- models/
|   |   |-- resnet_landmark.py  # Arquitectura
|   |   |-- losses.py           # Wing Loss
|   |-- training/
|   |   |-- trainer.py          # LandmarkTrainer
|   |   |-- callbacks.py        # EarlyStopping
|   |-- evaluation/
|       |-- metrics.py          # Metricas, TTA
|
|-- scripts/
|   |-- train.py                # Entrenamiento
|   |-- predict.py              # Inferencia
|   |-- evaluate_ensemble.py    # Evaluacion
|
|-- checkpoints/                # Modelos guardados
|-- configs/                    # Configuraciones
|-- outputs/                    # Resultados
\end{lstlisting}

% -----------------------------------------------------------------------------
% FIN DEL CAPITULO
% -----------------------------------------------------------------------------
