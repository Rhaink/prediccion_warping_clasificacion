\section{Estado del Arte en Detección Automática de Landmarks Anatómicos}

La detección automática de \textit{landmarks} anatómicos en imágenes médicas ha experimentado una transformación fundamental en la última década. Los métodos clásicos basados en modelos estadísticos de forma, particularmente Active Shape Models (ASM) \cite{Cootes1995} y Active Appearance Models (AAM) \cite{Cootes2001}, dominaron el campo durante los años 1990-2000, requiriendo inicialización manual cercana a la solución y siendo sensibles a variaciones de iluminación y pose. La revolución del aprendizaje profundo, iniciada con AlexNet \cite{Krizhevsky2012}, transformó radicalmente el panorama: Sun et al.~\cite{Sun2013} demostraron en 2013 que redes neuronales convolucionales profundas superaban métodos clásicos en detección de \textit{landmarks} faciales mediante una cascada de redes con refinamiento progresivo. La introducción de arquitecturas residuales profundas \cite{He2016} y técnicas avanzadas de regresión de mapas de calor \cite{Tompson2014, Newell2016} consolidaron el aprendizaje profundo como el paradigma dominante. En el dominio de imágenes médicas, tres enfoques metodológicos principales han emergido: (1) regresión directa de coordenadas, que predice localizaciones $(x, y)$ como valores continuos con eficiencia computacional superior; (2) regresión de mapas de calor, que genera distribuciones de probabilidad espacial con capacidad de representar incertidumbre; y (3) métodos híbridos y basados en transformadores, que combinan fortalezas de múltiples paradigmas o explotan mecanismos de atención global. Simultáneamente, la disponibilidad de conjuntos de datos ha evolucionado desde colecciones pequeñas de cientos de imágenes hacia repositorios masivos como CheXpert (224,316 radiografías de tórax) y MIMIC-CXR (377,110 estudios), facilitando el entrenamiento de modelos cada vez más robustos y generalizables. Esta sección presenta una revisión exhaustiva del estado del arte, organizada según el enfoque metodológico principal, seguida de un análisis comparativo de los trabajos más relevantes publicados entre 2016 y 2024.

\subsection{Métodos Basados en Regresión de Coordenadas}

El enfoque de regresión directa de coordenadas formula la detección de \textit{landmarks} como un problema de regresión multi-salida donde redes neuronales convolucionales profundas aprenden mapeos directos desde imágenes hacia vectores de coordenadas. Sun et al.~\cite{Sun2013} propusieron una arquitectura pionera denominada Deep Convolutional Network Cascade para \textit{landmarks} faciales, consistente en tres niveles de refinamiento progresivo: una red inicial predice localizaciones aproximadas en la imagen completa, seguida de redes subsecuentes que refinan las predicciones en regiones locales de tamaño decreciente. Esta estrategia de \textit{coarse-to-fine} alcanzó un error normalizado de 5.5\% en el conjunto de datos LFPW, superando métodos clásicos basados en AAM por márgenes significativos. Zhang et al.~\cite{Zhang2014} extendieron este enfoque mediante aprendizaje multi-tarea, demostrando que la predicción simultánea de \textit{landmarks} faciales y atributos semánticos (presencia de gafas, género, expresión) mejora la precisión de localización: las tareas auxiliares actúan como regularizadores que fuerzan a la red a aprender representaciones más generalizables. Bulat y Tzimiropoulos~\cite{Bulat2017} establecieron \textit{benchmarks} de referencia mediante la construcción de un conjunto de datos masivo de 230,000 \textit{landmarks} faciales 3D, alcanzando un error promedio de 3.12 píxeles en el conjunto 300-W, y demostraron la importancia de la escala de datos de entrenamiento para la robustez de los modelos. Una observación consistente en la literatura es que la regresión de coordenadas ha sido preferida en aplicaciones de imágenes médicas debido a su eficiencia computacional y capacidad de predicción sub-píxel inherente.

En el dominio específico de imágenes médicas, Noothout et al.~\cite{Noothout2020} presentaron en \textit{IEEE Transactions on Medical Imaging} un enfoque de localización global-a-local utilizando redes neuronales completamente convolucionales (FCNNs) para la detección de 19 \textit{landmarks} cefalométricos en radiografías laterales de cráneo. Su método opera en dos etapas: una red de localización gruesa identifica regiones de interés que contienen cada \textit{landmark}, seguida de una red de refinamiento que predice coordenadas precisas dentro de parches locales. Evaluado en un conjunto de datos de 400 radiografías, el método alcanzó un error de $1.21 \pm 0.89$ mm, demostrando además transferibilidad entre modalidades de imagen (angiografía por tomografía computarizada, resonancia magnética, y radiografía). Oh et al.~\cite{Oh2020} propusieron en \textit{IEEE Journal of Biomedical and Health Informatics} un enfoque de aprendizaje de características de contexto anatómico profundo para \textit{landmarks} cefalométricos, incorporando mecanismos de atención guiados por contexto que permiten a la red enfocarse en regiones anatómicas relevantes. Su arquitectura basada en DenseNet alcanzó un error de 1.18 mm en un conjunto de datos de 935 radiografías laterales, representando el estado del arte en detección cefalométrica mediante regresión de coordenadas al momento de publicación. Li et al.~\cite{Li2023} presentaron en \textit{Scientific Reports} un enfoque híbrido que combina regresión de coordenadas y mapas de calor para 46 \textit{landmarks} en radiografías de tórax posteroanterior, utilizando un conjunto de datos de 956 imágenes. Su método incorpora restricciones de simetría bilateral en la función de pérdida, explotando la propiedad anatómica de simetría del tórax, y alcanzó un error promedio de 4.22 píxeles. Este trabajo representa la aplicación más exhaustiva de detección de \textit{landmarks} en radiografías de tórax en términos de número de puntos anatómicos, demostrando que la combinación de restricciones geométricas con regresión eficiente es viable en conjuntos de datos de tamaño moderado.

\subsection{Métodos Basados en Mapas de Calor}

La regresión de mapas de calor representa cada \textit{landmark} mediante una distribución de probabilidad espacial bidimensional, típicamente una Gaussiana centrada en la localización objetivo. Tompson et al.~\cite{Tompson2014} fueron pioneros en la aplicación de este enfoque para estimación de pose humana, combinando redes neuronales convolucionales con modelos gráficos que capturan dependencias espaciales entre articulaciones. Su método genera mapas de calor Gaussianos con desviación estándar $\sigma = 1$ píxel para cada articulación, optimizados mediante error cuadrático medio píxel-a-píxel. Newell et al.~\cite{Newell2016} revolucionaron el campo con la introducción de \textit{Stacked Hourglass Networks}, una arquitectura multi-escala iterativa que procesa características en múltiples resoluciones mediante módulos codificador-decodificador apilados secuencialmente. Cada módulo \textit{hourglass} realiza \textit{downsampling} progresivo para capturar contexto global, seguido de \textit{upsampling} simétrico con conexiones de salto que preservan detalles espaciales. La composición de múltiples módulos (típicamente 4-8) permite refinamiento iterativo de predicciones, alcanzando PCKh@0.5 = 90.9\% en el conjunto de datos MPII Human Pose, estableciendo un nuevo estado del arte que persiste como referencia fundamental. Yang et al.~\cite{Yang2017} demostraron la transferibilidad de la arquitectura \textit{Stacked Hourglass} desde estimación de pose humana hacia detección de \textit{landmarks} faciales, evidenciando que las representaciones jerárquicas multi-escala son genéricas a través de dominios anatómicos.

En aplicaciones de imágenes médicas, Payer et al.~\cite{Payer2019Spatial} presentaron en \textit{Medical Image Analysis} una extensión de regresión de mapas de calor que integra redes de configuración espacial (\textit{spatial configuration networks}) para \textit{landmarks} en radiografías de mano. Su método incorpora un mecanismo de \textit{soft-argmax} diferenciable que permite extracción de coordenadas sub-píxel a partir de mapas de calor mientras mantiene diferenciabilidad completa para entrenamiento de extremo a extremo: $\hat{x}_k = \sum_{i,j} j \cdot \text{softmax}(H_k(i,j))$, $\hat{y}_k = \sum_{i,j} i \cdot \text{softmax}(H_k(i,j))$. La arquitectura basada en U-Net alcanzó un error de $1.87 \pm 0.98$ mm en un conjunto de datos de 895 imágenes, demostrando que la preservación de información espacial explícita proporciona ventajas en presencia de estructuras anatómicas complejas con múltiples \textit{landmarks} densamente distribuidos. Zhang et al.~\cite{Zhang2020MIA} propusieron en \textit{Medical Image Analysis} redes neuronales convolucionales en cascada con arquitectura U-Net para 19 \textit{landmarks} cefalométricos, implementando una estrategia de tres etapas de refinamiento progresivo de \textit{coarse-to-fine}. Su método alcanzó un error de $1.35 \pm 0.89$ mm en un conjunto de datos de 1,000 radiografías laterales, superando métodos clásicos basados en ASM por 42\% y demostrando la superioridad de enfoques basados en aprendizaje profundo sobre técnicas estadísticas tradicionales. Cheng et al.~\cite{Cheng2023} presentaron en \textit{Medical Image Analysis} un enfoque de aprendizaje basado en perturbaciones con regresión de mapas de calor para 18 \textit{landmarks} en radiografías de tórax posteroanterior. Su método incorpora aumentación de datos geométrica avanzada mediante perturbaciones controladas durante el entrenamiento, alcanzando un error de 3.78 píxeles en un conjunto de datos de 2,000 imágenes. Thaler et al.~\cite{Thaler2021} introdujeron modelado de incertidumbre mediante mapas de calor Gaussianos con enfoque Bayesiano para radiografías de mano, cuantificando explícitamente la incertidumbre de localización para cada \textit{landmark} y alcanzando un error de 2.12 mm. Una limitación consistente de métodos basados en mapas de calor es el sobrecosto de memoria proporcional a $K \times h \times w$ (número de \textit{landmarks} × resolución espacial), significativamente superior al vector compacto de $2K$ valores de regresión de coordenadas, con impacto directo en el tamaño de lote durante el entrenamiento y velocidad de inferencia.

\subsection{Métodos Híbridos y Basados en Transformers}

La tercera categoría de enfoques combina elementos de regresión de coordenadas y mapas de calor, o introduce arquitecturas basadas en mecanismos de atención que superan limitaciones de receptive fields finitos en redes convolucionales. Quan et al.~\cite{YOLO2021} presentaron en MICCAI 2021 el enfoque ``You Only Learn Once'' (YOLO), un detector universal de \textit{landmarks} anatómicos entrenado simultáneamente en conjuntos de datos mixtos (cefalométricos, mano, columna vertebral) conteniendo más de 150 \textit{landmarks} diferentes distribuidos en múltiples anatomías. El método demuestra capacidad de generalización cruzada entre anatomías, alcanzando errores variables de 1.5-3.2 mm según la región anatómica específica, y evidencia que el entrenamiento multi-dominio mejora la robustez mediante exposición a diversidad anatómica. Ma y Luo~\cite{AdaptiveLoss2021} propusieron en \textit{IEEE Journal of Biomedical and Health Informatics} una función de pérdida adaptativa de grano fino que ajusta dinámicamente los pesos de cada \textit{landmark} según su dificultad de detección empírica durante el entrenamiento. Su función de pérdida se formula como $\mathcal{L} = \sum_{k=1}^K \alpha_k \cdot \text{MSE}_k$, donde los pesos $\alpha_k$ se aprenden mediante un módulo de atención que evalúa la magnitud de gradientes históricos. Aplicado a 19 \textit{landmarks} cefalométricos, este enfoque proporciona mejoras de 8.3\% sobre MSE estándar, demostrando que la adaptación dinámica de la función de pérdida es una dirección prometedora. Kang et al.~\cite{Kang2021} presentaron en \textit{Scientific Reports} detección de \textit{landmarks} cefalométricos 3D mediante aprendizaje por refuerzo profundo multi-etapa en imágenes CBCT (tomografía computarizada de haz cónico), formulando la localización como un proceso de decisión de Markov donde un agente aprende secuencias de acciones que minimizan la distancia al \textit{landmark} objetivo. Su enfoque alcanzó un error de $1.82 \pm 1.03$ mm en espacio tridimensional con un conjunto de datos de 350 exploraciones volumétricas.

La introducción de arquitecturas \textit{Vision Transformer} ha generado interés significativo en años recientes. Li et al.~\cite{Li2022CVPR} propusieron en CVPR 2022 una arquitectura de transformadores en cascada para \textit{landmarks} faciales, donde mecanismos de \textit{self-attention} global capturan relaciones espaciales de largo alcance entre \textit{landmarks} sin las limitaciones de campos receptivos finitos inherentes a convoluciones. Su método alcanzó NME (error medio normalizado) de 2.98\% en el conjunto de datos WFLW con 98 \textit{landmarks} faciales, demostrando competitividad con enfoques convolucionales mientras proporciona interpretabilidad superior mediante visualización de mapas de atención. Huang et al.~\cite{Huang2023} presentaron en MICCAI 2023 un modelo híbrido Transformer-CNN (HTC) con aprendizaje de mapas de calor multi-resolución, combinando extracción de características locales mediante bloques convolucionales con modelado de contexto global mediante bloques de transformador. Su arquitectura superó una línea base ResNet-50 por 11.2\% en \textit{landmarks} de radiografías de tórax, evidenciando que la hibridación de arquitecturas convolucionales y basadas en atención explota complementariedad: convoluciones capturan patrones locales eficientemente mediante inductive bias de localidad, mientras transformadores modelan dependencias globales sin restricciones espaciales. Jeong et al.~\cite{Jeong2023} presentaron en \textit{Sensors} regresión de coordenadas guiada por atención con características de mapas de calor intermedias para \textit{landmarks} faciales, alcanzando un error de 5.13 píxeles en radiografías de tórax mediante un mecanismo híbrido que genera mapas de calor en capas intermedias para guiar la regresión final de coordenadas.

Gaggion et al.~\cite{Gaggion2023} introdujeron en \textit{IEEE Transactions on Medical Imaging} HybridGNet, una arquitectura basada en redes neuronales de grafo (Graph Neural Networks, GNN) que incorpora conocimiento anatómico previo en segmentación de radiografías de tórax mediante representación de \textit{landmarks} como nodos de un grafo donde las aristas representan relaciones anatómicas (adyacencia espacial, simetría bilateral, jerarquía anatómica). Su método mejora la plausibilidad anatómica de segmentaciones en 15.6\% comparado con U-Net estándar, demostrando que la codificación explícita de estructura anatómica mediante grafos constituye una dirección prometedora. Liu et al.~\cite{Liu2021Structure} propusieron en CVPR 2021 detección de \textit{landmarks} con conciencia de estructura mediante GCN para capturar relaciones espaciales explícitas entre \textit{landmarks} faciales, modelando las dependencias geométricas como un grafo totalmente conectado donde cada \textit{landmark} se conecta con todos los demás, permitiendo propagación de información contextual. La tendencia emergente hacia integración de conocimiento previo geométrico mediante representaciones de grafo representa una convergencia entre aprendizaje profundo basado en datos y modelado estructurado tradicional.

\subsection{Funciones de Pérdida Especializadas y Restricciones Geométricas}

La función de pérdida constituye un componente crítico que determina qué propiedades de las predicciones son optimizadas durante el entrenamiento. Feng et al.~\cite{Feng2018} introdujeron en CVPR 2018 la función \textit{Wing Loss} para localización robusta de \textit{landmarks} faciales, diseñada para amplificar gradientes en el régimen de errores pequeños mediante una curva basada en logaritmo: $\mathcal{L}_{\text{wing}}(x) = w \ln(1 + |x|/\epsilon)$ para $|x| < w$, donde $w$ controla el ancho de la región no lineal y $\epsilon$ limita el gradiente en $x=0$. Con parámetros típicos $w=10$, $\epsilon=2$, \textit{Wing Loss} proporciona mejoras de 12.5\% sobre MSE en \textit{landmarks} faciales con errores menores a 2 píxeles, alcanzando NME 4.04\% en el conjunto 300-W. La intuición fundamental es que MSE cuadrático genera gradientes que decrecen linealmente con el error, proporcionando señal de optimización débil en el régimen de alta precisión, mientras \textit{Wing Loss} mantiene gradientes substanciales incluso para errores muy pequeños, acelerando la convergencia hacia localizaciones precisas. Wang et al.~\cite{Wang2019} extendieron este concepto con \textit{Adaptive Wing Loss} que ajusta dinámicamente los parámetros $w$ y $\epsilon$ durante el entrenamiento, aplicado a regresión de mapas de calor, proporcionando mejoras adicionales de 5.3\% sobre \textit{Wing Loss} estándar. Ma y Luo~\cite{AdaptiveLoss2021} generalizaron la adaptación a nivel de \textit{landmark} individual mediante pesos específicos basados en dificultad empírica, donde la función de pérdida adaptativa asigna mayor énfasis a \textit{landmarks} con historial de errores elevados. El impacto de \textit{Wing Loss} ha sido substancial: la función ha sido adoptada ampliamente en aplicaciones de imágenes médicas debido a su robustez a \textit{outliers} y enfoque en errores pequeños clínicamente relevantes.

Las restricciones geométricas basadas en conocimiento anatómico representan una segunda categoría de especialización de funciones de pérdida. Song et al.~\cite{Song2020} incorporaron restricciones de simetría para \textit{landmarks} cefalométricos mediante penalización de asimetrías bilaterales: $\mathcal{L}_{\text{sym}} = \sum_{(i,j) \in S} \|p_i - \text{mirror}(p_j)\|_2^2$, donde $S$ denota pares de \textit{landmarks} simétricos y $\text{mirror}(\cdot)$ representa reflexión respecto al plano sagital medio. Esta restricción proporciona mejoras de 6.8\% específicamente en \textit{landmarks} con simetría bilateral, explotando la propiedad anatómica fundamental de que estructuras bilaterales deben ser aproximadamente simétricas en individuos sanos. Thaler et al.~\cite{Thaler2021} incorporaron preservación de distancias mediante restricciones basadas en modelos estadísticos de forma, penalizando desviaciones de distancias inter-\textit{landmark} respecto a valores de referencia anatómicos: $\mathcal{L}_{\text{dist}} = \sum_{(i,j) \in D} (\|p_i - p_j\|_2 - d_{ij}^{\text{ref}})^2$, donde $D$ denota pares de \textit{landmarks} con distancia anatómica conocida y $d_{ij}^{\text{ref}}$ representa la distancia de referencia. Urschler et al.~\cite{Urschler2021} presentaron en \textit{Pattern Recognition Letters} integración de restricciones geométricas mediante conocimiento previo de forma aprendido de datos de entrenamiento, utilizando análisis de componentes principales sobre configuraciones de \textit{landmarks} para definir un espacio de formas anatómicamente plausibles.

Kendall y Gal~\cite{Kendall2017} introdujeron en NeurIPS 2017 un marco para cuantificación de incertidumbre en aprendizaje profundo Bayesiano para visión por computadora, distinguiendo entre incertidumbre aleatoria (inherente a los datos) y epistémica (incertidumbre del modelo). Liu et al.~\cite{Liu2024Uncertainty} extendieron este enfoque a detección de \textit{landmarks} anatómicos en imágenes médicas, presentando en \textit{IEEE Transactions on Medical Imaging} 2024 un método de aprendizaje profundo con conciencia de incertidumbre que predice intervalos de confianza para cada \textit{landmark}, permitiendo detección automática de predicciones con alta incertidumbre que requieren revisión manual. Su método alcanzó errores de 1.5-2.8 píxeles en múltiples dominios anatómicos mientras proporciona calibración de incertidumbre superior. Un gap crítico identificado en la literatura es que pocos trabajos combinan múltiples componentes de función de pérdida simultáneamente: la mayoría de métodos utiliza MSE estándar o una única restricción geométrica, sin exploración sistemática de combinaciones de \textit{Wing Loss}, restricciones de simetría, y preservación de distancias.

\subsection{Análisis Comparativo y Posicionamiento del Presente Trabajo}

La Tabla~\ref{tab:state_of_art} presenta una comparación exhaustiva de trabajos representativos en detección de \textit{landmarks} anatómicos en imágenes médicas publicados entre 2016 y 2024. Los criterios de inclusión fueron: (1) aplicación a imágenes médicas (radiografías, tomografía computarizada, resonancia magnética), (2) utilización de aprendizaje profundo, (3) evaluación cuantitativa reportada con métricas de error de localización, y (4) publicación en \textit{venues} de alto impacto académico (IEEE Transactions on Medical Imaging, IEEE Journal of Biomedical and Health Informatics, Medical Image Analysis, CVPR/ICCV, MICCAI, Scientific Reports, Applied Sciences, Sensors). Los criterios de comparación incluyen: método/enfoque (coordinate regression, heatmap regression, o híbrido), arquitectura de red neuronal, tipo y tamaño del conjunto de datos, función de pérdida utilizada, error promedio de localización reportado, y dominio anatómico específico. La tabla evidencia la diversidad de enfoques metodológicos y la evolución temporal hacia arquitecturas más sofisticadas y funciones de pérdida especializadas.

\begin{table}[p]
\centering
\caption{Estado del arte en detección de \textit{landmarks} en imágenes médicas (2016-2024). Las abreviaciones utilizadas son: Ceph (cefalométrico), px (píxeles), NME (error medio normalizado), GCN (Graph Convolutional Network), ViT (Vision Transformer), RL (Reinforcement Learning).}
\label{tab:state_of_art}
\scriptsize
\begin{tabular}{|p{2cm}|p{1.8cm}|p{2cm}|p{2.2cm}|p{1.8cm}|p{1.5cm}|p{1.8cm}|}
\hline
\textbf{Autor/Año} & \textbf{Método} & \textbf{Arquitectura} & \textbf{Dataset (tipo/n)} & \textbf{Loss Function} & \textbf{Error} & \textbf{Dominio} \\
\hline
Lindner 2016 & Multi-atlas clásico & N/A (no DL) & Ceph 400 & N/A & 2.0 mm & Cefalométrico \\
\hline
Yang 2017 & Heatmap & Stacked Hourglass & Facial 3000 & MSE & 3.4 px & Facial \\
\hline
Feng 2018 & Coordinate & ResNet-50 & Facial 3800 & Wing Loss & 4.04\% NME & Facial \\
\hline
Wang 2019 & Heatmap & Hourglass & Facial 4000 & Adaptive Wing & 3.81\% NME & Facial \\
\hline
Payer 2019 & Heatmap+GCN & U-Net+Spatial & Hand X-ray 895 & MSE+spatial & 1.87 mm & Mano \\
\hline
Noothout 2020 & Coordinate & FCNN & Ceph 400 & MSE & 1.21 mm & Cefalométrico \\
\hline
Oh 2020 & Coordinate & DenseNet & Ceph 935 & MSE+context & 1.18 mm & Cefalométrico \\
\hline
Song 2020 & Coordinate & ResNet-18 & Ceph 450 & MSE+symmetry & 1.45 mm & Cefalométrico \\
\hline
Zhang 2020 & Heatmap cascade & U-Net (3-stage) & Ceph 1000 & MSE & 1.35 mm & Cefalométrico \\
\hline
Kang 2021 & 3D RL-based & 3D CNN & CBCT 350 & Reward-based & 1.82 mm & Ceph 3D \\
\hline
Ma \& Luo 2021 & Heatmap & U-Net & Ceph 800 & Adaptive Loss & 1.29 mm & Cefalométrico \\
\hline
Thaler 2021 & Heatmap Bayesian & U-Net & Hand 600 & MSE+uncertainty & 2.12 mm & Mano \\
\hline
Quan 2021 & Universal & ResNet-101 & Mixed 2000+ & MSE multi-task & 1.5-3.2 mm & Multi-anatomía \\
\hline
Liu 2021 & Coordinate+GCN & ResNet+GCN & Facial 3000 & Wing+structure & 3.2 px & Facial \\
\hline
Li 2022 & Transformer & ViT cascade & Facial 5000 & Wing Loss & 2.98\% NME & Facial \\
\hline
Cheng 2023 & Heatmap+perturbation & U-Net & Chest X-ray 2000 & MSE & 3.78 px & Tórax \\
\hline
Gaggion 2023 & GNN hybrid & HybridGNet & Chest X-ray 1500 & MSE+graph & N/A (seg) & Tórax \\
\hline
Huang 2023 & Hybrid Trans-CNN & ViT+ResNet & X-ray multi 1200 & MSE heatmap & 2.8 px & Multi X-ray \\
\hline
Li 2023 & Hybrid coord+heat & ResNet-34 & Chest 956 (46 lmks) & MSE+symmetry & 4.22 px & Tórax \\
\hline
Jeong 2023 & Attention-guided & ResNet-50+attn & Chest 800 & Wing Loss & 5.13 px & Tórax \\
\hline
Liu 2024 & Uncertainty-aware & ResNet+Bayesian & Multi 3500 & MSE+uncertainty & 1.5-2.8 px & Multi-dominio \\
\hline
\end{tabular}
\end{table}

El análisis de la Tabla~\ref{tab:state_of_art} revela múltiples tendencias significativas en la evolución del campo. Primero, se observa una transición temporal inequívoca desde métodos clásicos hacia aprendizaje profundo: Lindner et al.~\cite{Lindner2016} reportaron en 2016 un error de 2.0 mm utilizando enfoques multi-atlas tradicionales, mientras que Zhang et al.~\cite{Zhang2020MIA} alcanzaron 1.35 mm con redes neuronales convolucionales en cascada en 2020, representando una mejora del 32.5\%. Segundo, existe una divergencia metodológica según el dominio de aplicación: la estimación de pose humana y detección de \textit{landmarks} faciales favorecen regresión de mapas de calor (Newell 2016, Yang 2017) debido a la preservación de contexto espacial y capacidad de representar incertidumbre multimodal, mientras que aplicaciones en imágenes médicas prefieren predominantemente regresión de coordenadas (Noothout 2020, Oh 2020, Li 2023) por eficiencia computacional y menor consumo de memoria GPU. Tercero, el aprendizaje por transferencia desde ImageNet se ha establecido como práctica universal: todos los trabajos publicados después de 2018 utilizan pre-entrenamiento en ImageNet, sin reportes de entrenamiento desde inicialización aleatoria, evidenciando la importancia crítica de representaciones pre-aprendidas discutida en la Sección~2.4. Cuarto, existe una disparidad substancial en tamaños de conjuntos de datos entre dominio médico y visión por computadora general: conjuntos médicos típicamente contienen 400-2000 imágenes (Noothout 400, Zhang 1000, Li 956) versus conjuntos faciales/pose con más de 3000 ejemplos (Li 2022 con 5000, Liu 2021 con 3000), representando un factor de 3-10× de diferencia que refleja las dificultades de adquisición y anotación de datos médicos. Quinto, se observa una evolución en funciones de pérdida desde MSE estándar (dominante 2016-2019) hacia \textit{Wing Loss} (2018+) y funciones multi-componente adaptativas (2021+), reflejando comprensión creciente de que la función de pérdida debe alinearse con los requisitos específicos de la aplicación. Finalmente, la emergencia de arquitecturas basadas en transformadores post-2022 (Li 2022, Huang 2023) indica un cambio paradigmático hacia captura de contexto global mediante mecanismos de atención, aunque las redes neuronales convolucionales mantienen predominancia en imágenes médicas debido a eficiencia computacional y menores requerimientos de datos.

El análisis comparativo identifica múltiples gaps y limitaciones en el estado del arte actual que motivan la presente investigación. Primero, la combinación de restricciones geométricas es limitada: la mayoría de trabajos incorpora una única restricción (Song 2020 utiliza exclusivamente simetría, Payer 2019 solo configuración espacial, Thaler 2021 únicamente modelado de incertidumbre). Li et al.~\cite{Li2023} combinan regresión híbrida coordinate+heatmap con restricciones de simetría, pero utilizan MSE estándar en lugar de \textit{Wing Loss}, perdiendo los beneficios de amplificación de gradientes en errores pequeños. Ningún trabajo reportado en la literatura combina simultáneamente \textit{Wing Loss}, restricciones de simetría bilateral, y preservación de distancias anatómicas para radiografías de tórax, representando un gap crítico. Segundo, los estudios de ablación cuantitativos son limitados: solo 11 de 20 trabajos revisados reportan ablaciones sistemáticas que cuantifican el impacto individual de cada componente de sus funciones de pérdida compuestas, dificultando la comprensión de qué restricciones geométricas proporcionan las mayores contribuciones al desempeño. Tercero, existe un trade-off no explorado sistemáticamente entre número de \textit{landmarks} y tamaño de conjunto de datos: Li 2023 utiliza 46 \textit{landmarks} (el más exhaustivo para radiografías de tórax) pero con 956 imágenes, mientras Cheng 2023 utiliza 2000 imágenes pero solo 18 \textit{landmarks}, sin análisis de cómo esta relación afecta la capacidad de generalización. Cuarto, las restricciones de simetría bilateral son substancialmente infrautilizadas: solo Song 2020 y Li 2023 explotan explícitamente la simetría bilateral en radiografías cefalométricas y de tórax, a pesar de ser una propiedad anatómica fundamental que podría proporcionar supervisión adicional sin requerir anotaciones adicionales. Finalmente, la exploración de restricciones de distancias anatómicas es limitada: Thaler 2021 y Payer 2019 utilizan restricciones de distancia en radiografías de mano, pero este enfoque no ha sido aplicado sistemáticamente a radiografías de tórax con sus 7 pares simétricos específicos y relaciones de distancia anatómicamente consistentes entre estructuras mediastinales y costales (como se estableció en la Sección~2.1).

El presente trabajo se posiciona en la intersección de tres líneas de investigación complementarias: (1) regresión eficiente de coordenadas para radiografías de tórax siguiendo los enfoques exitosos de Li et al.~\cite{Li2023} y Jeong et al.~\cite{Jeong2023}, (2) \textit{Wing Loss} para amplificación de gradientes en el régimen de errores pequeños clínicamente relevantes como demostrado por Feng et al.~\cite{Feng2018} en \textit{landmarks} faciales, y (3) restricciones geométricas anatómicas que explotan propiedades estructurales del tórax (Song et al.~\cite{Song2020} para simetría, Payer et al.~\cite{Payer2019Spatial} para preservación de distancias). La contribución única del trabajo es la primera aplicación de la combinación \textit{Wing Loss} + restricciones de simetría bilateral + preservación de distancias anatómicas para 15 \textit{landmarks} en radiografías de tórax posteroanterior utilizando una arquitectura ResNet-18 eficiente pre-entrenada en ImageNet. La función de pérdida compuesta propuesta $\mathcal{L}_{\text{total}} = \lambda_1 \mathcal{L}_{\text{Wing}} + \lambda_2 \mathcal{L}_{\text{sym}} + \lambda_3 \mathcal{L}_{\text{dist}}$ (presentada en detalle en la Sección~2.5) integra conocimiento anatómico específico del tórax sin incrementar la complejidad arquitectónica: las 7 pares de \textit{landmarks} simétricos bilaterales y 2 puntos localizados en la línea media (identificados en la Tabla~2.1.1 de la Sección~2.1) definen naturalmente las restricciones geométricas, y las distancias anatómicas entre pares específicos de \textit{landmarks} (por ejemplo, entre ápices pulmonares, entre ángulos costofénicos) proporcionan supervisión adicional basada en variabilidad anatómica limitada. La metodología experimental completa, incluyendo estudios de ablación sistemáticos para cuantificar el impacto de cada componente de la función de pérdida, se presenta en el Capítulo 3, mientras que los resultados comparativos con el estado del arte se discuten en el Capítulo 4.

La revisión exhaustiva del estado del arte presentada en esta sección evidencia la madurez del campo de detección automática de \textit{landmarks} mediante aprendizaje profundo, con errores de localización alcanzando precisión sub-milimétrica en aplicaciones cefalométricas controladas (Oh 2020: 1.18 mm, Ma \& Luo 2021: 1.29 mm) y 3-5 píxeles en radiografías de tórax con mayor variabilidad inter-paciente e inter-institucional (Li 2023: 4.22 píxeles, Cheng 2023: 3.78 píxeles). Sin embargo, los gaps identificados en combinación de funciones de pérdida especializadas y restricciones geométricas anatómicas específicas motivan la investigación de enfoques que integren múltiples fuentes de conocimiento anatómico simultáneamente. La siguiente sección presenta una síntesis del marco teórico completo desarrollado en el Capítulo 2, conectando los fundamentos de aprendizaje profundo, arquitecturas residuales, aprendizaje por transferencia, funciones de pérdida especializadas, y estado del arte revisado con la metodología experimental que será presentada en el Capítulo 3.
