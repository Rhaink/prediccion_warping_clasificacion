\section{Extracción de Características}
\label{sec:extraccion_caracteristicas_teoria}
La extracción de características es el proceso de transformar datos brutos (como los píxeles de una imagen) en un conjunto de valores (un vector de características) que sea informativo, no redundante y que facilite las tareas de aprendizaje posteriores, como la clasificación o la regresión.

\subsection{Características Basadas en Perfiles de Intensidad (Contexto del Trabajo Previo)}
\label{ssec:caracteristicas_perfiles_1d}
En el contexto de los modelos deformables, una estrategia común para guiar el ajuste del modelo a la imagen es analizar la apariencia de la imagen en la vecindad de los landmarks del modelo. Los perfiles de intensidad 1D son una forma de hacerlo: para cada landmark, se extrae un perfil de intensidad a lo largo de una dirección (generalmente normal al contorno del modelo en ese punto). Este vector de intensidades 1D se utiliza luego como característica \cite{cootes1995active}. El trabajo previo que condujo a esta tesis (MaShDL v1) empleó perfiles de intensidad 1D. Si bien son computacionalmente eficientes, los perfiles 1D pueden perder información espacial 2D crucial, especialmente en regiones con texturas complejas o bordes ambiguos.

\subsection{Características Basadas en Apariencia Local 2D (Contexto del Nuevo Enfoque)}
\label{ssec:caracteristicas_parches_2d}
Para superar las limitaciones de los perfiles 1D, el enfoque MaShDL-CNN Hybrid propuesto en esta tesis se basa en el análisis de parches 2D extraídos alrededor de cada landmark. Un parche 2D de tamaño $Q \times Q$ captura una región de apariencia local mucho más rica que un perfil 1D. Estos parches pueden codificar información sobre texturas, gradientes en múltiples orientaciones y relaciones espaciales locales. La hipótesis es que esta información 2D más completa permitirá a un modelo de aprendizaje profundo (una CNN) aprender un mapeo más preciso hacia los parámetros de forma del SSM.

% (Sugerencia: Figura \ref{fig:comparacion_perfil_parche}: Una figura que muestre un landmark en un borde pulmonar. A la izquierda, visualizar un perfil de intensidad 1D extraído. A la derecha, visualizar un parche 2D Q×Q centrado en el mismo landmark. El pie de figura explicaría la mayor riqueza informativa del parche 2D.)

\subsection{Redes Neuronales Convolucionales (CNNs) como Extractoras de Características}
\label{ssec:cnns_feature_extractors}
Las Redes Neuronales Convolucionales (CNNs) se han convertido en el estándar de facto para la extracción de características de imágenes en una amplia variedad de tareas de visión por computadora \cite{lecun2015deep, gu2018recent}. Su arquitectura está inspirada en el córtex visual humano y se caracteriza por el uso de capas convolucionales, capas de pooling (submuestreo) y funciones de activación no lineales.

\begin{itemize}
\item \textbf{Capas Convolucionales:} Aplican un conjunto de filtros (kernels) aprendibles a la imagen de entrada (o al mapa de características de la capa anterior). Cada filtro está diseñado para detectar patrones específicos (e.g., bordes, texturas, formas simples). La operación de convolución permite compartir pesos, lo que reduce drásticamente el número de parámetros del modelo y lo hace más eficiente y menos propenso al sobreajuste. La salida de una capa convolucional es un conjunto de mapas de características.
Si $I$ es la entrada (imagen o mapa de características) y $K$ es un kernel, la operación de convolución 2D (simplificada) para un píxel $(x,y)$ en el mapa de salida $O$ es:
$O(x,y) = \sum_i \sum_j I(x-i, y-j)K(i,j) (+ \text{bias})$
Esto se aplica a través de toda la entrada para generar el mapa de características.

\item \textbf{Funciones de Activación:} Después de la convolución, se aplica una función de activación no lineal, como la Unidad Lineal Rectificada (ReLU), $f(z) = \max(0, z)$, o sus variantes (Leaky ReLU, ELU). Estas no linealidades son cruciales para que la red pueda aprender mapeos complejos.

\item \textbf{Capas de Pooling (Submuestreo):} Reducen la dimensionalidad espacial de los mapas de características, lo que ayuda a controlar el sobreajuste, reducir la carga computacional y crear invarianza a pequeñas traslaciones. Las operaciones de pooling comunes son Max Pooling (toma el valor máximo en una vecindad) y Average Pooling.

\item \textbf{Jerarquía de Características:} Al apilar múltiples capas convolucionales y de pooling, las CNNs aprenden una jerarquía de características. Las primeras capas tienden a aprender características de bajo nivel (e.g., bordes, esquinas), mientras que las capas más profundas aprenden a combinar estas características para detectar patrones más complejos y abstractos relevantes para la tarea en cuestión \cite{zeiler2014visualizing}.

\end{itemize}
En el contexto de esta tesis, una sub-CNN se utiliza para procesar cada parche 2D $Q \times Q$ extraído alrededor de los landmarks. La salida de esta sub-CNN es un vector de características de dimensión fija que representa la información relevante del parche para la estimación de la forma pulmonar. El uso de \texttt{tf.keras.layers.TimeDistributed} permite aplicar esta misma sub-CNN con pesos compartidos a todos los $N_{\text{lmk}}$ parches de una imagen, promoviendo un aprendizaje eficiente.

% (Sugerencia: Figura \ref{fig:arquitectura_cnn_generica}: Un diagrama genérico mostrando la estructura de una CNN típica: entrada, seguida de bloques [Convolución -> Activación -> Pooling], y finalmente capas totalmente conectadas (aunque en nuestro caso de extracción de features por parche, la "salida" es el vector de features antes de la DNN principal). Podrías indicar cómo los tamaños de los mapas de características cambian a través de la red.)

