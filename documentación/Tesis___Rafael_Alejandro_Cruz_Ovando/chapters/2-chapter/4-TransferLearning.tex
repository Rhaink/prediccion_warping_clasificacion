\section{Aprendizaje por Transferencia en Imágenes Médicas}

Las arquitecturas residuales presentadas en la Sección~2.3, particularmente ResNet con sus múltiples variantes de profundidad, han demostrado capacidad excepcional para aprender representaciones jerárquicas complejas en tareas de visión por computadora. Sin embargo, el entrenamiento de estas redes profundas desde inicialización aleatoria requiere conjuntos de datos masivos para lograr convergencia robusta y generalización adecuada. En el dominio médico, la adquisición de grandes conjuntos de datos etiquetados enfrenta barreras significativas: costos elevados de anotación por expertos radiólogos, consideraciones de privacidad de pacientes, y la naturaleza inherentemente limitada de casos patológicos específicos. Los conjuntos de datos médicos típicamente contienen cientos a miles de imágenes, en contraste con los millones de ejemplos disponibles en dominios de visión por computadora general como ImageNet. El aprendizaje por transferencia (del inglés, \textit{transfer learning}) constituye un paradigma fundamental que permite aprovechar representaciones aprendidas en conjuntos de datos masivos de un dominio fuente para mejorar significativamente el desempeño en tareas del dominio objetivo con datos limitados \cite{Yosinski2014, Moor2023, Zhou2022}.

\subsection{Pre-entrenamiento en ImageNet y Representaciones Transferibles}

ImageNet representa el conjunto de datos de referencia para pre-entrenamiento de modelos de visión por computadora, comprendiendo aproximadamente 1.2 millones de imágenes de entrenamiento distribuidas en 1,000 categorías de objetos cotidianos \cite{Krizhevsky2012}. Los modelos entrenados en ImageNet, incluyendo las arquitecturas ResNet descritas en la Sección~2.3, aprenden representaciones jerárquicas de características visuales mediante optimización de la función de pérdida de clasificación multi-clase. Formalmente, el pre-entrenamiento en el dominio fuente se define como:
\begin{equation}
\theta^* = \arg\min_{\theta} \sum_{i=1}^{N_s} \mathcal{L}_{\text{source}}(f_\theta(x_i^s), y_i^s)
\label{eq:source_pretraining}
\end{equation}
donde $f_\theta$ representa la red neuronal con parámetros $\theta$, $\mathcal{D}_{\text{source}} = \{(x_i^s, y_i^s)\}_{i=1}^{N_s}$ es el conjunto de datos fuente (ImageNet con $N_s \approx 1.2 \times 10^6$), y $\mathcal{L}_{\text{source}}$ es típicamente la entropía cruzada categórica para clasificación.

La hipótesis central del aprendizaje por transferencia es que las características de bajo y medio nivel aprendidas en ImageNet poseen utilidad general para tareas de visión por computadora, incluso en dominios substancialmente diferentes como imágenes médicas. Las capas convolucionales tempranas de redes pre-entrenadas detectan bordes, texturas, y gradientes de intensidad genéricos que son relevantes para cualquier tarea de procesamiento de imágenes. Las capas intermedias capturan estructuras geométricas de complejidad creciente (formas, patrones, composiciones espaciales), mientras que las capas profundas aprenden representaciones más específicas del dominio fuente \cite{Yosinski2014, Azizi2023}.

Yosinski et al.~\cite{Yosinski2014} demostraron empíricamente que la transferibilidad de características decae con la profundidad de la red cuando los dominios fuente y objetivo son muy diferentes: las primeras capas convolucionales aprenden detectores casi universales, mientras que capas superiores requieren adaptación substancial al dominio objetivo. Este hallazgo motivó estrategias de \textit{fine-tuning} selectivo que se discuten en la siguiente subsección.

Estudios recientes han expandido significativamente la comprensión de \textit{transfer learning} en medicina. Azizi et al.~\cite{Azizi2023} demostraron en \textit{Nature Biomedical Engineering} que modelos pre-entrenados mediante aprendizaje auto-supervisado en conjuntos de datos médicos multi-institucionales exhiben transferibilidad superior a modelos pre-entrenados exclusivamente en ImageNet, sugiriendo que el pre-entrenamiento en dominios más cercanos al objetivo (radiografías médicas en general) proporciona ventajas adicionales. Moor et al.~\cite{Moor2023}, en un artículo perspectivo en \textit{Nature}, argumentan que los modelos fundacionales (del inglés, \textit{foundation models}) pre-entrenados en datos médicos masivos representan el futuro del \textit{transfer learning} médico, reduciendo la dependencia de ImageNet. Sin embargo, para tareas específicas como detección de \textit{landmarks} anatómicos en radiografías de tórax, el pre-entrenamiento en ImageNet continúa siendo el estándar actual debido a la disponibilidad limitada de modelos fundacionales médicos especializados \cite{Zhou2022}.

\subsection{Estrategias de Fine-Tuning y Adaptación al Dominio Médico}

El \textit{transfer learning} puede implementarse mediante dos estrategias principales, que difieren en qué parámetros de la red se actualizan durante el entrenamiento en el dominio objetivo.

\textbf{Extracción de características} (del inglés, \textit{feature extraction}): Los pesos de las capas convolucionales pre-entrenadas se congelan completamente, y solo se entrenan las capas completamente conectadas finales específicas de la tarea objetivo. Matemáticamente, el modelo se descompone como $f_\theta = g_{\phi}(h_{\psi}(x))$, donde $h_{\psi}$ representa el extractor de características convolucionales con pesos congelados $\psi = \psi^*_{\text{ImageNet}}$, y $g_{\phi}$ representa las capas de tarea específica (típicamente una o dos capas completamente conectadas) con parámetros entrenables $\phi$:
\begin{equation}
\phi^* = \arg\min_{\phi} \sum_{j=1}^{N_t} \mathcal{L}_{\text{target}}(g_{\phi}(h_{\psi^*}(x_j^t)), y_j^t)
\label{eq:feature_extraction}
\end{equation}
donde $\mathcal{D}_{\text{target}} = \{(x_j^t, y_j^t)\}_{j=1}^{N_t}$ es el conjunto de datos objetivo (típicamente $N_t \ll N_s$), y $\mathcal{L}_{\text{target}}$ es la función de pérdida específica de la tarea (por ejemplo, error cuadrático medio para regresión de coordenadas, como se discutirá en la Sección~2.5). Esta estrategia es computacionalmente eficiente y apropiada cuando el conjunto de datos objetivo es muy pequeño ($N_t < 1{,}000$ típicamente), mitigando el riesgo de sobreajuste al limitar drásticamente el número de parámetros entrenables.

\textbf{Ajuste fino} (del inglés, \textit{fine-tuning}): Todos los parámetros de la red, o un subconjunto de capas superiores, se ajustan en el dominio objetivo utilizando la inicialización pre-entrenada:
\begin{equation}
\theta_{\text{fine-tuned}} = \arg\min_{\theta} \sum_{j=1}^{N_t} \mathcal{L}_{\text{target}}(f_\theta(x_j^t), y_j^t), \quad \text{con } \theta(t=0) = \theta^*_{\text{ImageNet}}
\label{eq:finetuning}
\end{equation}

El \textit{fine-tuning} permite que la red adapte sus representaciones internas al dominio objetivo, pero requiere conjuntos de datos de tamaño moderado ($N_t > 1{,}000$ típicamente) y selección cuidadosa de hiperparámetros de optimización para evitar sobreajuste o colapso catastrófico de las características pre-entrenadas útiles.

Una estrategia avanzada es la aplicación de tasas de aprendizaje diferenciales (del inglés, \textit{discriminative learning rates}): capas tempranas, que capturan características de bajo nivel genéricas, se actualizan con tasas de aprendizaje pequeñas o se congelan completamente, mientras que capas profundas y capas específicas de la tarea se entrenan con tasas de aprendizaje más altas:
\begin{align}
\theta_{\text{early}}^{(t+1)} &= \theta_{\text{early}}^{(t)} - \eta_{\text{low}} \nabla_{\theta_{\text{early}}} \mathcal{L}_{\text{target}} \label{eq:lr_early} \\
\theta_{\text{deep}}^{(t+1)} &= \theta_{\text{deep}}^{(t)} - \eta_{\text{high}} \nabla_{\theta_{\text{deep}}} \mathcal{L}_{\text{target}} \label{eq:lr_deep}
\end{align}
donde $\eta_{\text{high}} / \eta_{\text{low}} \approx 10$ es una configuración típica. Esta estrategia preserva las representaciones de bajo nivel útiles mientras permite adaptación substancial en capas superiores que requieren especialización al dominio médico.

El \textit{fine-tuning} progresivo (del inglés, \textit{progressive unfreezing}) constituye una variante donde inicialmente solo las capas finales son entrenables, y gradualmente se descongelan capas anteriores a medida que avanza el entrenamiento. Nguyen et al.~\cite{Nguyen2024} presentan un análisis exhaustivo de estrategias de \textit{transfer learning} multi-etapa en imágenes médicas, demostrando que el descongelamiento progresivo proporciona convergencia más estable en conjuntos de datos médicos pequeños comparado con \textit{fine-tuning} simultáneo de todas las capas.

\subsection{Brecha de Dominio y Adaptación para Radiografías de Tórax}

Existe una brecha de dominio (del inglés, \textit{domain gap}) substancial entre imágenes naturales de ImageNet e imágenes médicas de radiografías de tórax. ImageNet contiene fotografías RGB de objetos cotidianos en escenarios naturales con iluminación variada, mientras que las radiografías de tórax son imágenes de canal único (escala de grises) que representan proyecciones bidimensionales de atenuación de rayos X de estructuras anatómicas tridimensionales, como se describió en la Sección~2.1. Las distribuciones de intensidad, texturas, y estructuras geométricas difieren fundamentalmente entre ambos dominios.

A pesar de esta disparidad, estudios empíricos han demostrado consistentemente que el \textit{transfer learning} desde ImageNet proporciona mejoras substanciales sobre el entrenamiento desde inicialización aleatoria en tareas de análisis de radiografías de tórax. Tajbakhsh et al.~\cite{Tajbakhsh2016} evaluaron \textit{transfer learning} en cuatro tareas de análisis de imágenes médicas, incluyendo detección de nódulos pulmonares en radiografías de tórax, demostrando mejoras de 5-10\% en AUC al utilizar pre-entrenamiento de ImageNet versus inicialización aleatoria, particularmente en regímenes de datos limitados ($N_t < 5{,}000$).

Investigaciones recientes han explorado técnicas de adaptación de dominio específicamente diseñadas para abordar la brecha entre ImageNet y radiografías médicas. Sanchez et al.~\cite{Sanchez2022} propusieron CX-DaGAN en \textit{IEEE Transactions on Medical Imaging}, una red generativa adversarial para adaptación de dominio en diagnóstico de neumonía con conjuntos de datos de radiografías de tórax extremadamente pequeños. Guan y Liu~\cite{Guan2022} presentaron un análisis comprehensivo de técnicas de adaptación de dominio para análisis de imágenes médicas en \textit{IEEE Transactions on Biomedical Engineering}, categorizando enfoques en: (1) adaptación basada en discrepancia de características, (2) adaptación adversarial, y (3) adaptación mediante reconstrucción. Estos métodos avanzados buscan alinear las distribuciones de características entre dominios fuente y objetivo, reduciendo la brecha de dominio y mejorando la transferibilidad.

La transferencia desde ImageNet a radiografías de tórax requiere adaptaciones arquitectónicas específicas. Las arquitecturas ResNet estándar esperan imágenes RGB (3 canales de entrada), mientras que las radiografías de tórax son de canal único. La práctica común consiste en replicar la imagen de escala de grises a tres canales ($x_{\text{RGB}} = [x, x, x]$), preservando los pesos pre-entrenados de la primera capa convolucional sin modificación. Alternativamente, los pesos del filtro de entrada pueden promediarse a través de los tres canales RGB y utilizarse para procesar el canal único directamente. La capa completamente conectada final pre-entrenada, que tiene 1,000 salidas correspondientes a las clases de ImageNet, debe reemplazarse con una capa específica de la tarea: para detección de \textit{landmarks}, esta capa predice $2K$ valores continuos representando coordenadas $(x, y)$ de $K$ \textit{landmarks}, sin función \textit{softmax}. La función de pérdida apropiada para esta tarea de regresión de coordenadas se discutirá en detalle en la Sección~2.5.

El aprendizaje por transferencia representa un componente fundamental para el desarrollo de sistemas de \textit{deep learning} en imágenes médicas con conjuntos de datos limitados. La combinación de pre-entrenamiento en ImageNet, estrategias de \textit{fine-tuning} con tasas de aprendizaje diferenciales, y adaptaciones arquitectónicas apropiadas permite la construcción de modelos robustos que aprovechan conocimiento visual genérico mientras se especializan en características anatómicas específicas del dominio médico \cite{Litjens2017, Esteva2019, Zhou2022}.
