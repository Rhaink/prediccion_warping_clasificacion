
% \section{Extracción de Parches para Entrenamiento de la CNN Híbrida}
% \label{sec:extraccion_parches_cnn}

% La Red Neuronal Convolucional (CNN) híbrida, diseñada para predecir los parámetros de forma $\vect{b}$ del SSM (ver Ecuación~\eqref{eq:ssm_reconstruction}), requiere como entrada información visual local derivada de la apariencia de la imagen alrededor de los puntos de referencia. Esta sección detalla el proceso de generación y extracción de estos parches de imagen, que constituyen los datos de entrenamiento para la CNN.

% \subsection{Generación de Ejemplos de Entrenamiento}
% Para cada uno de los $m$ modos de variación del SSM, se entrena un clasificador CNN independiente para predecir el coeficiente $b_k$ correspondiente (donde $k \in \{1, \dots, m\}$). La generación de ejemplos de entrenamiento para el $k$-ésimo clasificador implica la creación de instancias de forma que representen tanto el valor ground truth de $b_k$ como valores perturbados.
% \begin{itemize}
%     \item \textbf{Ejemplos Positivos:} Para una imagen de entrenamiento dada, se utiliza el vector de parámetros de forma $\vect{b}_{GT}$ (obtenido al proyectar la forma ground truth de esa imagen sobre la base del SSM) para generar una instancia de forma. Los parches extraídos alrededor de los landmarks de esta forma se asocian con la etiqueta del bin correspondiente al valor $b_{k,GT}$ (el $k$-ésimo componente de $\vect{b}_{GT}$).
%     \item \textbf{Ejemplos Negativos:} Para generar diversidad y robustez en el entrenamiento, se crean ejemplos negativos perturbando el $k$-ésimo coeficiente $b_k$ del vector $\vect{b}_{GT}$ mientras se mantienen los otros coeficientes $b_j (j < k)$ en sus valores ground truth (o estimados por clasificadores previos en un esquema secuencial). El valor de $b_k$ se muestrea aleatoriamente de un rango que excluye el bin ground truth, típicamente dentro de los límites de $\pm n\sigma_k$ (donde $\sigma_k = \sqrt{\lambda_k}$ es la desviación estándar del modo $k$). Los parches extraídos de estas formas perturbadas se asocian con la etiqueta del bin correspondiente al valor $b_k$ perturbado.
% \end{itemize}

% \begin{figure}[htbp] % Posicionamiento flexible
%     \centering
%     \includegraphics[width=0.7\columnwidth]{Figures/fig_pos_neg_examples.png}
%     \caption{Comparación visual entre un ejemplo positivo (izquierda), generado a partir de los parámetros de forma ground truth ($\vect{b}_{GT}$ con $b_k=0.04$ para un $k$ específico), y un ejemplo negativo (derecha), obtenido al perturbar el coeficiente $b_k$ ($b_{k,\text{pert}}=0.13$). Para cada caso, se muestra la forma resultante superpuesta en la radiografía y los parches de imagen correspondientes extraídos alrededor de sus landmarks.}
%     \label{fig:pos_neg_examples}
% \end{figure}

% \subsection{Transformación de Forma al Espacio de la Imagen}
% Antes de extraer los parches, la instancia de forma del SSM (ya sea positiva o negativa, definida por un vector de parámetros $\vect{b}$) debe ser transformada desde el espacio canónico del SSM al espacio de la imagen. Esto se logra utilizando la transformación de similitud $\mathcal{T}_{ESL}$ obtenida de la etapa de Estimación de Pose Inicial (ESL, Sección~\ref{sec:esl_matematica}):
% \begin{equation}
% \mat{S}'_{\text{img}} = \mathcal{T}_{ESL}(\mat{S}'_{\text{SSM}}(\vect{b}))
% \label{eq:shape_ssm_to_image} % Añadida etiqueta para referencia si es necesaria
% \end{equation}
% donde $\mat{S}'_{\text{SSM}}(\vect{b})$ es la forma de $K_{total}$ puntos (donde $K_{total}=144$) generada por el SSM con los parámetros $\vect{b}$, y $\mat{S}'_{\text{img}}$ son las coordenadas de los landmarks en el espacio de la imagen.

% \begin{figure}[htbp] % Posicionamiento flexible
%     \centering
%     \includegraphics[width=0.7\columnwidth]{Figures/fig_shape_transformation.png}
%     \caption{Ilustración del proceso de transformación de una forma desde el espacio canónico del Modelo Estadístico de Forma (SSM) al espacio de la imagen. (a) Representa la forma canónica del SSM, $\mat{S}'_{\text{SSM}}(\vect{b})$. (b) Muestra la forma transformada $\mat{S}'_{\text{img}}$ alineada con la radiografía de tórax, obtenida al aplicar la transformación de similitud $\mathcal{T}_{ESL}$ (proveniente de la Estimación de Pose Inicial) a la forma canónica, según la Ecuación~\eqref{eq:shape_ssm_to_image}.}
%     \label{fig:ssm_to_image_transformation}
% \end{figure}

% \subsection{Extracción de Parches}
% Para cada uno de los $K_{total}$ landmarks de la forma proyectada $\mat{S}'_{\text{img}}$, se extrae un parche cuadrado de intensidad de tamaño $Q \times Q$ píxeles, centrado en la posición del landmark $(x_i, y_i)$. Estos parches capturan la apariencia local de la imagen alrededor de cada punto de referencia.
% Los $K_{total}$ parches extraídos para una instancia de forma se aplanan y concatenan para formar un único vector de características $\vect{f} \in \R^{K_{total} Q^2}$, que sirve como entrada para la CNN.

% \begin{figure}[htbp] % Posicionamiento flexible
%     \centering   
%     \includegraphics[width=0.7\columnwidth]{Figures/fig_patch_extraction_details.png}
%     \caption{Proceso de extracción de parches para la CNN. (a) Una instancia de forma del SSM (línea azul) se proyecta al espacio de la imagen usando la pose estimada por ESL. (b) Para cada uno de los $K_{total}$ landmarks (puntos verdes), se extrae un parche de imagen $Q \times Q$ (cuadrados rojos) centrado en el landmark. Estos parches, una vez procesados, se utilizan como entrada para la CNN.}
%     \label{fig:patch_extraction_cnn}
% \end{figure}

% \subsection{Aumento de Datos}
% Para incrementar la variabilidad del conjunto de entrenamiento y mejorar la generalización de los modelos CNN, se aplican diversas técnicas de aumento de datos a las imágenes antes de la extracción de parches. Estas pueden incluir:
% \begin{itemize}
%     \item \textbf{Volteo Horizontal (Flipping):} Las imágenes se voltean horizontalmente con una cierta probabilidad. Si una imagen se voltea, las coordenadas de los landmarks y los parámetros de forma $\vect{b}$ asociados con modos asimétricos también deben ser ajustados correspondientemente (e.g., invirtiendo el signo de los $b_k$ para modos asimétricos).
%     \item \textbf{Variación de Intensidad:} Se pueden aplicar variaciones aleatorias al brillo y contraste de la imagen. Una técnica más sofisticada implica aplicar PCA a los valores de intensidad de las imágenes de entrenamiento y luego añadir múltiplos aleatorios de los principales eigenvectores de intensidad a la imagen.
% \end{itemize}

% \begin{figure}[htbp] % Posicionamiento flexible
%     \centering
%     \includegraphics[width=0.7\columnwidth]{Figures/fig_data_augmentation.png}
%     \caption{Técnicas de aumento de datos aplicadas a una radiografía de tórax y su correspondiente forma SSM superpuesta, utilizadas para enriquecer el conjunto de entrenamiento. Se observa: (a) la imagen original; (b) la imagen y la forma SSM después de un volteo horizontal (nótese que los coeficientes $b_k$ de los parámetros de forma $\vect{b}$ para modos asimétricos se ajustarían en consecuencia); y (c) la imagen original con variaciones aleatorias de contraste y brillo.}
%     \label{fig:data_augmentation_examples}
% \end{figure}

% \subsection{Discretización de Coeficientes $b_k$}
% Dado que las CNNs se entrenan como clasificadores, el valor continuo del coeficiente $b_k$ (ya sea el ground truth o el perturbado) se discretiza en uno de $B$ bins. Típicamente, el rango de variación de $b_k$ (e.g., $[-n\sigma_k, n\sigma_k]$, donde $\sigma_k = \sqrt{\lambda_k}$ es la desviación estándar del $k$-ésimo modo) se divide en $B$ intervalos de igual tamaño. La etiqueta discreta $y_k \in \{0, \dots, B-1\}$ correspondiente al bin en el que cae el valor de $b_k$ se utiliza como la etiqueta ground truth para el entrenamiento del $k$-ésimo clasificador CNN.

% \begin{figure}[htbp] % Posicionamiento flexible
%     \centering
%     \includegraphics[width=0.7\textwidth]{Figures/fig_b_discretization.png}
%     \caption{Ilustración conceptual del proceso de discretización para un coeficiente de forma $b_k$. El rango de variación del coeficiente (aquí mostrado como $\pm 3.0\sigma_k$, con $\sigma_k=0.06$ para el ejemplo) se divide en $B=3$ bins de igual tamaño (Bin 0, Bin 1, Bin 2). Un valor continuo del coeficiente, como $b_k = 0.04$ (indicado por el punto rojo), se asigna al bin correspondiente (en este caso, Bin 1, resaltado en azul claro), generando una etiqueta discreta para el entrenamiento del clasificador CNN. La curva negra representa esquemáticamente la distribución de probabilidad $p(b_k)$ del coeficiente.}
%     \label{fig:bk_discretization}
% \end{figure}

% \subsection{Reducción de Dimensionalidad de Parches (Opcional)}
% El vector de características concatenado $\vect{f} \in \R^{K_{total} Q^2}$ puede tener una dimensionalidad muy alta (e.g., $144 \times 25^2 = 90000$ para $Q=25$, si $K_{total}=144$). Para reducir la carga computacional y potencialmente mejorar el rendimiento eliminando redundancias, se puede aplicar PCA a estos vectores de características de parches. Se entrena un modelo PCA separado para los vectores de características de cada modo $k$, transformando $\vect{f}$ a un subespacio de menor dimensión $\vect{f}' \in \R^{d_{\text{PCA}}}$, donde $d_{\text{PCA}} \ll K_{total} Q^2$.

% Este proceso de extracción y preparación de datos asegura que la CNN reciba información local relevante y normalizada para aprender la compleja relación entre la apariencia de la imagen y los parámetros de forma del SSM.

\section{Extracción de Parches para Entrenamiento de la CNN Híbrida}
\label{sec:extraccion_parches_cnn_simplified}

La Red Neuronal Convolucional (CNN) híbrida predice los parámetros de forma $\vect{b}$ del Modelo Estadístico de Forma (SSM, ver Ecuación~\eqref{eq:ssm_reconstruction_simplified} de una sección anterior). Para ello, necesita parches de imagen extraídos alrededor de los puntos de referencia (landmarks).

\subsection{Generación de Ejemplos de Entrenamiento}
Para cada uno de los $m$ modos de variación del SSM, se entrena una CNN para predecir su coeficiente $b_k$.
\begin{itemize}
    \item \textbf{Ejemplos Positivos:} Se usan los parámetros de forma verdaderos $\vect{b}_{GT}$ para generar una forma. Los parches extraídos de esta forma se asocian con el valor $b_{k,GT}$.
    \item \textbf{Ejemplos Negativos:} Se generan formas perturbando el coeficiente $b_k$ de $\vect{b}_{GT}$. Los parches de estas formas se asocian con el valor $b_k$ perturbado. Esto ayuda a la CNN a aprender a distinguir diferentes valores de $b_k$.
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\columnwidth]{Figures/fig_pos_neg_examples.png}
    \caption{Ejemplo positivo (forma ground truth) y negativo (forma perturbada), con sus parches asociados.}
    \label{fig:pos_neg_examples_simplified}
\end{figure}

\subsection{Transformación de Forma al Espacio de la Imagen}
Una forma del SSM, definida por $\vect{b}$, se transforma del espacio del modelo al espacio de la imagen usando la transformación de pose $\mathcal{T}_{ESL}$ (obtenida de la Estimación de Pose Inicial, Sección~\ref{sec:esl_simplified}):
\begin{equation}
\mat{S}'_{\text{img}} = \mathcal{T}_{ESL}(\mat{S}'_{\text{SSM}}(\vect{b}))
\label{eq:shape_ssm_to_image_simplified}
\end{equation}
donde $\mat{S}'_{\text{SSM}}(\vect{b})$ es la forma generada por el SSM y $\mat{S}'_{\text{img}}$ son las coordenadas de los landmarks en la imagen.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\columnwidth]{Figures/fig_shape_transformation.png}
    \caption{Transformación de una forma del SSM al espacio de la imagen usando $\mathcal{T}_{ESL}$.}
    \label{fig:ssm_to_image_transformation_simplified}
\end{figure}

\subsection{Extracción de Parches}
Para cada uno de los $\Ktotal$ landmarks de la forma $\mat{S}'_{\text{img}}$ en la imagen, se extrae un parche cuadrado de intensidad de $Q \times Q$ píxeles, centrado en el landmark.
Estos $\Ktotal$ parches se aplanan y concatenan en un vector de características $\vect{f}$, que es la entrada para la CNN.

\begin{figure}[htbp]
    \centering   
    \includegraphics[width=0.8\columnwidth]{Figures/fig_patch_extraction_details.png}
    \caption{Extracción de parches de $Q \times Q$ centrados en los landmarks de la forma proyectada en la imagen.}
    \label{fig:patch_extraction_cnn_simplified}
\end{figure}

\subsection{Aumento de Datos}
Para mejorar la generalización, se aplica aumento de datos a las imágenes antes de extraer parches. Esto puede incluir volteo horizontal y variaciones de intensidad (brillo/contraste).

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\columnwidth]{Figures/fig_data_augmentation.png}
    \caption{Ejemplos de aumento de datos: original, volteo horizontal, y variación de contraste/brillo.}
    \label{fig:data_augmentation_examples_simplified}
\end{figure}

\subsection{Discretización de Coeficientes $b_k$}
Como las CNNs se usan como clasificadores, el valor continuo del coeficiente $b_k$ se discretiza en $B$ `bins` o categorías. El rango de $b_k$ se divide en $B$ intervalos, y la etiqueta del bin correspondiente se usa para el entrenamiento.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{Figures/fig_b_discretization.png}
    \caption{Discretización de un coeficiente $b_k$ en $B$ bins para la clasificación.}
    \label{fig:bk_discretization_simplified}
\end{figure}