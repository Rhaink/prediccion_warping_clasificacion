\chapter{Metodología}
\label{cap:metodologia}

\section{Visión General}
\label{sec:vis_general}

El objetivo central de esta metodología es desarrollar un sistema computacional capaz de localizar puntos relevantes en imágenes radiográficas de tórax. Estos puntos, denominados puntos de referencia o landmarks, son cruciales para el análisis cuantitativo de la forma y el tamaño de estructuras pulmonares.

La estrategia para alcanzar este objetivo se basa en el aprendizaje supervisado. Se utiliza un conjunto de datos donde manualmente se ha identificado y marcado la ubicación de estos landmarks en mil radiografías.

El proceso se compone de las siguientes etapas:

\begin{enumerate}
\item \textbf{Acondicionamiento de los Datos de Entrenamiento:} Se procesan las radiografías y las anotaciones manuales. Este paso incluye la normalización del tamaño de las imágenes y la alineación espacial de los conjuntos de landmarks. Dicha alineación asegura que las variaciones de forma entre las estructuras se puedan comparar de manera consistente, mitigando el efecto de diferencias en la pose o la escala.
\item \textbf{Definición de Regiones de Búsqueda:} Con base en la distribución espacial observada de los landmarks en el conjunto de entrenamiento, se establecen regiones de búsqueda delimitadas para cada landmark en nuevas imágenes. Estas regiones restringen el área donde el sistema intentará localizar el landmark, optimizando la eficiencia del proceso.
\item \textbf{Modelado de la Apariencia Local:} Para cada landmark, se extraen subimágenes (parches) centradas en su ubicación a través de todo el conjunto de entrenamiento. Estos parches representan la variabilidad visual típica de la región anatómica circundante a cada landmark. Mediante técnicas de análisis estadístico, se construyen modelos de apariencia que capturan los patrones visuales característicos y las variaciones comunes para cada tipo de landmark.
\item \textbf{Proceso de Búsqueda y Coincidencia:} Al analizar una nueva radiografía, el sistema examina múltiples ubicaciones candidatas dentro de la región de búsqueda definida para cada landmark. En cada ubicación candidata, se extrae un parche de imagen y se compara su apariencia con el modelo de apariencia previamente aprendido para ese landmark específico.
\item \textbf{Estimación de la Posición Óptima:} El sistema cuantifica la similitud entre cada parche candidato y el modelo de apariencia correspondiente mediante una métrica de error. La posición del parche que minimiza este error, indicando la mayor semejanza con la apariencia característica del landmark, se selecciona como la ubicación predicha para dicho punto.
\end{enumerate}

Las secciones siguientes de este capítulo detallan la formulación matemática y los algoritmos específicos que implementan cada una de estas etapas. Se abordará la representación numérica de imágenes y landmarks, los métodos de alineación basados en transformaciones geométricas, la construcción de modelos de apariencia mediante análisis de componentes principales, y la optimización para la localización de landmarks a través de la minimización de una función de error de reconstrucción. El principio en sí es utilizar datos de ejemplo y herramientas matemáticas para desarrollar un sistema capaz de identificar y localizar puntos de referencia clave en imágenes radiográficas de tórax.

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=1\linewidth]{Figures/diagrama_bloques_metodologia.png}
    \caption{Diagrama de bloques de la visión general de la metodología}
    \label{fig:diagrama_bloques_metodologia}
\end{figure}

\section{Adquisición y Preprocesamiento de Datos Anotados}

La metodología se fundamenta en un conjunto de imágenes de radiografías de tórax que contienen anotaciones manuales de puntos de referencia. La preparación de estos datos comprende las siguientes etapas:

\subsection{Selección y Organización del Conjunto de Datos}
Se selecciona un subconjunto de imágenes provenientes del conjunto de datos original. Cada imagen se asocia con un identificador único y una categoría (ej., COVID, Normal). Dicha información se estructura en un archivo de índice.

\subsection{Etiquetado Manual Asistido de Puntos de Referencia}
El proceso de anotación implica la definición interactiva y secuencial por parte de un observador de 15 puntos de referencia anatómicos, denotados como $\mathbf{p}_i = (x_i, y_i) \in \mathbb{Z}^2$ para $i=0, \dots, 14$, sobre la imagen visualizada. Los dos primeros puntos, $\mathbf{p}_0$ y $\mathbf{p}_1$, definen una \textit{Línea Principal}. Los 13 puntos restantes se derivan computacionalmente a partir de la configuración geométrica definida por $\mathbf{p}_0$ y $\mathbf{p}_1$.

La \textit{Línea Principal}, $\mathcal{L}_{main}$, se define como la recta que contiene los puntos $\mathbf{p}_0 = (x_0, y_0)$ y $\mathbf{p}_1 = (x_1, y_1)$. Su pendiente, $m$, se determina mediante:
$$ m = \begin{cases} \frac{y_1 - y_0}{x_1 - x_0} & \text{si } x_1 \neq x_0 \\ \infty & \text{si } x_1 = x_0 \end{cases} $$
Consecuentemente, la pendiente $m_{\perp}$ de cualquier recta perpendicular a $\mathcal{L}_{main}$ se calcula como:
$$ m_{\perp} = \begin{cases} -1/m & \text{si } m \neq 0, \infty \\ \infty & \text{si } m = 0 \\ 0 & \text{si } m = \infty \end{cases} $$

Los puntos $\mathbf{p}_8, \mathbf{p}_9,$ y $\mathbf{p}_{10}$ se establecen como puntos intermedios sobre el segmento rectilíneo $[\mathbf{p}_0, \mathbf{p}_1]$ a través de interpolación lineal:
$$ \mathbf{p}_i = \mathbf{p}_0 + c_i (\mathbf{p}_1 - \mathbf{p}_0), \quad i \in \{8, 9, 10\} $$
donde los factores de interpolación $c_8 = 1/4$, $c_9 = 1/2$, y $c_{10} = 3/4$ corresponden al primer cuarto, punto medio y tercer cuarto del segmento, respectivamente. Las coordenadas resultantes se redondean al entero más cercano.

Los puntos de referencia restantes se generan en pares. Cada par se sitúa a una distancia predefinida de uno de los puntos base ($\mathbf{p}_0, \mathbf{p}_1, \mathbf{p}_8, \mathbf{p}_9, \mathbf{p}_{10}$) a lo largo de la recta perpendicular a $\mathcal{L}_{main}$ que pasa por dicho punto base. Dado un punto base $\mathbf{p}_{ba} = (x_{ba}, y_{ba})$ sobre $\mathcal{L}_{main}$ y una distancia de separación $d$, las coordenadas de los dos puntos $\mathbf{q}_a$ y $\mathbf{q}_b$, situados simétricamente a lo largo de la perpendicular, se calculan como:\\
\\
Si $m_{\perp} \neq \infty$ y $m_{\perp} \neq 0$:
$$ x_{a,b} = x_{ba} \pm \frac{d}{\sqrt{1 + m_{\perp}^2}}, \quad y_{a,b} = y_{ba} + m_{\perp}(x_{a,b} - x_{ba}) $$
Si $m_{\perp} = \infty$ (Línea Principal horizontal):
$$ x_{a,b} = x_{ba}, \quad y_{a,b} = y_{ba} \pm d $$
Si $m_{\perp} = 0$ (Línea Principal vertical):
$$ x_{a,b} = x_{ba} \pm d, \quad y_{a,b} = y_{ba} $$
Las coordenadas resultantes se redondean al entero más cercano.

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=0.5\linewidth]{Figures/etiquetado_puntos.png}
    \caption{Puntos $\mathbf{q}_a$ y $\mathbf{q}_b$ para cada punto base $\mathbf{p}_0, \mathbf{p}_1, \mathbf{p}_8, \mathbf{p}_9, \mathbf{p}_{10}$}
    \label{fig:etiqueda_manual_puntos}
\end{figure}

% Se contempla un caso particular cuando la Línea Principal $\mathcal{L}_{main}$ es vertical (i.e., $x_0 = x_1$). En esta situación, los puntos intermedios sobre $\mathcal{L}_{main}$ se determinan únicamente mediante interpolación de sus coordenadas $y$. Los puntos perpendiculares, que en este escenario son horizontales, se generan utilizando coordenadas $x$ preestablecidas (0, 16, 48, 64) y coordenadas $y$ idénticas a las de sus respectivos puntos base sobre $\mathcal{L}_{main}$.

Se permite al observador realizar un ajuste fino de la posición horizontal de un subconjunto específico de puntos (índices 2-7 y 11-14). Si un punto $\mathbf{p}_i = (x_i, y_i)$ es desplazado horizontalmente por una cantidad $\Delta x$, su nueva coordenada $x'_i$ es $x_i + \Delta x$. La coordenada $y'_i$ correspondiente se recalcula para asegurar que el punto ajustado $\mathbf{p}'_i = (x'_i, y'_i)$ permanezca sobre la línea perpendicular original a $\mathcal{L}_{main}$ que contiene al punto de referencia original $\mathbf{p}_{ref} = (x_{ref}, y_{ref})$ en $\mathcal{L}_{main}$. \\
Esta se calcula como:
$$ y'_i = \text{round}(m_{\perp}(x'_i - x_{ref}) + y_{ref}) $$
donde $m_{\perp}$ es la pendiente de la línea perpendicular asociada al punto $\mathbf{p}_i$.

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=0.5\linewidth]{Figures/etiquetado.png}
    \caption{Etiquetado manual asisitido de puntos de referencia}
    \label{fig:etiqueda_manual}
\end{figure}

\subsection{Transformación de Coordenadas para Almacenamiento}
Las coordenadas de los puntos de referencia, inicialmente definidas en la resolución de visualización $D_v \times D_v$ (ej., $640 \times 640$ píxeles), se transforman para adecuarse a múltiples resoluciones objetivo $R_t \times R_t$ (ej., $\{64 \times 64, 128 \times 128, 256 \times 256\}$ píxeles). Para una coordenada $c$ (sea $x$ o $y$), su valor escalado $c_{escalada}$ para una resolución objetivo $R_t$ se calcula mediante:
$$ c_{escalada} = \max\left(0, \min\left(\text{round}\left(c \cdot \frac{R_t}{D_v}\right), R_t-1\right)\right) $$
Este cálculo implica la aplicación de un factor de escala $S = R_t / D_v$, el redondeo al entero más próximo, y una operación de acotación al intervalo $[0, R_t-1]$. Esta última garantiza que las coordenadas transformadas se encuentren dentro de los límites de la imagen reescalada.

\section{Alineamiento de Formas}

Para mitigar la variabilidad inducida por transformaciones globales de traslación, rotación y escala en los conjuntos de puntos de referencia anotados, se implementa un proceso de alineamiento de formas. Este proceso se basa en el Análisis Generalizado de Procrustes (GPA).

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=0.6\linewidth]{Figures/gpa_step1_original.png}
    \caption{Ejemplo con 4 landmarks formando cuadriláteros}
    \label{fig:gpa_step1}
\end{figure}

Dado un conjunto de $N$ configuraciones de puntos (formas), donde cada forma $k$ se representa por una matriz $\mathbf{S}_k \in \mathbb{R}^{15 \times 2}$ que contiene las coordenadas $(x, y)$ de sus 15 puntos de referencia, el GPA busca alinear iterativamente estas formas a una forma media.

El algoritmo GPA se desarrolla en las siguientes etapas:

\begin{enumerate}
    \item \textbf{Preprocesamiento de Formas Individuales:} Cada forma $\mathbf{S}_k$ se somete a un preprocesamiento inicial.
    \begin{enumerate}
        \item Centrado: Se calcula el centroide de la forma $\mathbf{S}_k$:
        \[
            \overline{\mathbf{s}}_k = \frac{1}{15} \sum_{j=1}^{15} \mathbf{p}_{kj}
        \]
        La forma se centra restando su centroide:
        \[
            \mathbf{S}'_k = \mathbf{S}_k - \mathbf{1}\overline{\mathbf{s}}_k^T
        \]
        donde $\mathbf{1}$ es un vector columna de unos.
        \item Normalización de Escala: La escala de la forma centrada $\mathbf{S}'_k$ se normaliza dividiendo por su norma de Frobenius (también conocida como Tamaño Centroide):
        \[
            \mathbf{S}''_k = \frac{\mathbf{S}'_k}{\|\mathbf{S}'_k\|_F}
        \]
    \end{enumerate}

    \begin{figure}[htbp] 
    \centering
    \includegraphics[width=0.6\linewidth]{Figures/gpa_step2_centered.png}
    \caption{Ejemplo con 4 landmarks centrados}
    \label{fig:gpa_step2}
    \end{figure}

    \item \textbf{Inicialización de la Forma Media:} Se selecciona una de las formas preprocesadas (e.g., $\mathbf{S}''_1$) como la estimación inicial de la forma media, denotada como $\mathbf{M}^{(0)}$.
    
    \item \textbf{Proceso Iterativo de Alineamiento (GPA):} Se ejecuta un procedimiento iterativo, indexado por $t=0, 1, \dots$, hasta alcanzar un criterio de convergencia.
    \begin{enumerate}
        \item \textbf{Alineamiento a la Forma Media Actual:} Cada forma preprocesada $\mathbf{S}''_k$ se alinea a la forma media actual $\mathbf{M}^{(t)}$. Esto implica encontrar la matriz de rotación óptima $\mathbf{R}_k$ que minimiza la suma de las distancias euclidianas al cuadrado entre los puntos correspondientes de $\mathbf{S}''_k \mathbf{R}_k$ y $\mathbf{M}^{(t)}$. Este problema es equivalente a minimizar la siguiente expresión:
        \[
            \|\mathbf{S}''_k \mathbf{R}_k - \mathbf{M}^{(t)}\|_F^2
        \]
        La solución para $\mathbf{R}_k$ se obtiene a partir de la Descomposición en Valores Singulares (SVD) de la matriz de covarianza cruzada $\mathbf{C}_k = (\mathbf{S}''_k)^T \mathbf{M}^{(t)}$. Si la SVD de $\mathbf{C}_k$ es $\mathbf{U}_k \boldsymbol{\Sigma}_k \mathbf{V}_k^T$, entonces la matriz de rotación óptima es:
        \[
            \mathbf{R}_k = \mathbf{V}_k \mathbf{U}_k^T
        \]
        Se aplica una corrección a $\mathbf{R}_k$ si su determinante es negativo, para asegurar que representa una rotación propia. Las formas alineadas en la iteración $t$ son $\tilde{\mathbf{S}}''_k = \mathbf{S}''_k \mathbf{R}_k$.

        \item \textbf{Actualización de la Forma Media:} Se calcula una nueva forma media $\mathbf{M}_{\text{raw}}^{(t+1)}$ promediando las coordenadas de todas las formas alineadas $\tilde{\mathbf{S}}''_k$:
        \[
            \mathbf{M}_{\text{raw}}^{(t+1)} = \frac{1}{N} \sum_{k=1}^N \tilde{\mathbf{S}}''_k
        \]
        \item \textbf{Normalización de la Nueva Forma Media:} La forma media $\mathbf{M}_{\text{raw}}^{(t+1)}$ se centra y se normaliza a escala unitaria (siguiendo el procedimiento del paso 1) para obtener la forma media actualizada $\mathbf{M}^{(t+1)}$.
    \end{enumerate}

            \begin{figure}[htbp] 
    \centering
    \includegraphics[width=0.6\linewidth]{Figures/gpa_step3_normalized.png}
    \caption{Ejemplo con 4 landmarks normalizados}
    \label{fig:gpa_step3}
    \end{figure}
    
    \item \textbf{Criterio de Convergencia:} El proceso iterativo concluye cuando la diferencia entre formas medias consecutivas, cuantificada mediante la norma de Frobenius, es inferior a un umbral de tolerancia predefinido $\epsilon$:
    \[
        \|\mathbf{M}^{(t+1)} - \mathbf{M}^{(t)}\|_F < \epsilon
    \]
\end{enumerate}
Las formas resultantes del GPA están centradas en el origen y poseen una escala normalizada (unitaria). Para alinear las imágenes originales correspondientes a estas formas normalizadas, se estima una transformación de similitud $\mathbf{T}_k$ para cada imagen. Esta transformación, que incluye parámetros de escala, rotación y traslación, mapea los puntos de referencia originales de la imagen $k$ a sus correspondientes puntos alineados por GPA. Dicha transformación $\mathbf{T}_k$ puede estimarse utilizando una transformación afín 2D. Finalmente, la transformación $\mathbf{T}_k$ estimada se aplica a la imagen original para generar la imagen alineada.

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=0.6\linewidth]{Figures/gpa_step4_aligned.png}
    \caption{Ejemplo con 4 landmarks alineados y su forma media}
    \label{fig:gpa_step4}
\end{figure}

\section{Extracción de Regiones de Búsqueda y Análisis de Templates}
\label{sec:extraccion_region}

Esta etapa define las áreas en las imágenes donde se buscarán los puntos anatómicos y los parámetros para extraer parches de apariencia.

\subsection{Extracción de Regiones de Búsqueda}
Para cada punto de referencia $j \in \{0, \dots, 14\}$, se analiza la distribución espacial de sus coordenadas $(x_{ij}, y_{ij})$ en el conjunto de entrenamiento alineado. Estas coordenadas, que pueden ser de punto flotante debido a los calculos GPA, se convierten a enteros y se aplica \textit{clamping} al rango $[0, 63]$ para asegurar su correspondencia con una cuadrícula de $64 \times 64$ píxeles. Se construye un histograma 2D $H_j$ de $64 \times 64$ donde $H_j[y, x]$ cuenta el número de veces que el punto $j$ aparece en la ubicación $(x, y)$ después del clamping. Se calcula la caja delimitadora (bounding box) más pequeña que contiene todas las ubicaciones con $H_j[y, x] > 0$. Esta caja, definida por $(\min\_x_j, \max\_x_j, \min\_y_j, \max\_y_j)$, establece la región de búsqueda rectangular $\mathcal{R}_j$ para el punto $j$.

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=0.7\linewidth]{Figures/landmark_1_search_zone.png}
    \caption{Región de búsqueda para landmark 1}
    \label{fig:landmar_1_search_zone}
\end{figure}

\subsection{Análisis de Templates de Recorte}
Se analizan las regiones de búsqueda $\mathcal{R}_j$ para derivar parámetros de un template de recorte rectangular para cada punto $j$. Para la caja delimitadora $(\min\_x_j, \max\_x_j, \min\_y_j, \max\_y_j)$ dentro de una cuadrícula de $64 \times 64$, se calculan las distancias a los bordes de la cuadrícula:
$$ a_j = \min\_y_j \quad (\text{distancia superior}) $$
$$ b_j = 63 - \max\_x_j \quad (\text{distancia derecha}) $$
$$ c_j = 63 - \max\_y_j \quad (\text{distancia inferior}) $$
$$ d_j = \min\_x_j \quad (\text{distancia izquierda}) $$

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=0.5\linewidth]{Figures/template1.png}
    \caption{Ejemplo de región de búsqueda mostrando las dimensiones ($a_j$, $b_j$, $c_j$, $d_j$)}
    \label{fig:landmar_1_template_recorte}
\end{figure}

El template de recorte para el punto $j$ se define como un rectángulo cuyas dimensiones son las de la caja delimitadora de la región de búsqueda: 
$$W_{template,j} = (\max\_x_j - \min\_x_j + 1),  H_{template,j} = (\max\_y_j - \min\_y_j + 1)$$
Se identifica un "punto de intersección":  
$$\mathbf{p}_{int,j} = (x_{int,j}, y_{int,j}) = (\min\_x_j, \min\_y_j)$$

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=1\linewidth]{Figures/template_analysis_coord1.png}
    \caption{Análisis template de recorte landmark 1}
    \label{fig:landmar_1_template}
\end{figure}

\section{Recorte de Imágenes para Entrenamiento de Apariencia}

Este procedimiento extrae parches de imágenes, previamente redimensionadas a $64 \times 64$ píxeles, mediante el uso de plantillas y puntos de referencia. El objetivo es generar datos para el entrenamiento de un modelo de apariencia.

Para una imagen $i$ y su $j$-ésimo punto de referencia, se emplea la coordenada de referencia (ground truth) $\mathbf{p}_{lp,ij} = (x_{lp,ij}, y_{lp,ij})$. Los componentes de esta coordenada se convierten a valores enteros y se acotan al rango $[0, 63]$ para que se ajusten a las dimensiones de la imagen.

A cada $j$-ésimo punto de referencia se asocia una plantilla de recorte de dimensiones $W_{\text{template},j} \times H_{\text{template},j}$. Esta plantilla posee un punto de anclaje interno $\mathbf{p}_{\text{int},j} = (x_{\text{int},j}, y_{\text{int},j})$, cuyas coordenadas son relativas a la esquina superior izquierda de la propia plantilla. La esquina superior izquierda de la región de búsqueda (o posición de referencia inicial) para la plantilla del punto $j$ en la imagen se denota como $(\min\_x_j, \min\_y_j)$. En esta configuración, el punto de anclaje $\mathbf{p}_{\text{int},j}$ se proyecta en la imagen en la coordenada $(\min\_x_j + x_{\text{int},j}, \min\_y_j + y_{\text{int},j})$.

El objetivo consiste en alinear esta proyección del punto de anclaje de la plantilla con el punto de referencia $\mathbf{p}_{lp,ij}$ en la imagen. Para lograr esta alineación, se calcula un vector de desplazamiento $(dx_{ij}, dy_{ij})$:
$$ dx_{ij} = x_{lp,ij} - (\min\_x_j + x_{\text{int},j}) $$
$$ dy_{ij} = y_{lp,ij} - (\min\_y_j + y_{\text{int},j}) $$
Posteriormente, se determinan las coordenadas de la esquina superior izquierda de la ventana de recorte final, $(\text{final\_min\_x}_{ij}, \text{final\_min\_y}_{ij})$. Estas se obtienen al aplicar el desplazamiento $(dx_{ij}, dy_{ij})$ a la posición de referencia inicial de la plantilla $(\min\_x_j, \min\_y_j)$. Adicionalmente, se aplica una operación de acotación para asegurar que la ventana de recorte se encuentre completamente contenida dentro de los límites $[0, 63]$ de la imagen:
$$ \text{final\_min\_x}_{ij} = \max(0, \min(\min\_x_j + dx_{ij}, 63 - W_{\text{template},j} + 1)) $$
$$ \text{final\_min\_y}_{ij} = \max(0, \min(\min\_y_j + dy_{ij}, 63 - H_{\text{template},j} + 1)) $$

\begin{figure}[htbp] 
\centering
\includegraphics[width=0.6\linewidth]{Figures/recorte.png}
\caption{Ejemplo de extracción del parche donde el punto verde ($\mathbf{p}_{\text{int},j}$) es alineado con el punto rojo ($\mathbf{p}_{lp,ij}$).}
\label{fig:extraccion}
\end{figure}

Finalmente, se extrae el parche de apariencia $\mathbf{P}_{ij}$ recortando la imagen en la posición $(\text{final\_min\_x}_{ij}, \text{final\_min\_y}_{ij})$ con las dimensiones $W_{\text{template},j} \times H_{\text{template},j}$ de la plantilla.

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=0.8\linewidth]{Figures/diagrama_parches.png}
    \caption{Parches de 39x34 pixeles extraidos del conjunto de entrenamiento para la landmark 1}
    \label{fig:landmar_1_parches}
\end{figure}

\section{Modelos de Apariencia (Eigenpatches)}

Para cada punto anatómico $j$, se entrena un modelo de apariencia utilizando el conjunto de parches recortados $\{\mathbf{P}_{ij}\}_{i=1}^N$, donde $N$ es el número total de imágenes de entrenamiento. Cada parche $\mathbf{P}_{ij}$, de dimensiones $H \times W$ píxeles, se vectoriza transformándolo en un vector columna $\mathbf{x}_{ij} \in \mathbb{R}^{D}$, donde $D = HW$ representa la dimensionalidad del espacio de los parches.

\subsection{Análisis de Componentes Principales (PCA)}
El Análisis de Componentes Principales (PCA) se aplica al conjunto de parches vectorizados $\{\mathbf{x}_{ij}\}_{i=1}^N$ correspondientes a un punto anatómico $j$. El objetivo de PCA es identificar un subespacio lineal de menor dimensión que capture la máxima varianza presente en los datos originales. Este proceso se desglosa en los siguientes pasos:

\begin{enumerate}
    \item \textbf{Cálculo de la media muestral:} Se determina el parche promedio $\mean{\mathbf{x}}_j$ para el punto anatómico $j$:
    $$ \mean{\mathbf{x}}_j = \frac{1}{N} \sum_{i=1}^N \mathbf{x}_{ij} $$
    Esta media representa la apariencia central de los parches observados.

    \item \textbf{Centrado de los datos:} Cada parche vectorizado $\mathbf{x}_{ij}$ se centra restándole la media muestral $\mean{\mathbf{x}}_j$. Estos vectores centrados se organizan como las filas de una matriz de datos centrados $\mathbf{X}_{c,j} \in \mathbb{R}^{N \times D}$:
    $$ \mathbf{X}_{c,j} = [\mathbf{x}_{1j} - \mean{\mathbf{x}}_j, \dots, \mathbf{x}_{Nj} - \mean{\mathbf{x}}_j]^T $$
    Este paso asegura que la varianza se calcule respecto al centro de la distribución de los datos.

    \item \textbf{Cálculo de la matriz de covarianza:} Se estima la matriz de covarianza muestral $\mathbf{C}_j \in \mathbb{R}^{D \times D}$ a partir de los datos centrados:
    $$ \mathbf{C}_j = \frac{1}{N-1} \mathbf{X}_{c,j}^T \mathbf{X}_{c,j} $$
    La matriz de covarianza codifica las interrelaciones y variaciones entre los diferentes píxeles de los parches.

    \item \textbf{Resolución del problema de valores propios:} Se calculan los valores propios $\lambda_{jk}$ y los vectores propios $\mathbf{v}_{jk}$ de la matriz de covarianza $\mathbf{C}_j$:
    $$ \mathbf{C}_j\mathbf{v}_{jk} = \lambda_{jk} \mathbf{v}_{jk}, \quad \text{para } k=1, \dots, D $$
    Los vectores propios indican las direcciones de máxima varianza en el espacio de los datos, y los valores propios cuantifican dicha varianza.

    \item \textbf{Selección de componentes principales:} Se ordenan los vectores propios según sus valores propios correspondientes en orden descendente. Se seleccionan los primeros $m_j$ vectores propios (componentes principales), $\mathbf{v}_{j1}, \dots, \mathbf{v}_{jm_j}$, que se utilizan para formar las columnas de la matriz de proyección $\mathbf{V}_j = [\mathbf{v}_{j1}, \dots, \mathbf{v}_{jm_j}] \in \mathbb{R}^{D \times m_j}$. El número de componentes $m_j$ (donde $m_j \ll D$) se elige típicamente para retener un porcentaje predefinido de la varianza total de los datos (p. ej., 95\%). Esta selección permite una representación compacta de la variabilidad principal de la apariencia.
\end{enumerate}

\subsection{Extraccion de Eigenpatches}

Una vez entrenado el modelo PCA para el punto $j$, un nuevo parche vectorizado $\mathbf{x}$ (no necesariamente del conjunto de entrenamiento) se puede proyectar al subespacio de menor dimensión $m_j$. Para ello, primero se centra el parche $\mathbf{x}$ utilizando la media $\mean{\mathbf{x}}_j$ calculada durante el entrenamiento, y luego se multiplica por la transpuesta de la matriz de proyección $\mathbf{V}_j$:
$$ \boldsymbol{\omega} = \mathbf{V}_j^T (\mathbf{x} - \mean{\mathbf{x}}_j) $$
El vector resultante $\boldsymbol{\omega} \in \mathbb{R}^{m_j}$ contiene los coeficientes o pesos que representan al parche $\mathbf{x}$ en el subespacio PCA.

Es posible reconstruir una aproximación $\hat{\mathbf{x}}$ del parche original $\mathbf{x}$ a partir de su representación en el subespacio PCA $\boldsymbol{\omega}$:
$$ \hat{\mathbf{x}} = \mathbf{V}_j\boldsymbol{\omega} + \mean{\mathbf{x}}_j $$
Esta reconstrucción $\hat{\mathbf{x}} \in \mathbb{R}^D$ reside en el espacio original de los parches y representa la porción de $\mathbf{x}$ que puede ser explicada por los $m_j$ componentes principales seleccionados.

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=1\linewidth]{Figures/coord1_eigenfaces.png}
    \caption{Visualización conceptual de la implementación de PCA y Eigenpatches para la landmark 1. Muestra el ''parche medio" ($\mean{\mathbf{x}}$ reformado) y los primeros componentes principales ($\mathbf{v}_k$ reformados a la dimensión del parche) que capturan los modos de variación en la apariencia de los parches de entrenamiento.}
    \label{fig:pca_eigenfaces}
\end{figure}

\section{Predicción de Coordenadas en Imágenes de Prueba}

Para predecir la ubicación de un punto anatómico $j$ en una nueva imagen de prueba $\mathbf{I}_{test}$ (redimensionada a $64 \times 64$), se utiliza el modelo de apariencia $\mathcal{M}_j$ entrenado y la región de búsqueda $\mathcal{R}_j$.

\begin{enumerate}
    \item \textbf{Búsqueda en Región Definida:} Se itera sobre cada punto candidato $(y_c, x_c)$ dentro de la región de búsqueda $\mathcal{R}_j$.
    \item \textbf{Extracción de Parche Candidato:} Para cada $(y_c, x_c)$, se calcula la esquina superior izquierda $(y_{tl}, x_{tl})$ de un parche $\mathbf{P}_{c}$ de tamaño $W_{template,j} \times H_{template,j}$, de manera que el punto de intersección $\mathbf{p}_{int,j}$ del template se alinee con $(y_c, x_c)$. El parche $\mathbf{P}_{c}$ se extrae de $\mathbf{I}_{test}$.
    \item \textbf{Aplicación del Modelo y Cálculo de Error:} El parche extraído $\mathbf{P}_{c}$ se vectoriza a $\mathbf{x}_c$ y se procesa a través del modelo $\mathcal{M}_j$ (PCA). Se calcula el error de reconstrucción $E(\mathbf{x}_c)$ entre el parche original y su reconstrucción $\hat{\mathbf{x}}_c$ desde el subespacio del modelo. La métrica de error utilizada es la norma L2 (distancia euclidiana):
    $$ E_{L2}(\mathbf{x}_c) = \vectornorm{\mathbf{x}_c - \hat{\mathbf{x}}_c}_2 = \sqrt{\sum_{k=1}^D (x_{c,k} - \hat{x}_{c,k})^2} $$
    donde $D$ es el número de píxeles en el parche.
    \item \textbf{Selección del Punto Óptimo:} El punto candidato $(y_c, x_c)$ que minimiza el error de reconstrucción $E(\mathbf{x}_c)$ se considera la ubicación predicha $\hat{\mathbf{p}}_j$ del punto anatómico $j$.
\end{enumerate}

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=1\linewidth]{Figures/coord1_iteration_00244.png}
    \caption{Visualización del proceso de iteración de predicción para el landmark 1.}
    \label{fig:prediccion_1}
\end{figure}

% \section{Conclusiones Metodología}

% Esta metodología ha cumplido con el objetivo de sentar las bases del proceso de investigación realizado hasta el momento y da las herramientas necesarias para poder profundizar en la investigación de los temas analizados hasta este momento. a continuacion se desarrolla la metodologia desarrolada para resolver el problema de que se necesita un metodo de extraccion de características robusto para combatir las variabilidades inherentes del dataset de las radiografias de torax que la metodologia actual no logro capturar adecuadamente con un rendimiento no óptimo, esto puede ser mediante el aumento de datos, uso de metodos mas vanzados como emtodods de apariencia activa, o forma activa, redes profundas o redes convolucionales,entre otros, este proceso que se ha desarrolado se basa en el paper  [A Generic Approach to Lung Field Segmentation from Chest Radiographs using Deep Space and Shape Learning] el cual sirvio de base para continuar la investigacion y experimentacion, se buscaba replicar el metodo propuesto en el paper para comprender sus diferentes metodos utilizados ya que sus condiciones iniciales eran muy similares al de esta investigación, se logro replicar el paper pero los resultados no fueron optimos debido a diferencias en las condiciones inciales, principalmente que el dataset usado en el metodo del paper usa imagenes de 2048x2048 pixeles, imagenes con una alta definicion y gran contenido de informacion diferente al dataset de esta investigacion con caracteristicas de 299x299 pixeles, la disminucion de informacion y detalle de la simagenes de este dataset no permitieron que se lograra una correcta extraccion de caractyeristicas y por lo tanto la prediccion no fue la deseable, se continuo con la experimentacion y se decidio experiemntar con adaptar el trabajo realizado para que usara redes convolucionales para la extraccion y prediccion de caractersiticas ya que las redes convolucionales son fuertes opciones para trabajar con imagenes pequeñas con pocos detalles, se experimento con diferentes arquitecturas basandose en la investigacion de las redes convolucionales mas comunes y sencillas y se experimento con diferentes parametros como batches, learning rate, tamaños de parches, etc hasta que se logro obtener resultados deseables con predicciones lo suficientemente cercanas a las ground truth. se expĺica la metodologia de manera superficial ya que aun falta mayor profundización en los conceptos clave que se tratan y además aún no se ha terminado de decidir si esta metodologia junto a sus resultados serán de utilidad para solventar las necesidades del proceso de investigación que se esta realizando en esta tesis.

\section{Expansión Estadística de Histograma Asimétrico}

Las imágenes radiográficas de tórax típicamente muestran una distribución de intensidades no uniforme, con una tendencia hacia los tonos más oscuros debido a las áreas oscuras de aire en los pulmones. Esta característica resulta en histogramas que son notablemente asimétricos, con una forma característica como se muestra en la Figura 3-8, donde aparece un pico angosto a extrema la izquierda, siguiendo una zona larga y de poca amplitud que crece hasta un máximo prominente a la derecha.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/histograma1.png}
    \caption{Visualización en diferentes imágenes de la forma característica de los histogramas en radiografías de tórax}
    \label{fig:enter-label11}
\end{figure}

La expansión del histograma tendría la ventaja de no cambiar las proporciones de zonas blancas y oscuras en la imagen. Sin embargo, la utilización de un mínimo global y de un máximo global puede hacer que el ajuste falle cuando hay presencia de algunos pixeles espurios contaminando la imagen. Por esta última razón, sería más razonable calcular un mínimo promedio y un máximo promedio de los niveles de gris de la imagen. La desviación estándar puede ser útil para esto. No obstante, y dado que los histogramas de este tipo de imágenes son asimétricos como lo muestra la Figura 3-8, utilizar alguna proporción de la desviación estándar tanto hacia arriba de la media como hacia debajo de la media para obtener el máximo y el mínimo tampoco resultaría adecuado, pues en muchas imágenes el mínimo calculado de esta forma estaría cercano al mínimo absoluto pero el máximo podría quedar muy por arriba del máximo absoluto, o bien al revés (Figura 3-9). 

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/imagen22.png}
    \caption{ Ilustración en diferentes imágenes del máximo y mínimo estadístico, se puede observar que, al usar estos límites basados en 1.5 veces la desviación estándar, se mejora la representación del rango de intensidades, esto demuestra que si usamos la desviación común puede ser que quede bien hacía arriba de la desviación estándar, pero se encuentren conflictos hacia debajo de la desviación estándar, por ello se debe usar una desviación asimétrica y poder obtener así los máximos y mínimos estadísticos que se adapten mejor a lo necesitado}
    \label{fig:sahs_max_min_estadistico}
\end{figure}

\subsection{Cálculo de intensidades y normalización}
El proceso de normalización de intensidades se realiza mediante las siguientes ecuaciones:

\subsubsection{Media de intensidades}
Sea $I(x, y)$ la imagen de entrada en escala de grises. La media de intensidades $\mu$ se calcula como:

\begin{equation}
\mu = \frac{1}{N} \sum_{x=1}^{n} \sum_{y=1}^{m} I(x, y)
\end{equation}

donde $N = n \times m$ es el número total de píxeles.

\subsubsection{Separación de valores de intensidad}
Los valores de intensidad se dividen en dos conjuntos:

\begin{equation}
A = { I(x, y) \mid I(x, y) > \mu }
\end{equation}

\begin{equation}
B = { I(x, y) \mid I(x, y) \leq \mu }
\end{equation}

\subsubsection{Desviaciones estándar asimétricas}
\begin{equation}
\sigma_+ = \sqrt{ \frac{1}{\#A} \sum_{I(x, y) \in A} (I(x, y) - \mu)^2 }
\end{equation}

\begin{equation}
\sigma_- = \sqrt{ \frac{1}{\#B} \sum_{I(x, y) \in B} (I(x, y) - \mu)^2 }
\end{equation}

\subsubsection{Límites de expansión}
\begin{equation}
u = \mu + c_+ \sigma_+
\end{equation}

\begin{equation}
l = \mu - c_- \sigma_-
\end{equation}

donde $c_+ = 2.5$ y $c_- = 2$.

\subsubsection{Función de mapeo}
La función de mapeo lineal se define como:

\begin{equation}
I'(x, y) = 255 \times \frac{I(x, y) - l}{u - l}
\end{equation}

con las restricciones:
\begin{itemize}
\item Si $I'(x, y) > 255$, entonces $I'(x, y) = 255$
\item Si $I'(x, y) < 0$, entonces $I'(x, y) = 0$
\end{itemize}

Este método además de ser computacionalmente más ligero que CLAHE, ofrece ventajas para el caso específico del tipo de histograma asimétrico típico en esta clase de imágenes radiográficas de tórax. En la Figura 3-10 se muestra que CLAHE enfatiza el ruido en una radiografía sin neumonía, haciendo parecer que pudiera haber lesiones (segundo trío imágenes). En el tercer trío de la misma Figura 3 se ilustra que las regiones claras de una imagen con neumonía podrían ser oscurecidas por CLAHE, no siendo así cuando se usa SAHS. Finalmente, la Figura 3-11 se el ajuste de contraste SAHS para 3 imágenes diferentes.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/imagen33.png}
    \caption{Comparación original, CLAHE y SAHS en una radiografía, mostrando así que CLAHE agrega imperfecciones}
    \label{fig:clahe_vs_sahs_comparison}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/imagen44.png}
    \caption{Comparación de imágenes radiográficas de tórax con neumonía antes y después de aplicar SAHS}
    \label{fig:sahs_pneumonia_examples}
\end{figure}
\subsection{Algoritmo Localizador de Pulmones (ALP)}

Para mejorar la precisión de la clasificación, hemos usado el Algoritmo Localizador de Pulmones (ALP) propuesto en \cite{picazo2023sistema}, que permite extraer o segmentar la región de interés (ROI) pulmonar en las radiografías. El ALP utiliza regresión K-NN para estimar las coordenadas de la ROI en una nueva imagen radiográfica de prueba.

El proceso del ALP se resume en los siguientes pasos:

\begin{enumerate}
    \item \textbf{Identificación de landmarks:} Se definen cuatro puntos clave (Q1, Q2, Q3, Q4) que delimitan la región pulmonar.
    \item \textbf{Regresión K-NN:} Se predicen las coordenadas de estos puntos en la imagen de prueba.
    \item \textbf{Warping:} Se aplica una transformación geométrica para extraer la ROI y normalizarla a una imagen de 256x256 píxeles.
\end{enumerate}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/imagen55.png}
    \caption{Proceso ALP, imágenes de ejemplo con sus regiones de interés ya extraídas en imágenes procesadas con SAHS. Las coordenadas rojas son obtenidas por regresión y las azules se usan en la extracción de la ROI.}
    \label{fig:ALP_process}
\end{figure}

Este enfoque asegura que todas las imágenes procesadas tengan la misma alineación, lo cual mejora la clasificación \cite{Ayala2010, picazo2023sistema}.

\subsection{Integración de Métodos SAHS y ALP}

La combinación de SAHS con ALP proporciona un preprocesamiento robusto para las imágenes radiográficas de tórax:

\begin{enumerate}
    \item \textbf{Mejora de contraste inicial:} Se aplica el método de expansión asimétrica del histograma a la imagen original.
    \item \textbf{Localización pulmonar:} Se utiliza el ALP para extraer y normalizar la ROI.
\end{enumerate}

Este proceso se ilustra en la Figura \ref{fig:SAHS_ALP_comparison}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/imagen66.png}
    \caption{Comparación de una imagen radiográfica de tórax en las diferentes etapas del proceso integrado: original, después de aplicar SAHS, y después de obtener la ROI.}
    \label{fig:SAHS_ALP_comparison}
\end{figure}

\section{Evolución Hacia una Metodología de Segmentación Robusta}
\label{sec:evolucion_metodologia_segmentacion}

La metodología de localización de puntos de referencia previamente establecida proporciona un fundamento esencial para el análisis cuantitativo. Sin embargo, la tarea de segmentar de forma robusta los campos pulmonares, particularmente frente a las variaciones inherentes y la resolución limitada (299x299 píxeles) de nuestro conjunto de datos de radiografías de tórax, exigió la exploración de enfoques más avanzados.

En esta búsqueda, se tomó como referencia el trabajo de \cite{Mansoor2020Generic}, titulado 'A Generic Approach to Lung Field Segmentation from Chest Radiographs using Deep Space and Shape Learning', dada la aparente similitud en los desafíos iniciales. Se emprendió un esfuerzo por comprender y adaptar los métodos propuestos en dicha publicación. No obstante, durante esta fase, se confirmo que la considerable diferencia en la resolución de las imágenes, específicamente, el dataset de referencia empleaba imágenes de alta definición (2048x2048 píxeles), imponía limitaciones significativas. La menor cantidad de información y detalle en nuestras imágenes comprometió la efectividad de una extracción de características directamente análoga a la del paper, resultando en un rendimiento de predicción subóptimo.

Ante este escenario, y reconociendo la necesidad de una estrategia mejor adaptada a las particularidades de nuestro dataset, se procedió a desarrollar una metodología híbrida. Esta nueva aproximación, si bien inspirada por los conceptos del trabajo de referencia, integra de manera prominente Redes Neuronales Convolucionales (CNNs) para la extracción de características y la predicción de parámetros de forma. Se optó por las CNNs debido a su probada capacidad para aprender representaciones robustas a partir de imágenes con menor detalle y resolución. El desarrollo implicó una fase de experimentación con diversas arquitecturas de CNN, ajustando parámetros clave como la tasa de aprendizaje, el tamaño de los lotes (batches) y las dimensiones de los parches de imagen, hasta alcanzar un rendimiento que permitiera predicciones suficientemente precisas en relación con las anotaciones de referencia (ground truth). La siguiente sección detalla esta metodología de segmentación.