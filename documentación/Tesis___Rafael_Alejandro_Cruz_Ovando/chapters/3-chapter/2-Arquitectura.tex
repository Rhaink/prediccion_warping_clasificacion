\section{Arquitectura del Modelo}
\label{sec:arquitectura}

La arquitectura neuronal profunda seleccionada para la tarea de regresión de coordenadas de \textit{landmarks} anatómicos debe balancear múltiples objetivos en tensión: capacidad representacional suficiente para capturar variabilidad anatómica compleja observable en radiografías de tórax de 224$\times$224 píxeles, eficiencia computacional compatible con recursos de \textit{hardware} disponible (GPU con 8GB VRAM), facilidad de entrenamiento mediante \textit{transfer learning} desde \textit{datasets} de imágenes naturales, y arquitectura modular que permita experimentación con componentes intercambiables. La arquitectura implementada se fundamenta en ResNet-18 \cite{He2016}, variante ligera de la familia de Redes Residuales que proporciona profundidad suficiente (18 capas con pesos) para aprendizaje de representaciones jerárquicas complejas sin incurrir en costo computacional prohibitivo de variantes más profundas como ResNet-50 o ResNet-101.

% Como se fundamentó teóricamente en la Sección~\ref{sec:resnet_teoria} del marco teórico, (NOTA: label no existe en Cap 2 actual)
Las conexiones residuales $\mathbf{y} = \mathcal{F}(\mathbf{x}) + \mathbf{x}$ constituyen el mecanismo arquitectural clave que permite entrenamiento efectivo de redes profundas al facilitar flujo directo de gradientes durante retropropagación, evitando problema de desvanecimiento de gradientes que limita profundidad de arquitecturas completamente convolucionales estándar. La arquitectura ResNet-18 específica empleada mantiene estructura de bloques residuales básicos (\textit{basic blocks}) sin cuellos de botella (\textit{bottlenecks}), adecuados para imágenes de resolución moderada donde capacidad representacional de bloques básicos es suficiente y complejidad adicional de bloques con cuello de botella no proporciona beneficio significativo.

\subsection{Backbone ResNet-18: Extractor de Características Visuales}
\label{subsec:backbone_resnet18}

El \textit{backbone} (columna vertebral) del modelo consiste en ResNet-18 preentrenada en ImageNet \cite{Krizhevsky2012}, \textit{dataset} de clasificación de imágenes naturales conteniendo 1.2 millones de imágenes de entrenamiento distribuidas en 1000 categorías de objetos. El preentrenamiento en ImageNet proporciona inicialización de parámetros que codifica características visuales genéricas útiles para múltiples tareas de visión por computadora: detectores de bordes, esquinas y texturas en capas inferiores; detectores de partes de objetos y patrones complejos en capas medias; y representaciones semánticas de alto nivel en capas superiores. Aunque las 1000 categorías de ImageNet no incluyen imágenes médicas, numerosos estudios empíricos demuestran transferibilidad sorprendente de representaciones aprendidas en imágenes naturales a dominio médico \cite{Raghu2019, Tajbakhsh2016}, particularmente cuando el \textit{dataset} médico objetivo es pequeño ($< 10{,}000$ imágenes) y entrenamiento desde inicialización aleatoria resultaría en sobreajuste severo.

La arquitectura ResNet-18 implementa la estructura jerárquica estándar de redes residuales, comenzando con capa convolucional inicial de $7\times7$ con \textit{stride} 2 que reduce resolución espacial de $224\times224$ a $112\times112$ mientras expandiendo canales de 3 (RGB) a 64, seguida de capa de \textit{max pooling} $3\times3$ con \textit{stride} 2 que reduce adicionalmente resolución a $56\times56$, preparando la entrada para los bloques residuales principales. La red procede con cuatro grupos de bloques residuales organizados en \textit{layers} (capas) con profundidad creciente y resolución decreciente:

\textbf{Layer 1:} Dos bloques residuales básicos con 64 canales, resolución espacial $56\times56$. Cada bloque implementa la transformación
\begin{equation}
\mathbf{y} = \text{ReLU}(\text{BN}(\text{Conv}_{3\times3}(\text{ReLU}(\text{BN}(\text{Conv}_{3\times3}(\mathbf{x})))))) + \mathbf{x}
\label{eq:basic_block_resnet18}
\end{equation}
donde BN denota \textit{Batch Normalization} (normalización por lotes) que estandariza activaciones para facilitar entrenamiento \cite{Ioffe2015}, Conv$_{3\times3}$ representa convolución con filtros de $3\times3$, y ReLU es activación \textit{Rectified Linear Unit}. La conexión residual (término $+\mathbf{x}$) permite que el bloque aprenda refinamientos incrementales en lugar de transformación completa, facilitando optimización.

\textbf{Layer 2:} Dos bloques residuales básicos con 128 canales, resolución espacial $28\times28$. El primer bloque de Layer 2 implementa reducción de resolución espacial mediante \textit{stride} 2 en primera convolución y conexión residual con convolución $1\times1$ con \textit{stride} 2 para igualar dimensiones:
\begin{equation}
\mathbf{y} = \text{ReLU}(\text{BN}(\text{Conv}_{3\times3}^{s=2}(\mathbf{x}_1))) + \text{Conv}_{1\times1}^{s=2}(\mathbf{x})
\label{eq:downsample_block}
\end{equation}
donde $s=2$ indica \textit{stride} de 2. Esta arquitectura de reducción progresiva de resolución espacial con expansión de canales implementa jerarquía de representaciones: capas tempranas capturan detalles espaciales finos con pocos canales, capas intermedias representan patrones visuales más abstractos con resolución reducida, y capas finales codifican información semántica de alto nivel en representaciones compactas con muchos canales pero resolución espacial mínima.

\textbf{Layer 3:} Dos bloques residuales básicos con 256 canales, resolución espacial $14\times14$, implementando reducción adicional de resolución mediante mecanismo idéntico a Layer 2.

\textbf{Layer 4:} Dos bloques residuales básicos con 512 canales, resolución espacial $7\times7$. La salida de Layer 4 constituye el mapa de características final del \textit{backbone}, tensor de dimensiones $7\times7\times512$ que codifica representación visual de la imagen de entrada en 512 canales de características con resolución espacial reducida a $7\times7$, reducción de $32\times$ respecto a entrada original de $224\times224$ resultado de cinco operaciones de reducción de resolución (\textit{stride} 2): capa convolucional inicial, \textit{max pooling}, y tres transiciones entre \textit{layers} con \textit{downsampling}.

La arquitectura completa del \textit{backbone} ResNet-18 contiene $|\psi| = 11{,}176{,}512$ parámetros distribuidos en convoluciones, normalizaciones por lotes, y sesgos, constituyendo 96.6\% de los parámetros totales del modelo. Estos parámetros son inicializados con pesos oficiales de PyTorch preentrenados en ImageNet mediante optimización de función de pérdida de clasificación multi-clase sobre 1.2 millones de imágenes durante cientos de épocas, proceso computacionalmente costoso (semanas en GPUs de alto rendimiento) que sería inviable replicar para cada aplicación específica, justificando uso de \textit{transfer learning} que aprovecha este preentrenamiento masivo como inicialización para tareas derivadas.

\subsection{Módulo de Regresión: Mapeo de Características a Coordenadas}
\label{subsec:modulo_regresion}

El módulo de regresión diseñado específicamente para esta tarea mapea el vector de características de 512 dimensiones extraído por el \textit{backbone} a las 30 coordenadas objetivo (15 \textit{landmarks} $\times$ 2 coordenadas por punto). Este módulo reemplaza la capa completamente conectada final de ResNet-18 estándar (originalmente diseñada para clasificación en 1000 categorías) con arquitectura de regresión de tres capas que implementa transformación no lineal progresiva con regularización mediante \textit{dropout} (desactivación estocástica de neuronas durante entrenamiento) para prevenir sobreajuste.

La entrada al módulo de regresión se obtiene mediante \textit{Global Average Pooling} (promediado espacial global) que reduce el mapa de características $7\times7\times512$ a vector de 512 dimensiones mediante promediado sobre dimensiones espaciales:
\begin{equation}
\mathbf{z} = \text{GAP}(\mathbf{F}) = \frac{1}{49} \sum_{i=1}^{7} \sum_{j=1}^{7} \mathbf{F}_{i,j} \in \mathbb{R}^{512}
\label{eq:global_average_pooling}
\end{equation}
donde $\mathbf{F} \in \mathbb{R}^{7\times7\times512}$ es el mapa de características de salida de Layer 4. \textit{Global Average Pooling} constituye alternativa efectiva a capas completamente conectadas tradicionales, reduciendo dramáticamente número de parámetros (49$\times$512 conexiones se reducen a operación libre de parámetros) y proporcionando invarianza a traslaciones espaciales residuales, aunque en este caso la función primaria es dimensional: convertir representación espacial bidimensional a vector unidimensional compatible con capas completamente conectadas subsiguientes.

El módulo de regresión implementa la transformación secuencial:

\textbf{Bloque Completamente Conectado 1:}
\begin{align}
\mathbf{h}_1 &= \text{Dropout}(\mathbf{z}, p=0.5) \label{eq:fc1_dropout} \\
\mathbf{h}_1' &= \mathbf{W}_1 \mathbf{h}_1 + \mathbf{b}_1 \quad \text{donde } \mathbf{W}_1 \in \mathbb{R}^{512\times512}, \mathbf{b}_1 \in \mathbb{R}^{512} \label{eq:fc1_linear} \\
\mathbf{a}_1 &= \text{ReLU}(\mathbf{h}_1') \label{eq:fc1_relu}
\end{align}

La capa completamente conectada 1 mantiene dimensionalidad de 512, permitiendo que la red aprenda representación transformada de características visuales sin reducción prematura de capacidad representacional. \textit{Dropout} con probabilidad $p=0.5$ desactiva aleatoriamente 50\% de las neuronas durante cada iteración de entrenamiento, implementando regularización estocástica que previene co-adaptación de características y mejora generalización \cite{Srivastava2014}. Durante inferencia, \textit{dropout} se desactiva y activaciones se escalan por factor $(1-p)=0.5$ para compensar diferencia entre entrenamiento (50\% neuronas activas en promedio) e inferencia (100\% neuronas activas).

\textbf{Bloque Completamente Conectado 2:}
\begin{align}
\mathbf{h}_2 &= \text{Dropout}(\mathbf{a}_1, p=0.25) \\
\mathbf{h}_2' &= \mathbf{W}_2 \mathbf{h}_2 + \mathbf{b}_2 \quad \text{donde } \mathbf{W}_2 \in \mathbb{R}^{256\times512}, \mathbf{b}_2 \in \mathbb{R}^{256} \\
\mathbf{a}_2 &= \text{ReLU}(\mathbf{h}_2')
\end{align}

La capa completamente conectada 2 reduce dimensionalidad de 512 a 256, comenzando compresión de representación hacia salida de 30 coordenadas. La probabilidad de \textit{dropout} se reduce a $p=0.25$, implementando estrategia de regularización progresivamente decreciente: capas superiores cercanas a características visuales reciben regularización fuerte, capas inferiores cercanas a salida reciben regularización moderada, permitiendo mayor flexibilidad de representación en etapas finales de transformación.

\textbf{Bloque Completamente Conectado 3 (Salida):}
\begin{align}
\mathbf{h}_3 &= \text{Dropout}(\mathbf{a}_2, p=0.125) \\
\mathbf{h}_3' &= \mathbf{W}_3 \mathbf{h}_3 + \mathbf{b}_3 \quad \text{donde } \mathbf{W}_3 \in \mathbb{R}^{30\times256}, \mathbf{b}_3 \in \mathbb{R}^{30} \\
\hat{\mathbf{y}} &= \sigma(\mathbf{h}_3') \label{eq:output_sigmoid}
\end{align}

donde $\sigma(\cdot)$ es la función sigmoide aplicada elemento-a-elemento:
\begin{equation}
\sigma(z) = \frac{1}{1 + e^{-z}} \in (0, 1)
\label{eq:sigmoid}
\end{equation}

La capa completamente conectada 3 proyecta la representación de 256 dimensiones a las 30 coordenadas objetivo. La activación sigmoide final garantiza que todas las coordenadas predichas se encuentren en el rango $(0, 1)$, coincidiendo con el rango de coordenadas \textit{ground truth} normalizadas descrito en la Sección~\ref{sec:pipeline_datos}. La probabilidad de \textit{dropout} en la última capa se reduce a $p=0.125$, aplicando regularización mínima inmediatamente antes de la salida para maximizar expresividad de la predicción final.

El módulo de regresión completo contiene $|\phi| = 262{,}656 + 131{,}328 + 7{,}710 = 401{,}694$ parámetros (excluyendo sesgos en conteo simplificado), correspondiendo al 3.4\% del total de parámetros del modelo. Esta fracción pequeña implica que durante Fase 1 de entrenamiento con \textit{backbone} congelado, solo el 3.4\% de parámetros se optimizan, explicando rapidez de convergencia (aproximadamente 1 minuto para 15 épocas) y memoria GPU limitada requerida.

\subsection{Distribución de Parámetros y Complejidad Computacional}
\label{subsec:distribucion_parametros}

La distribución de parámetros entre componentes arquitecturales informa decisiones sobre estrategia de entrenamiento, particularmente en protocolo de \textit{transfer learning} por fases donde diferentes componentes se optimizan con tasas de aprendizaje diferenciadas o se congelan completamente.

\begin{table}[!ht]
\centering
\caption{Distribución detallada de parámetros entrenables en arquitectura del modelo}
\label{tab:parametros_detallados}
\begin{tabular}{@{}lrr@{}}
\toprule
\textbf{Componente Arquitectural} & \textbf{Número de Parámetros} & \textbf{Porcentaje del Total} \\
\midrule
\multicolumn{3}{l}{\textit{Backbone ResNet-18}} \\
\quad Capa convolucional inicial + BN & 9,472 & 0.08\% \\
\quad Layer 1 (2 bloques, 64 canales) & 147,968 & 1.28\% \\
\quad Layer 2 (2 bloques, 128 canales) & 525,824 & 4.54\% \\
\quad Layer 3 (2 bloques, 256 canales) & 2,099,712 & 18.14\% \\
\quad Layer 4 (2 bloques, 512 canales) & 8,393,728 & 72.50\% \\
\midrule
\textbf{Subtotal Backbone} & \textbf{11,176,512} & \textbf{96.53\%} \\
\midrule
\multicolumn{3}{l}{\textit{Módulo de Regresión}} \\
\quad Capa FC1 (512 $\rightarrow$ 512) & 262,656 & 2.27\% \\
\quad Capa FC2 (512 $\rightarrow$ 256) & 131,328 & 1.13\% \\
\quad Capa FC3 (256 $\rightarrow$ 30) & 7,710 & 0.07\% \\
\midrule
\textbf{Subtotal Módulo Regresión} & \textbf{401,694} & \textbf{3.47\%} \\
\midrule
\textbf{Total Modelo Completo} & \textbf{11,578,206} & \textbf{100.00\%} \\
\bottomrule
\end{tabular}
\end{table}

La Tabla~\ref{tab:parametros_detallados} revela que Layer 4 domina complejidad paramétrica con 72.5\% del total, concentración explicada por número de canales (512) y dos bloques residuales cada uno con múltiples convoluciones de $512\times512$ canales. Esta concentración de parámetros en capas profundas es característica de arquitecturas residuales: las características de alto nivel semántico requieren mayor capacidad representacional que características de bajo nivel (bordes, texturas) que son relativamente universales y compactas.

La complejidad computacional del modelo, medida en operaciones de punto flotante (\textit{FLOPs}), es aproximadamente 1.8 giga-FLOPs por imagen de $224\times224$, cálculo dominado por convoluciones en resoluciones espaciales altas (Layers 1-2) donde aunque número de canales es menor, número de posiciones espaciales es grande (Layer 1: $56\times56 = 3136$ posiciones por canal). En comparación, ResNet-50 requiere aproximadamente 4.1 giga-FLOPs y ResNet-101 requiere 7.8 giga-FLOPs, justificando selección de ResNet-18 como balance entre capacidad y eficiencia para tarea de regresión de coordenadas con \textit{dataset} de tamaño moderado (956 imágenes).

\subsection{Arquitectura Experimental: Integración de Coordinate Attention}
\label{subsec:coordinate_attention}

Como experimento metodológico complementario implementado durante desarrollo del sistema, se evaluó incorporación de mecanismo de atención espacial denominado \textit{Coordinate Attention} \cite{Hou2021}, módulo arquitectural diseñado para mejorar sensibilidad posicional de redes convolucionales mediante descomposición de información espacial en atención horizontal y vertical separadas. La motivación teórica para este experimento surge del reconocimiento que localización precisa de \textit{landmarks} requiere sensibilidad fina a posiciones absolutas en la imagen, aspecto que convoluciones estándar capturan solo implícitamente a través de receptive fields (campos receptivos) que agregan información espacial local sin codificación explícita de coordenadas globales.

El módulo \textit{Coordinate Attention} se inserta entre Layer 4 del \textit{backbone} ResNet-18 y la capa de \textit{Global Average Pooling}, procesando el mapa de características $\mathbf{F} \in \mathbb{R}^{7\times7\times512}$ mediante atención selectiva que amplifica características en posiciones espaciales informativas mientras suprime características en posiciones irrelevantes. El módulo implementa tres operaciones secuenciales:

\textbf{Pooling Direccional:} El mapa de características se agrega separadamente a lo largo de dimensiones horizontal y vertical:
\begin{align}
z^c_h(i) &= \frac{1}{W} \sum_{j=0}^{W-1} F^c(i, j) \quad \text{(pooling horizontal, preserva altura)} \label{eq:coord_attn_h} \\
z^c_w(j) &= \frac{1}{H} \sum_{i=0}^{H-1} F^c(i, j) \quad \text{(pooling vertical, preserva anchura)} \label{eq:coord_attn_w}
\end{align}
donde $H=7$, $W=7$ son dimensiones espaciales, $c$ indexa canales, y las salidas $z_h \in \mathbb{R}^{H\times C}$ y $z_w \in \mathbb{R}^{W\times C}$ codifican perfiles de activación promediados a lo largo de cada fila y columna respectivamente. Esta descomposición direccional captura información posicional sin colapsar completamente estructura espacial como hace \textit{Global Average Pooling} estándar.

\textbf{Codificación Compartida:} Los perfiles direccionales se concatenan y procesan mediante convolución 1D compartida seguida de activación:
\begin{equation}
\mathbf{f} = \text{ReLU}(\text{BN}(\text{Conv}_{1\times1}([\mathbf{z}_h; \mathbf{z}_w])))
\label{eq:coord_attn_shared}
\end{equation}
donde $[\mathbf{z}_h; \mathbf{z}_w]$ denota concatenación y la convolución $1\times1$ reduce canales de 512 a $512/32 = 16$ mediante factor de reducción $r=32$, implementando cuello de botella que fuerza compresión de información posicional en representación compacta.

\textbf{Generación de Atención:} La representación compartida se divide y procesa mediante convoluciones separadas para generar mapas de atención direccionales:
\begin{align}
\mathbf{a}_h &= \sigma(\text{Conv}_{1\times1}(\mathbf{f}_h)) \quad \text{donde } \mathbf{a}_h \in \mathbb{R}^{H\times C} \\
\mathbf{a}_w &= \sigma(\text{Conv}_{1\times1}(\mathbf{f}_w)) \quad \text{donde } \mathbf{a}_w \in \mathbb{R}^{W\times C}
\end{align}
donde $\sigma$ es sigmoide que normaliza atención a $(0,1)$. Los mapas de atención se aplican multiplicativamente al mapa de características original:
\begin{equation}
\mathbf{F}'(i,j,c) = \mathbf{F}(i,j,c) \times \mathbf{a}_h(i,c) \times \mathbf{a}_w(j,c)
\label{eq:coord_attn_apply}
\end{equation}

El modelo con \textit{Coordinate Attention} fue entrenado siguiendo protocolo idéntico a Fase 2 (70 épocas, tasas de aprendizaje diferenciadas, \textit{Wing Loss}), pero los resultados experimentales demostraron que la complejidad arquitectural adicional no proporcionó beneficio medible en métricas de localización. El análisis de estos resultados negativos, detallado en el Capítulo~\ref{cap:resultados}, sugiere que para tarea de regresión de coordenadas con \textit{dataset} de tamaño moderado, la capacidad representacional de ResNet-18 estándar es suficiente y adición de mecanismos de atención introduce riesgo de sobreajuste que contrarresta potenciales beneficios de sensibilidad posicional mejorada. Esta observación es consistente con principio general de parsimonia arquitectural: complejidad adicional solo beneficia cuando capacidad base es insuficiente y datos de entrenamiento son abundantes, condiciones no satisfechas en este trabajo.

La siguiente sección describe el \textit{pipeline} completo de procesamiento de datos que transforma radiografías crudas y coordenadas anotadas en tensores normalizados compatibles con la arquitectura descrita.
