\section{Pipeline de preprocesamiento y aumentación de datos}
\label{sec:pipeline_datos}

La Sección~\ref{sec:arquitectura} especificó la arquitectura neuronal implementada: ResNet-18 preentrenada con módulo de regresión especializado, diseñada para procesar tensores normalizados de dimensión $224 \times 224 \times 3$ con estadísticas específicas de ImageNet. La presente sección describe exhaustivamente el \textit{pipeline} (secuencia de procesamiento) completo que transforma radiografías de tórax en formato digital crudo desde su adquisición clínica hasta tensores adecuadamente normalizados para inferencia mediante la red neuronal, preservando simultáneamente las correspondencias geométricas precisas entre coordenadas de \textit{landmarks} (puntos de referencia anatómicos) en espacio de imagen original y espacio de entrada de la red. Este \textit{pipeline} constituye componente crítico de la metodología: transformaciones geométricas incorrectas o normalizaciones inapropiadas comprometirían irremediablemente la capacidad del modelo para localizar estructuras anatómicas con precisión sub-píxel, independientemente de la sofisticación arquitectural o estrategia de entrenamiento implementadas.

El diseño del \textit{pipeline} de datos enfrenta múltiples restricciones simultáneas que deben reconciliarse cuidadosamente. Primero, compatibilidad con arquitecturas preentrenadas en ImageNet: ResNet-18 estándar fue entrenada sobre $1.3 \times 10^6$ imágenes RGB naturales normalizadas con estadísticas específicas (medias $\mu = [0.485, 0.456, 0.406]$ y desviaciones estándar $\sigma = [0.229, 0.224, 0.225]$ por canal), requiriendo conversión de radiografías monocromáticas a representación pseudocromática y normalización coherente con distribución de activaciones esperada por capas convolucionales iniciales \cite{Krizhevsky2012, Raghu2019}. Segundo, preservación de precisión geométrica: cada transformación espacial aplicada a la imagen (redimensionamiento, rotación, reflexión) debe replicarse matemáticamente sobre coordenadas de \textit{landmarks} mediante transformaciones afines inversas correctamente parametrizadas, garantizando correspondencia exacta entre píxeles de entrada y coordenadas de supervisión durante entrenamiento. Tercero, aumentación de variabilidad sin corrupción anatómica: transformaciones de \textit{data augmentation} (aumentación de datos) deben incrementar robustez del modelo ante variabilidad clínica realista (posicionamiento del paciente, diferencias en técnica radiográfica) sin generar configuraciones anatómicamente imposibles que confundirían el aprendizaje de restricciones geométricas. La estrategia implementada, documentada en esta sección, balancea estas restricciones mediante secuencia cuidadosamente ordenada de transformaciones determinísticas y estocásticas \cite{Shorten2019}.

El \textit{pipeline} se estructura en dos etapas funcionalmente distintas. La etapa de preprocesamiento determinístico aplica transformaciones idénticas a todas las muestras tanto en entrenamiento como en inferencia: conversión de espacio de color, redimensionamiento estandarizado, y normalización según estadísticas de ImageNet. Esta etapa garantiza compatibilidad con representaciones preentrenadas y homogeneidad de entrada. La etapa de aumentación estocástica se aplica exclusivamente durante entrenamiento, introduciendo variabilidad controlada mediante transformaciones geométricas (reflexión horizontal, rotación limitada) y fotométricas (ajustes de brillo y contraste) aplicadas aleatoriamente con probabilidades calibradas. Esta separación permite reproducibilidad perfecta en evaluación y validación mientras maximiza variabilidad durante aprendizaje, siguiendo principios establecidos de regularización mediante transformaciones de datos \cite{Shorten2019, Krizhevsky2012}.


\subsection{Preprocesamiento determinístico}
\label{subsec:preprocesamiento_determinista}

El preprocesamiento determinístico transforma radiografías crudas desde formato de adquisición clínica a representación normalizada esperada por ResNet-18, mediante secuencia de tres operaciones aplicadas consistentemente a cada muestra.

\subsubsection{Conversión de espacio de color}
\label{subsubsec:conversion_color}

Las radiografías digitales de tórax en el conjunto de datos descrito en la Sección~\ref{sec:dataset} se almacenan como imágenes monocromáticas de un solo canal de intensidad, codificando información de transmisión de rayos X en escala de grises de 8 bits ($I \in [0, 255]$). Sin embargo, ResNet-18 preentrenada en ImageNet espera tensores tricromáticos de entrada con tres canales RGB $(R, G, B) \in \mathbb{R}^{224 \times 224 \times 3}$, reflejando la naturaleza de las imágenes fotográficas naturales sobre las cuales fue entrenada. Esta incompatibilidad dimensional requiere conversión explícita del espacio de color monocromático al espacio pseudocromático RGB.

La estrategia de conversión implementada replica el canal de intensidad monocromática a través de los tres canales RGB, generando imagen pseudocromática acromática:
\begin{equation}
\label{eq:conversion_rgb}
\begin{aligned}
R(i,j) &= I(i,j), \\
G(i,j) &= I(i,j), \\
B(i,j) &= I(i,j),
\end{aligned}
\end{equation}
donde $I(i,j)$ denota la intensidad del píxel en posición $(i,j)$ de la radiografía monocromática original, y $R(i,j)$, $G(i,j)$, $B(i,j)$ representan los valores de los canales rojo, verde y azul en la representación tricromática resultante. Esta transformación preserva completamente la información radiográfica original (no introduce contenido espurio ni descarta información diagnóstica) mientras satisface la restricción dimensional de arquitecturas preentrenadas en imágenes naturales.

La justificación de esta estrategia simple de replicación de canal, en contraste con esquemas más sofisticados de pseudocolorización basados en \textit{colormaps} (mapas de color especializados para visualización médica), se fundamenta en dos consideraciones. Primero, compatibilidad con normalización de ImageNet: la replicación uniforme garantiza que, tras normalización con estadísticas de ImageNet, las activaciones en capas convolucionales iniciales permanezcan dentro del régimen de valores para el cual los filtros preentrenados fueron optimizados, facilitando \textit{transfer learning} (aprendizaje por transferencia) efectivo \cite{Raghu2019}. Segundo, preservación de linealidad radiométrica: la relación lineal entre intensidad de píxel y atenuación de rayos X, fundamental para interpretación radiográfica, se mantiene sin distorsión no lineal que introduciría \textit{colormaps} complejos. Estudios empíricos sobre \textit{transfer learning} en dominio médico validan esta estrategia, demostrando que replicación simple de canal produce resultados comparables o superiores a esquemas de pseudocolorización elaborados cuando se combina con normalización apropiada \cite{Tajbakhsh2016}.

La conversión de espacio de color se implementa mediante la función \texttt{cv2.cvtColor} de OpenCV \cite{Bradski2000} con parámetro \texttt{cv2.COLOR\_GRAY2RGB}, ejecutada inmediatamente tras carga de imagen desde disco. Esta operación tiene costo computacional despreciable ($\mathcal{O}(N)$ donde $N = 299 \times 299$ es el número de píxeles) y complejidad de memoria $3\times$ respecto a imagen monocromática original.


\subsubsection{Redimensionamiento y transformación de coordenadas}
\label{subsubsec:redimensionamiento}

Las radiografías en el conjunto de datos poseen resolución espacial uniforme de $299 \times 299$ píxeles (Tabla~\ref{tab:dataset_specs} en Sección~\ref{sec:dataset}), mientras que ResNet-18 estándar procesa entradas de dimensión $224 \times 224$ píxeles, resolución establecida como estándar en competencias ImageNet \cite{Krizhevsky2012}. Esta discrepancia dimensional requiere operación de redimensionamiento que reduce resolución espacial mediante interpolación, acompañada de transformación compensatoria de coordenadas de \textit{landmarks} que preserva correspondencias geométricas.

El redimensionamiento de imagen se realiza mediante interpolación bilineal, aplicando transformación de escalamiento uniforme isotrópico:
\begin{equation}
\label{eq:redimensionamiento}
\mathbf{I}'(i',j') = \text{BilinearInterpolation}\left(\mathbf{I}, \frac{i' \cdot W_{orig}}{W_{target}}, \frac{j' \cdot H_{orig}}{H_{target}}\right),
\end{equation}
donde $\mathbf{I}$ denota la imagen RGB de dimensión $W_{orig} \times H_{orig} = 299 \times 299$, $\mathbf{I}'$ es la imagen redimensionada de dimensión $W_{target} \times H_{target} = 224 \times 224$, e $(i', j') \in [0, W_{target}) \times [0, H_{target})$ son coordenadas en espacio de imagen de salida. La interpolación bilineal fue seleccionada por su balance óptimo entre calidad de reconstrucción (superior a interpolación por vecino más cercano) y eficiencia computacional (superior a interpolación bicúbica), siendo estándar en \textit{pipelines} de visión computacional \cite{Bradski2000}.

Dado que el problema formulado es regresión directa de coordenadas normalizadas $(x_k, y_k) \in [0,1]^2$ para cada \textit{landmark} $k \in \{1, \ldots, 15\}$, expresadas como fracciones relativas a dimensiones de imagen, el redimensionamiento espacial no requiere transformación explícita de coordenadas de supervisión. Las coordenadas normalizadas son invariantes ante cambios de escala uniforme:
\begin{equation}
\label{eq:invariancia_coordenadas_normalizadas}
\left(\frac{x_{pixel}}{W}, \frac{y_{pixel}}{H}\right) = \left(\frac{x_{pixel} \cdot s}{W \cdot s}, \frac{y_{pixel} \cdot s}{H \cdot s}\right) \quad \forall s > 0,
\end{equation}
donde $s = W_{target} / W_{orig} = 224/299 \approx 0.749$ es el factor de escalamiento. Esta propiedad constituye ventaja significativa de la formulación de regresión de coordenadas normalizadas respecto a regresión de coordenadas absolutas en píxeles, eliminando necesidad de transformaciones compensatorias complejas ante variaciones en resolución de entrada. La normalización de coordenadas a rango $[0,1]$ fue implementada durante anotación del conjunto de datos (Sección~\ref{sec:dataset}), permitiendo compatibilidad inmediata con múltiples resoluciones de procesamiento.

El redimensionamiento se implementa mediante la función \texttt{cv2.resize} de OpenCV con parámetro de interpolación \texttt{cv2.INTER\_LINEAR}, aplicada tras conversión de espacio de color. La reducción de resolución de $299^2 = 89401$ píxeles a $224^2 = 50176$ píxeles (reducción del 44\%) disminuye sustancialmente demanda computacional de capas convolucionales subsecuentes sin degradación observable de capacidad de localización, dado que la resolución efectiva para tareas de detección de \textit{landmarks} anatómicos en imágenes de $224 \times 224$ permanece suficiente para precisión sub-píxel cuando se combinan representaciones jerárquicas profundas con funciones de pérdida especializadas \cite{Feng2018}.


\subsubsection{Normalización según estadísticas de ImageNet}
\label{subsubsec:normalizacion_imagenet}

La normalización de intensidades de píxeles constituye componente crítico del \textit{pipeline} de preprocesamiento, transformando valores de píxeles RGB desde su rango original $[0, 255]$ (enteros de 8 bits) a distribución centrada y escalada compatible con estadísticas de activación aprendidas por capas convolucionales de ResNet-18 durante preentrenamiento en ImageNet \cite{Krizhevsky2012}.

El procedimiento de normalización se realiza en dos etapas secuenciales. Primero, conversión a rango de punto flotante $[0,1]$ mediante división por 255:
\begin{equation}
\label{eq:normalizacion_rango}
\tilde{\mathbf{I}}(i,j,c) = \frac{\mathbf{I}'(i,j,c)}{255}, \quad c \in \{R, G, B\},
\end{equation}
donde $\mathbf{I}'$ denota la imagen redimensionada con valores enteros en $[0,255]$, y $\tilde{\mathbf{I}}$ representa la imagen en formato de punto flotante. Segundo, estandarización canal-específica mediante sustracción de media y división por desviación estándar de ImageNet:
\begin{equation}
\label{eq:normalizacion_imagenet}
\mathbf{I}_{norm}(i,j,c) = \frac{\tilde{\mathbf{I}}(i,j,c) - \mu_c}{\sigma_c},
\end{equation}
donde $\mu = [\mu_R, \mu_G, \mu_B] = [0.485, 0.456, 0.406]$ y $\sigma = [\sigma_R, \sigma_G, \sigma_B] = [0.229, 0.224, 0.225]$ son las medias y desviaciones estándar computadas sobre el conjunto de entrenamiento de ImageNet ILSVRC-2012 \cite{Krizhevsky2012}, valores estándar utilizados universalmente en \textit{transfer learning} con arquitecturas preentrenadas en ImageNet.

Esta normalización canal-específica garantiza que, para cada canal $c$, la distribución de activaciones de entrada posea media aproximadamente cero y varianza unitaria cuando se promedian sobre el conjunto de datos. Aunque las radiografías pseudocromáticas producidas por replicación de canal (Ecuación~\ref{eq:conversion_rgb}) poseen estadísticas idénticas en los tres canales ($\mu_R = \mu_G = \mu_B$ y $\sigma_R = \sigma_G = \sigma_B$ localmente para cada imagen individual), la aplicación de parámetros de normalización diferenciados por canal de ImageNet introduce asimetría deliberada que mejora compatibilidad con filtros convolucionales preentrenados. Estos filtros aprendieron patrones visuales sensibles a variaciones cromáticas específicas de imágenes naturales, y la normalización canal-específica preserva la estructura de covarianza entre canales que caracteriza el espacio de representación aprendido durante preentrenamiento \cite{Raghu2019}.

La normalización se implementa mediante transformaciones de PyTorch: conversión inicial a tensor con \texttt{torch.from\_numpy}, permutación de dimensiones desde formato OpenCV $(H \times W \times C)$ a formato PyTorch $(C \times H \times W)$ mediante \texttt{permute(2,0,1)}, conversión a punto flotante con \texttt{float()}, división por 255, y aplicación de normalización mediante \texttt{torchvision.transforms.Normalize} con medias y desviaciones estándar especificadas \cite{Paszke2019}. El tensor normalizado resultante $\mathbf{I}_{norm} \in \mathbb{R}^{3 \times 224 \times 224}$ constituye la entrada estándar al modelo durante entrenamiento e inferencia.


\subsection{Aumentación estocástica de datos}
\label{subsec:augmentation}

La aumentación de datos mediante transformaciones estocásticas constituye técnica fundamental de regularización en aprendizaje profundo supervisado, particularmente crítica en dominio médico donde conjuntos de datos anotados son inherentemente limitados por el costo prohibitivo de anotación experta \cite{Shorten2019}. La estrategia implementada aplica transformaciones geométricas y fotométricas aleatorias durante entrenamiento, expandiendo artificialmente la diversidad del conjunto de datos de 956 muestras anotadas (Sección~\ref{sec:dataset}) mediante generación implícita de variantes transformadas de cada radiografía original.

El diseño del protocolo de aumentación enfrenta restricción fundamental impuesta por la naturaleza de la tarea: a diferencia de clasificación de imágenes donde transformaciones como recortes aleatorios (\textit{random crops}) y escalamientos no uniformes son admisibles, la tarea de regresión de \textit{landmarks} requiere que cada transformación geométrica aplicada a la imagen se replique exactamente sobre las coordenadas de supervisión mediante transformación afín inversa matemáticamente consistente. Transformaciones que no preservan correspondencias geométricas (como recortes asimétricos que eliminan \textit{landmarks} del campo de visión) corrompen irremediablemente la supervisión, impidiendo aprendizaje. Esta restricción limita las transformaciones admisibles a aquellas geométricamente invertibles: reflexiones, rotaciones, traslaciones, y escalamientos uniformes cuyos parámetros son conocidos exactamente \cite{Shorten2019}.

El protocolo implementado incorpora tres categorías de transformaciones estocásticas, aplicadas secuencialmente con probabilidades calibradas para balancear incremento de variabilidad contra preservación de realismo anatómico.


\subsubsection{Reflexión horizontal}
\label{subsubsec:flip_horizontal}

La reflexión horizontal constituye transformación de aumentación más frecuentemente aplicada (probabilidad $p_{flip} = 0.70$), explotando la simetría bilateral aproximada de la anatomía torácica humana. Una radiografía de tórax reflejada horizontalmente permanece anatómicamente plausible y diagnósticamente válida, representando simplemente una adquisición con orientación lateral invertida.

La transformación de reflexión horizontal se define matemáticamente como:
\begin{equation}
\label{eq:flip_horizontal_imagen}
\mathbf{I}_{flip}(i, j) = \mathbf{I}(W - 1 - i, j),
\end{equation}
donde $W = 224$ es el ancho de imagen, $(i,j)$ son coordenadas en imagen original, y $(W-1-i, j)$ son coordenadas reflejadas respecto al eje vertical central. Las coordenadas normalizadas de \textit{landmarks} se transforman mediante reflexión correspondiente:
\begin{equation}
\label{eq:flip_horizontal_coordenadas}
x'_k = 1 - x_k, \quad y'_k = y_k, \quad k \in \{1, \ldots, 15\},
\end{equation}
donde $(x_k, y_k) \in [0,1]^2$ son coordenadas normalizadas originales del \textit{landmark} $k$, y $(x'_k, y'_k)$ son coordenadas transformadas tras reflexión.

Adicionalmente, la reflexión horizontal requiere intercambio de identidades entre \textit{landmarks} que forman pares simétricos bilaterales. Como se definió en la Sección~\ref{sec:dataset}, el conjunto de datos incluye cinco pares de \textit{landmarks} bilateralmente simétricos: $\mathcal{P}_{sym} = \{(2,3), (4,5), (6,7), (11,12), (13,14)\}$, correspondientes a estructuras anatómicas emparejadas (ápices pulmonares, ángulos costofrénicos, hilios, etc.). Tras reflexión horizontal, la identidad de \textit{landmarks} emparejados debe intercambiarse para mantener consistencia anatómica:
\begin{equation}
\label{eq:flip_swap_simetricos}
(x'_i, y'_i) \leftrightarrow (x'_j, y'_j) \quad \forall (i,j) \in \mathcal{P}_{sym}.
\end{equation}

La implementación de reflexión horizontal utiliza \texttt{torch.flip} con parámetro \texttt{dims=[2]} para invertir dimensión espacial horizontal del tensor de imagen, y permutación explícita de índices de coordenadas para intercambio de pares simétricos. La alta probabilidad de aplicación ($p = 0.70$) garantiza que el modelo observe tanto configuraciones anatómicas originales como reflejadas con frecuencia balanceada, promoviendo invariancia ante orientación lateral y mejorando capacidad de generalización a variabilidad de posicionamiento clínico.


\subsubsection{Rotación aleatoria limitada}
\label{subsubsec:rotacion}

La rotación aleatoria dentro de rango angular limitado modela variabilidad en posicionamiento del paciente durante adquisición radiográfica, donde ligeras inclinaciones son inevitables en práctica clínica. La transformación se aplica con probabilidad $p_{rot} = 0.30$ (menos frecuente que reflexión para evitar exceso de transformaciones compuestas que degradarían calidad de imagen), muestreando ángulo de rotación uniformemente desde intervalo $\theta \sim \mathcal{U}(-15°, +15°)$.

La transformación de rotación centrada en el centro de imagen se define mediante matriz de rotación afín:
\begin{equation}
\label{eq:matriz_rotacion}
\mathbf{R}(\theta) = \begin{bmatrix}
\cos\theta & -\sin\theta & t_x \\
\sin\theta & \cos\theta & t_y \\
0 & 0 & 1
\end{bmatrix},
\end{equation}
donde las componentes de traslación compensatoria $t_x$ y $t_y$ garantizan rotación centrada en punto $(W/2, H/2)$ de imagen. Las coordenadas normalizadas de \textit{landmarks} se transforman mediante aplicación de rotación inversa centrada en $(0.5, 0.5)$, punto central en espacio de coordenadas normalizadas:
\begin{equation}
\label{eq:rotacion_coordenadas_normalizadas}
\begin{bmatrix}
x'_k - 0.5 \\
y'_k - 0.5
\end{bmatrix} = \begin{bmatrix}
\cos\theta & -\sin\theta \\
\sin\theta & \cos\theta
\end{bmatrix} \begin{bmatrix}
x_k - 0.5 \\
y_k - 0.5
\end{bmatrix}.
\end{equation}

La limitación del rango angular a $\pm 15°$ responde a dos consideraciones. Primero, realismo clínico: rotaciones superiores a 15° son infrecuentes en radiografías de tórax de calidad diagnóstica estándar, dado que protocolos de posicionamiento radiográfico buscan alineación precisa del paciente con el detector. Segundo, preservación de visibilidad de \textit{landmarks}: rotaciones excesivas podrían desplazar \textit{landmarks} periféricos (ápices pulmonares, ángulos costofrénicos) fuera del campo de visión tras rotación, corrompiendo supervisión. El rango de $\pm 15°$ balancea incremento de robustez ante variabilidad de posicionamiento con preservación de validez anatómica.

La implementación utiliza \texttt{torchvision.transforms.functional.affine} para aplicar transformación afín a imagen, y rotación matricial explícita sobre coordenadas normalizadas mediante operaciones tensoriales de PyTorch. La interpolación bilineal se emplea para reconstrucción de imagen rotada, con relleno de regiones externas mediante valor cero (\textit{padding} negro), consistente con fondo típico de radiografías digitales.


\subsubsection{Ajustes fotométricos}
\label{subsubsec:ajustes_fotometricos}

Los ajustes fotométricos modelan variabilidad en técnica radiográfica (variaciones en kilovoltaje pico, miliamperaje-segundo, tiempo de exposición) y procesamiento posterior (ajustes de ventana y nivel en sistemas PACS), que afectan contraste y brillo aparente de radiografías sin alterar geometría anatómica. Estas transformaciones se aplican con probabilidad $p_{photo} = 0.50$, ajustando brillo (mediante suma aditiva) y contraste (mediante multiplicación) dentro de rangos calibrados.

El ajuste de brillo se define como traslación aditiva uniforme de intensidades:
\begin{equation}
\label{eq:ajuste_brillo}
\mathbf{I}_{bright}(i,j,c) = \mathbf{I}(i,j,c) + \beta, \quad \beta \sim \mathcal{U}(-0.2, +0.2),
\end{equation}
donde $\beta$ es el factor de brillo muestreado uniformemente desde intervalo $[-0.2, +0.2]$ en espacio normalizado $[0,1]$. El ajuste de contraste se implementa como escalamiento multiplicativo centrado en intensidad media:
\begin{equation}
\label{eq:ajuste_contraste}
\mathbf{I}_{contrast}(i,j,c) = \alpha \cdot \mathbf{I}(i,j,c), \quad \alpha \sim \mathcal{U}(0.8, 1.2),
\end{equation}
donde $\alpha$ es el factor de contraste muestreado desde intervalo $[0.8, 1.2]$, permitiendo reducción o incremento del 20\% en contraste aparente.

Crucialmente, los ajustes fotométricos no requieren transformación de coordenadas de \textit{landmarks}, dado que preservan completamente la geometría espacial de imagen: ningún píxel cambia de posición, solo su intensidad. Esta propiedad contrasta con transformaciones geométricas (reflexión, rotación) que requieren compensación de coordenadas. Los ajustes fotométricas se aplican tras normalización de ImageNet descrita en la Sección~\ref{subsubsec:normalizacion_imagenet}, operando sobre tensores normalizados antes de ingreso a la red neuronal.

La implementación utiliza \texttt{torchvision.transforms.ColorJitter} con parámetros \texttt{brightness=0.2} y \texttt{contrast=0.2}, aplicados con probabilidad 0.5 mediante envoltura en \texttt{RandomApply}. Los valores de brillo y contraste tras ajuste se recortan (\textit{clipping}) al rango válido de tensores normalizados para evitar valores atípicos extremos que desestabilizarían gradientes durante retropropagación \cite{Paszke2019}.


\subsection{Orden de aplicación y composición de transformaciones}
\label{subsec:orden_transformaciones}

Las transformaciones de preprocesamiento y aumentación descritas en las subsecciones previas se aplican mediante \textit{pipeline} secuencial implementado como composición de funciones en PyTorch \cite{Paszke2019}. El orden de aplicación es crítico: transformaciones no conmutan, y secuencias incorrectas producirían inconsistencias entre imágenes procesadas y coordenadas transformadas.

El \textit{pipeline} completo de entrenamiento aplica transformaciones en el siguiente orden estrictamente especificado:
\begin{enumerate}
    \item Carga de radiografía monocromática desde disco (formato PNG de 8 bits).
    \item Conversión de espacio de color: monocromático $\rightarrow$ RGB pseudocromático (Ecuación~\ref{eq:conversion_rgb}).
    \item Redimensionamiento mediante interpolación bilineal: $299 \times 299 \rightarrow 224 \times 224$ (Ecuación~\ref{eq:redimensionamiento}).
    \item Conversión a tensor PyTorch con permutación de dimensiones.
    \item Normalización a rango $[0,1]$ mediante división por 255.
    \item Normalización según estadísticas de ImageNet (Ecuación~\ref{eq:normalizacion_imagenet}).
    \item Aplicación estocástica de reflexión horizontal con $p=0.70$ (Ecuaciones~\ref{eq:flip_horizontal_imagen}--\ref{eq:flip_swap_simetricos}).
    \item Aplicación estocástica de rotación con $p=0.30$, ángulo $\theta \sim \mathcal{U}(-15°, +15°)$ (Ecuaciones~\ref{eq:matriz_rotacion}--\ref{eq:rotacion_coordenadas_normalizadas}).
    \item Aplicación estocástica de ajustes fotométricos con $p=0.50$ (Ecuaciones~\ref{eq:ajuste_brillo}--\ref{eq:ajuste_contraste}).
\end{enumerate}

Durante inferencia (validación y evaluación en conjunto de prueba), únicamente los pasos determinísticos (1--6) se aplican, omitiendo completamente transformaciones estocásticas de aumentación. Esta separación garantiza reproducibilidad perfecta de predicciones durante evaluación, requisito fundamental para comparación rigurosa de rendimiento entre modelos y reportes de métricas estandarizadas.

La composición de transformaciones estocásticas geométricas (reflexión y rotación) puede aplicarse simultáneamente con probabilidades independientes, produciendo ocasionalmente muestras transformadas mediante ambas operaciones. La probabilidad de aplicación conjunta es $p_{flip} \cdot p_{rot} = 0.70 \times 0.30 = 0.21$ (21\% de muestras), mientras que la probabilidad de al menos una transformación geométrica es $1 - (1-p_{flip})(1-p_{rot}) = 1 - 0.30 \times 0.70 = 0.79$ (79\% de muestras). Esta composición estocástica expande significativamente la diversidad efectiva del conjunto de entrenamiento: cada radiografía original de 956 disponibles puede presentarse en múltiples configuraciones transformadas a lo largo de las épocas de entrenamiento, reduciendo sobreajuste mediante exposición continua a variantes no idénticas \cite{Shorten2019}.


\subsection{Síntesis del pipeline}
\label{subsec:sintesis_pipeline}

El \textit{pipeline} de preprocesamiento y aumentación documentado en esta sección reconcilia exitosamente los requerimientos simultáneos de compatibilidad con arquitecturas preentrenadas (mediante normalización de ImageNet), preservación de precisión geométrica (mediante transformaciones afines matemáticamente consistentes sobre coordenadas de \textit{landmarks}), e incremento de robustez ante variabilidad clínica (mediante aumentación estocástica controlada). La separación funcional entre preprocesamiento determinístico (aplicado uniformemente en entrenamiento e inferencia) y aumentación estocástica (exclusiva de entrenamiento) garantiza reproducibilidad en evaluación mientras maximiza regularización durante aprendizaje, siguiendo principios establecidos de diseño de \textit{pipelines} de visión computacional \cite{Shorten2019, Krizhevsky2012}.

La implementación completa del \textit{pipeline} se encapsula en clase personalizada \texttt{ChestXrayDataset} derivada de \texttt{torch.utils.data.Dataset}, que gestiona carga de imágenes, aplicación de transformaciones, y generación de pares (imagen transformada, coordenadas transformadas) durante iteración de entrenamiento. Esta abstracción modular facilita experimentación con variaciones del protocolo de aumentación y garantiza consistencia de procesamiento a través de todas las fases de entrenamiento descritas en la Sección~\ref{sec:estrategia_entrenamiento}.

La siguiente sección describe exhaustivamente la estrategia de entrenamiento progresivo en cuatro fases que incorpora gradualmente restricciones geométricas inspiradas en conocimiento anatómico, construyendo sobre la arquitectura especificada en la Sección~\ref{sec:arquitectura} y operando sobre datos procesados mediante el \textit{pipeline} documentado en la presente sección.
