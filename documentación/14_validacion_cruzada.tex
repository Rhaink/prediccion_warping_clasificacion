% ==============================================================================
% DOCUMENTACIÓN CIENTÍFICA - VALIDACIÓN CRUZADA ORIGINAL/WARPED
% Proyecto: Detección de COVID-19 mediante Landmarks Anatómicos
% Sesiones cubiertas: 26, 30
% Nivel: Doctoral/Científico - Completo y Detallado
% ==============================================================================

\documentclass[12pt,a4paper]{article}
\input{00_preambulo}

\title{Cross-Evaluation de Modelos:\\
Análisis de Generalización entre Dominios Original y Normalizado}
\author{Documentación del Proceso de Desarrollo}
\date{Sesiones: 26, 30}

\begin{document}
\maketitle

\begin{abstract}
Este documento presenta un análisis de cross-evaluation entre modelos
entrenados y evaluados en diferentes dominios: imágenes originales y
geométricamente normalizadas (warped). Se definen cuatro configuraciones
experimentales que evalúan la transferencia de conocimiento entre dominios:
Original$\to$Original (98.81\%), Original$\to$Warped (73.45\%),
Warped$\to$Warped (98.02\%), y Warped$\to$Original (95.78\%). El hallazgo
más significativo es la asimetría en la generalización: mientras que los
modelos entrenados en original sufren una degradación del 25.36\% al
evaluarse en warped, los modelos entrenados en warped solo pierden 2.24\%
al evaluarse en original. Esto indica que el modelo entrenado en imágenes
normalizadas ha aprendido características más robustas y transferibles,
con una mejora en generalización de 11.3× respecto al modelo original.
Este resultado valida la hipótesis de que la normalización geométrica
produce modelos con mayor capacidad de generalización.
\end{abstract}

\tableofcontents
\newpage

% ==============================================================================
\section{Introducción y Motivación}
% ==============================================================================

\subsection{Objetivo del Cross-Evaluation}

El cross-evaluation evalúa la transferencia de conocimiento entre dominios:

\begin{enumerate}
    \item \textbf{Evaluar generalización}: ¿Los modelos transfieren bien
    entre imágenes originales y normalizadas?

    \item \textbf{Detectar overfitting a shortcuts}: Si el modelo original
    depende de artefactos geométricos, fallará en imágenes warped

    \item \textbf{Validar el enfoque de normalización}: Si el modelo warped
    generaliza mejor, la normalización produce features más robustas
\end{enumerate}

\subsection{Hipótesis}

\begin{hipotesis}[Asimetría de Generalización]
Los modelos entrenados en imágenes normalizadas generalizarán mejor
a imágenes originales que viceversa, porque:
\begin{enumerate}
    \item El warping elimina shortcuts geométricos
    \item El modelo warped aprende características de textura pulmonar
    \item Estas características están presentes en ambos dominios
\end{enumerate}
\end{hipotesis}

% ==============================================================================
\section{Diseño Experimental}
% ==============================================================================

\subsection{Configuraciones de Cross-Evaluation}

Se definen cuatro configuraciones que combinan dominio de entrenamiento
y dominio de evaluación:

\begin{table}[htbp]
\centering
\caption{Matriz de configuraciones experimentales}
\label{tab:cross_eval_matrix}
\begin{tabular}{lcc}
\toprule
& \multicolumn{2}{c}{\textbf{Test Set}} \\
\cmidrule(lr){2-3}
\textbf{Entrenamiento} & \textbf{Original} & \textbf{Warped} \\
\midrule
\textbf{Original} & Original$\to$Original & Original$\to$Warped \\
\textbf{Warped} & Warped$\to$Original & Warped$\to$Warped \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Definiciones Formales}

\begin{definicion}[Accuracy en Configuración $X \to Y$]
Sea $M_X$ un modelo entrenado en el dataset $X$ y $D_Y$ el test set del
dataset $Y$. La accuracy de la configuración $X \to Y$ es:
\begin{equation}
\text{Acc}_{X \to Y} = \frac{1}{|D_Y|} \sum_{(x,y) \in D_Y} \mathbb{1}[M_X(x) = y]
\end{equation}
\end{definicion}

\begin{definicion}[Gap de Generalización]
El gap de generalización mide la pérdida de rendimiento al evaluar en
un dominio diferente al de entrenamiento:
\begin{equation}
\text{Gap}_X = \text{Acc}_{X \to X} - \text{Acc}_{X \to \bar{X}}
\label{eq:generalization_gap}
\end{equation}
donde $\bar{X}$ denota el dominio complementario (Original si $X$=Warped
y viceversa).
\end{definicion}

\begin{definicion}[Ratio de Mejora en Generalización]
El ratio de mejora compara los gaps de generalización:
\begin{equation}
R = \frac{\text{Gap}_{\text{Original}}}{\text{Gap}_{\text{Warped}}}
\label{eq:improvement_ratio}
\end{equation}
Un valor $R > 1$ indica que el modelo warped generaliza mejor.
\end{definicion}

\subsection{Protocolo Experimental}

\begin{enumerate}
    \item \textbf{Modelos utilizados}: ResNet-18 entrenado en cada dominio
    (sesiones 27-28)

    \item \textbf{Test sets}: 1518 imágenes en cada dominio

    \item \textbf{Métricas}: Accuracy, F1-score macro, matriz de confusión

    \item \textbf{Sin re-entrenamiento}: Los modelos se evalúan directamente
    sin fine-tuning al nuevo dominio
\end{enumerate}

% ==============================================================================
\section{Resultados}
% ==============================================================================

\subsection{Matriz de Resultados}

\begin{table}[htbp]
\centering
\caption{Resultados de cross-evaluation (Accuracy en \%)}
\label{tab:cross_eval_results}
\begin{tabular}{lcccc}
\toprule
& \multicolumn{2}{c}{\textbf{Test Set}} & \\
\cmidrule(lr){2-3}
\textbf{Entrenamiento} & \textbf{Original} & \textbf{Warped} & \textbf{Gap} \\
\midrule
\textbf{Original} & \cellcolor{green!20}98.81\% & \cellcolor{red!20}73.45\% & \textbf{25.36\%} \\
\textbf{Warped} & \cellcolor{yellow!20}95.78\% & \cellcolor{green!20}98.02\% & \textbf{2.24\%} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Análisis de Gaps}

\begin{table}[htbp]
\centering
\caption{Análisis detallado de gaps de generalización}
\label{tab:gap_analysis_detail}
\begin{tabular}{llcc}
\toprule
\textbf{Dominio Train} & \textbf{Métrica} & \textbf{In-Domain} & \textbf{Cross-Domain} \\
\midrule
Original & Accuracy & 98.81\% & 73.45\% \\
& Gap absoluto & \multicolumn{2}{c}{25.36 puntos} \\
& Gap relativo & \multicolumn{2}{c}{-25.7\%} \\
\midrule
Warped & Accuracy & 98.02\% & 95.78\% \\
& Gap absoluto & \multicolumn{2}{c}{2.24 puntos} \\
& Gap relativo & \multicolumn{2}{c}{-2.3\%} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Ratio de Mejora}

\begin{equation}
R = \frac{\text{Gap}_{\text{Original}}}{\text{Gap}_{\text{Warped}}} =
\frac{25.36\%}{2.24\%} = \textbf{11.32}
\end{equation}

\begin{resultadoimportante}[title={Mejora de 11× en generalización}]
El modelo entrenado en imágenes warped generaliza \textbf{11.3 veces mejor}
que el modelo entrenado en originales. Esta diferencia drástica confirma
que:
\begin{enumerate}
    \item El modelo original depende fuertemente de características
    específicas del dominio (shortcuts geométricos)
    \item El modelo warped ha aprendido características más robustas
    que transfieren entre dominios
    \item La normalización geométrica produce representaciones más
    generalizables
\end{enumerate}
\end{resultadoimportante}

\subsection{Análisis Asimétrico}

\begin{observacion}[Asimetría de Transferencia]
La transferencia de conocimiento es altamente asimétrica:

\textbf{Original $\to$ Warped (pobre)}: El modelo pierde 25.36 puntos
porque las características que aprendió (posiblemente incluyendo geometría,
marcadores, artefactos) no están presentes en las imágenes warped.

\textbf{Warped $\to$ Original (buena)}: El modelo solo pierde 2.24 puntos
porque las características de textura pulmonar que aprendió están presentes
en ambos dominios.
\end{observacion}

% ==============================================================================
\section{Análisis por Clase}
% ==============================================================================

\subsection{Degradación por Categoría en Original$\to$Warped}

\begin{table}[htbp]
\centering
\caption{Rendimiento por clase: Original$\to$Warped}
\label{tab:per_class_orig_to_warp}
\begin{tabular}{lcccc}
\toprule
\textbf{Clase} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} & \textbf{$n$ test} \\
\midrule
COVID & 53.7\% & 97.5\% & 69.3\% & 362 \\
Normal & 98.4\% & 62.0\% & 76.0\% & 1020 \\
Viral & 59.4\% & 95.6\% & 73.3\% & 136 \\
\midrule
\textbf{Macro Avg} & \textbf{70.5\%} & \textbf{85.0\%} & \textbf{72.9\%} & 1518 \\
\bottomrule
\end{tabular}
\end{table}

\begin{observacion}[Normal es la clase más afectada]
La clase Normal sufre la mayor degradación en recall (62.0\%) en cross-domain,
indicando que muchas imágenes Normal son clasificadas erróneamente como COVID
(301 de 1020). Esto sugiere que el modelo original depende de características
geométricas específicas para distinguir Normal de COVID.
\end{observacion}

\subsection{Rendimiento por Clase en Warped$\to$Original}

\begin{table}[htbp]
\centering
\caption{Rendimiento por clase: Warped$\to$Original}
\label{tab:per_class_warp_to_orig}
\begin{tabular}{lcccc}
\toprule
\textbf{Clase} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} & \textbf{$n$ test} \\
\midrule
COVID & 92.7\% & 95.0\% & 93.9\% & 362 \\
Normal & 96.7\% & 97.2\% & 96.9\% & 1020 \\
Viral & 97.5\% & 87.5\% & 92.2\% & 136 \\
\midrule
\textbf{Macro Avg} & \textbf{95.6\%} & \textbf{93.2\%} & \textbf{94.3\%} & 1518 \\
\bottomrule
\end{tabular}
\end{table}

\begin{observacion}[Rendimiento consistente entre clases]
El modelo warped mantiene rendimiento alto y balanceado en todas las clases
al evaluarse en original, indicando que las características aprendidas
son robustas y no dependen del dominio.
\end{observacion}

% ==============================================================================
\section{Interpretación Teórica}
% ==============================================================================

\subsection{Modelo de Características}

Podemos conceptualizar las características aprendidas como:

\begin{equation}
\mathcal{F}(x) = \underbrace{\mathcal{F}_{\text{textura}}(x)}_{\text{robustas}} +
\underbrace{\mathcal{F}_{\text{geom}}(x)}_{\text{shortcuts}}
\label{eq:feature_decomposition}
\end{equation}

donde:
\begin{itemize}
    \item $\mathcal{F}_{\text{textura}}$: Características de textura pulmonar
    (consolidaciones, opacidades) presentes en ambos dominios
    \item $\mathcal{F}_{\text{geom}}$: Características geométricas (forma,
    posición, marcadores) específicas del dominio original
\end{itemize}

\subsection{Comportamiento por Dominio de Entrenamiento}

\begin{proposicion}[Modelo Original]
El modelo entrenado en original aprende:
\begin{equation}
M_{\text{orig}} \approx f(\mathcal{F}_{\text{textura}} + \mathcal{F}_{\text{geom}})
\end{equation}
Al evaluarse en warped, donde $\mathcal{F}_{\text{geom}} \approx 0$
(eliminado por normalización), el modelo falla porque depende parcialmente
de estas características.
\end{proposicion}

\begin{proposicion}[Modelo Warped]
El modelo entrenado en warped aprende:
\begin{equation}
M_{\text{warp}} \approx f(\mathcal{F}_{\text{textura}})
\end{equation}
Al evaluarse en original, las características de textura siguen presentes,
por lo que el modelo mantiene buen rendimiento. Las características
geométricas adicionales en original son ignoradas.
\end{proposicion}

\subsection{Implicaciones para Generalización}

\begin{hallazgo}[title={La normalización produce invariancia geométrica}]
El modelo warped ha aprendido una representación invariante a transformaciones
geométricas. Esta invariancia se manifiesta en:
\begin{enumerate}
    \item Robustez a variaciones de posicionamiento del paciente
    \item Independencia de tamaño/escala del tórax
    \item Menor dependencia de artefactos de adquisición
\end{enumerate}
\end{hallazgo}

% ==============================================================================
\section{Implicaciones Prácticas}
% ==============================================================================

\subsection{Para Despliegue Clínico}

\begin{enumerate}
    \item \textbf{Robustez requerida}: En escenarios clínicos, las imágenes
    provendrán de diferentes equipos, protocolos y poblaciones de pacientes

    \item \textbf{Recomendación}: Usar el modelo warped incluso si la
    accuracy in-domain es ligeramente menor (98.02\% vs 98.81\%)

    \item \textbf{Justificación}: La mejora de 11× en generalización
    supera la pérdida de 0.79 puntos in-domain
\end{enumerate}

\subsection{Para Investigación}

\begin{enumerate}
    \item \textbf{Validación de datasets}: Cross-evaluation puede detectar
    shortcuts en datasets médicos

    \item \textbf{Desarrollo de modelos}: Entrenar en datos normalizados
    produce modelos más generalizables

    \item \textbf{Benchmark}: Reportar tanto accuracy in-domain como
    cross-domain para evaluación completa
\end{enumerate}

% ==============================================================================
\section{Figuras Sugeridas}
% ==============================================================================

\subsection{Figura 14.1: Matriz de Cross-Evaluation}

\begin{figuradescripcion}
\textbf{Título}: Matriz de accuracy en cross-evaluation

\textbf{Contenido}: Heatmap 2×2 con valores de accuracy.

\textbf{Elementos visuales}:
\begin{itemize}
    \item Filas: Dominio de entrenamiento (Original, Warped)
    \item Columnas: Dominio de test (Original, Warped)
    \item Colores: Verde (alto), Amarillo (medio), Rojo (bajo)
    \item Valores numéricos en cada celda
\end{itemize}

\textbf{Anotaciones}: Gaps en los márgenes
\end{figuradescripcion}

\subsection{Figura 14.2: Comparación de Gaps}

\begin{figuradescripcion}
\textbf{Título}: Gap de generalización por dominio de entrenamiento

\textbf{Contenido}: Gráfico de barras comparativo.

\textbf{Elementos visuales}:
\begin{itemize}
    \item Dos barras: Gap Original (25.36\%), Gap Warped (2.24\%)
    \item Anotación del ratio (11.3×)
    \item Colores contrastantes
\end{itemize}
\end{figuradescripcion}

\subsection{Figura 14.3: Rendimiento por Clase en Cross-Domain}

\begin{figuradescripcion}
\textbf{Título}: F1-score por clase en evaluación cross-domain

\textbf{Contenido}: Gráfico de barras agrupadas.

\textbf{Elementos visuales}:
\begin{itemize}
    \item 3 grupos (Normal, COVID, Viral)
    \item 2 barras por grupo (Orig$\to$Warp, Warp$\to$Orig)
    \item Línea de referencia en rendimiento in-domain
\end{itemize}

\textbf{Observación}: Mostrar que Viral es más afectada en Orig$\to$Warp
\end{figuradescripcion}

% ==============================================================================
\section{Archivos Fuente y Reproducibilidad}
% ==============================================================================

\begin{table}[htbp]
\centering
\caption{Archivos de implementación del cross-evaluation}
\label{tab:source_files_crosseval}
\begin{tabular}{p{5.5cm}p{7.5cm}}
\toprule
\textbf{Archivo} & \textbf{Contenido} \\
\midrule
\archivo{scripts/cross\_evaluation.py} & Evaluación cruzada de modelos:\\
& \quad - Carga de modelos pretrained\\
& \quad - Evaluación en ambos dominios\\
& \quad - Cálculo de métricas por clase\\
\midrule
\archivo{outputs/classifier/\\best\_model\_original.pt} & Mejor modelo en original (MobileNetV2)\\
\midrule
\archivo{outputs/classifier/\\best\_model\_warped.pt} & Mejor modelo en warped (ResNet-18)\\
\midrule
\archivo{outputs/cross\_evaluation/} & Resultados:\\
& \quad - cross\_eval\_matrix.csv\\
& \quad - per\_class\_metrics.json\\
& \quad - confusion\_matrices/\\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Discusión}
% ==============================================================================

\subsection{Limitaciones}

\begin{enumerate}
    \item \textbf{Misma arquitectura}: Se usó ResNet-18 para ambos dominios;
    resultados podrían variar con otras arquitecturas

    \item \textbf{Mismo dataset base}: Ambos dominios provienen del mismo
    dataset (1518 muestras); la generalización a datasets completamente
    externos requiere validación adicional
\end{enumerate}

\subsection{Comparación con Literatura}

El gap de 25.36\% observado en Original$\to$Warped es consistente con
resultados reportados en estudios de shortcut learning en imágenes
médicas, donde gaps del 20-30\% son comunes cuando se remueven artefactos
correlacionados con etiquetas.

% ==============================================================================
\section{Conclusiones}
% ==============================================================================

\begin{enumerate}
    \item \textbf{Asimetría significativa}: Los modelos entrenados en
    warped generalizan mucho mejor (gap 2.24\%) que los entrenados en
    original (gap 25.36\%).

    \item \textbf{Ratio de mejora de 11×}: La normalización geométrica
    produce modelos con capacidad de generalización 11.3 veces superior.

    \item \textbf{Validación del enfoque}: El cross-evaluation confirma
    que el warping elimina shortcuts y produce características más robustas.

    \item \textbf{Recomendación práctica}: Para despliegue clínico,
    preferir el modelo warped a pesar de accuracy ligeramente menor
    in-domain.

    \item \textbf{Implicación metodológica}: Cross-evaluation debería
    ser evaluación estándar para detectar shortcut learning en
    clasificación de imágenes médicas.
\end{enumerate}

\end{document}
