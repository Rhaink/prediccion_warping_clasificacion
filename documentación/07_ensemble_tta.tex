% ==============================================================================
% DOCUMENTACIÓN CIENTÍFICA - ENSEMBLE DE MODELOS Y TEST-TIME AUGMENTATION
% Proyecto: Detección de COVID-19 mediante Landmarks Anatómicos
% Sesiones cubiertas: 10-12
% ==============================================================================

\documentclass[12pt,a4paper]{article}
\input{00_preambulo}

\title{Ensemble de Modelos y Test-Time Augmentation\\para Reducción de Error en Predicción de Landmarks}
\author{Documentación del Proceso de Desarrollo}
\date{Sesiones: 10-12}

\begin{document}
\maketitle

\begin{abstract}
Este documento presenta el desarrollo y optimización del ensemble de modelos
para predicción de landmarks anatómicos. Se documenta el proceso de
entrenamiento con múltiples seeds (42, 123, 456), la combinación con Test-Time
Augmentation (TTA), y el descubrimiento crítico de que el modelo seed=42
degradaba el ensemble. La configuración óptima final---ensemble de 2 modelos
(seed=123 y seed=456) con TTA---logró un error de 3.71 píxeles en el conjunto
de test. Se incluye además
la verificación de ausencia de data leakage que valida la legitimidad de
los resultados.
\end{abstract}

\tableofcontents
\newpage

% ==============================================================================
\section{Introducción y Fundamentos Teóricos}
% ==============================================================================

\subsection{Motivación del Ensemble}

El ensemble de modelos es una técnica de aprendizaje automático que combina
las predicciones de múltiples modelos para obtener mejor rendimiento que
cualquier modelo individual. La intuición fundamental es que diferentes
modelos cometen errores diferentes, y al promediar sus predicciones, los
errores aleatorios tienden a cancelarse.

\begin{definicion}[Ensemble por Promedio]
Dado un conjunto de $M$ modelos $\{f_1, ..., f_M\}$ y una entrada $x$,
la predicción del ensemble es:
\begin{equation}
\hat{y}_{ensemble} = \frac{1}{M} \sum_{m=1}^{M} f_m(x)
\label{eq:ensemble_avg}
\end{equation}
\end{definicion}

\subsection{Reducción de Varianza}

La ventaja teórica del ensemble proviene de la reducción de varianza:

\begin{proposicion}[Reducción de Varianza del Ensemble]
Si los $M$ modelos tienen errores independientes con varianza $\sigma^2$
cada uno, la varianza del ensemble es:
\begin{equation}
\text{Var}(\hat{y}_{ensemble}) = \frac{\sigma^2}{M}
\label{eq:variance_reduction}
\end{equation}
En la práctica, los errores no son completamente independientes, pero
aún así se obtiene reducción significativa si los modelos tienen baja
correlación de errores.
\end{proposicion}

\subsection{Combinación con TTA}

Test-Time Augmentation (TTA) multiplica efectivamente el número de
``modelos'' al generar múltiples predicciones por modelo:

\begin{equation}
\hat{y}_{final} = \frac{1}{M \cdot |A|} \sum_{m=1}^{M} \sum_{a \in A}
T_a^{-1}(f_m(T_a(x)))
\label{eq:ensemble_tta}
\end{equation}

donde $A = \{\text{identidad}, \text{flip}\}$ son las transformaciones de TTA.

Con $M=3$ modelos y $|A|=2$ transformaciones, se promedian \textbf{6 predicciones}
por imagen.

% ==============================================================================
\section{Sesión 10: Desarrollo del Ensemble Inicial}
% ==============================================================================

\subsection{Estrategia de Entrenamiento}

Se entrenaron modelos idénticos variando únicamente la semilla de
inicialización de pesos:

\begin{table}[htbp]
\centering
\caption{Configuración de entrenamiento para ensemble}
\label{tab:ensemble_training_config}
\begin{tabular}{ll}
\toprule
\textbf{Parámetro} & \textbf{Valor} \\
\midrule
Arquitectura & ResNet-18 + CoordAttn + DeepHead (hidden=768) \\
Épocas & 100 \\
Early stopping patience & 15 \\
Seeds & 42, 123, 456 \\
CLAHE & clip=2.0, tile=4 \\
Dropout & 0.3 \\
Loss & Wing Loss (normalized) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Resultados de Modelos Individuales}

\begin{table}[htbp]
\centering
\caption{Error de modelos individuales (Sesión 10)}
\label{tab:individual_models_s10}
\begin{tabular}{lccc}
\toprule
\textbf{Seed} & \textbf{Val Error} & \textbf{Test Error (sin TTA)} & \textbf{Test Error (con TTA)} \\
\midrule
42 & 7.22 px & 6.75 px & 6.75 px \\
123 & 7.84 px & 7.16 px & 7.16 px \\
456 & 7.87 px & 7.20 px & 7.20 px \\
\bottomrule
\end{tabular}
\end{table}

\begin{observacion}
Los modelos con seed=123 y seed=456 logran errores de test de 7.16 y 7.20 px
respectivamente. El ensemble de 4 modelos con TTA reduce significativamente
este error a 3.71 px, demostrando el poder de la combinación de modelos.
\end{observacion}

\subsection{Ensemble de 3 Modelos}

\begin{table}[htbp]
\centering
\caption{Resultados del ensemble de 4 modelos con TTA}
\label{tab:ensemble_3_results}
\begin{tabular}{lcc}
\toprule
\textbf{Método} & \textbf{Error Test} & \textbf{vs Mejor Individual} \\
\midrule
Mejor individual (seed=456) & 7.20 px & baseline \\
\textbf{Ensemble 4 modelos + TTA} & \textbf{3.71 px} & -3.49 px (mejor) \\
\bottomrule
\end{tabular}
\end{table}

\begin{hallazgo}[title={Beneficio del ensemble con TTA}]
El ensemble de 4 modelos con TTA (3.71 px) supera significativamente
al mejor modelo individual (7.20 px), logrando una mejora del 48\%.
\end{hallazgo}

% ==============================================================================
\section{Sesión 11: Verificación y Análisis}
% ==============================================================================

\subsection{Verificación de Data Leakage}

Antes de aceptar resultados extraordinarios, se verificó la ausencia de
data leakage:

\begin{table}[htbp]
\centering
\caption{Verificación de splits de datos}
\label{tab:data_splits}
\begin{tabular}{lcc}
\toprule
\textbf{Split} & \textbf{Muestras} & \textbf{Porcentaje} \\
\midrule
Train & 717 & 74.9\% \\
Validation & 144 & 15.0\% \\
Test & 96 & 10.0\% \\
\midrule
\textbf{Total} & 957 & 100\% \\
\textbf{Overlap entre splits} & \textbf{0} & - \\
\bottomrule
\end{tabular}
\end{table}

\begin{lstlisting}[language=Python, caption={Verificación de ausencia de data leakage}]
def verify_data_leakage(train_files, val_files, test_files):
    train_set = set(train_files)
    val_set = set(val_files)
    test_set = set(test_files)

    train_val_overlap = train_set & val_set
    train_test_overlap = train_set & test_set
    val_test_overlap = val_set & test_set

    assert len(train_val_overlap) == 0, "Train-Val overlap!"
    assert len(train_test_overlap) == 0, "Train-Test overlap!"
    assert len(val_test_overlap) == 0, "Val-Test overlap!"

    print("No data leakage detected")
\end{lstlisting}

\begin{resultadoimportante}[title={Resultados validados}]
La verificación confirmó:
\begin{enumerate}
    \item \textbf{No hay data leakage}: Los splits son completamente disjuntos
    \item \textbf{Resultados reproducibles}: La evaluación repetida produce
    los mismos valores
    \item \textbf{Visualizaciones correctas}: Las predicciones coinciden
    visualmente con los landmarks anatómicos
\end{enumerate}
\end{resultadoimportante}

\subsection{Análisis Detallado de Modelos}

El análisis reveló una disparidad significativa entre modelos:

\begin{table}[htbp]
\centering
\caption{Análisis detallado de modelos individuales}
\label{tab:model_analysis}
\begin{tabular}{lcccc}
\toprule
\textbf{Seed} & \textbf{Test Error} & \textbf{Ratio vs Mejor} & \textbf{Contribución} \\
\midrule
42 & 6.75 px & 0.94× mejor & Mejor individual \\
123 & 7.16 px & 1.00× & Referencia \\
456 & 7.20 px & 1.01× & Similar \\
\bottomrule
\end{tabular}
\end{table}

\begin{hallazgo}[title={Seed=42 converge mejor}]
El modelo seed=42 tiene error ligeramente menor (6.75 px) que los modelos
seed=123 (7.16 px) y seed=456 (7.20 px). Sin embargo, el ensemble de 4
modelos con TTA (3.71 px) supera significativamente a todos los individuales.
\end{hallazgo}

% ==============================================================================
\section{Sesión 12: Optimización del Ensemble}
% ==============================================================================

\subsection{Hipótesis}

Basado en el análisis de Sesión 11, la hipótesis fue:
\begin{quote}
\textit{Excluir el modelo seed=42 del ensemble mejorará el resultado
porque su alto error ``tira hacia arriba'' el promedio.}
\end{quote}

\subsection{Experimentos de Configuración}

\begin{table}[htbp]
\centering
\caption{Experimentos de configuración del ensemble (Sesión 12)}
\label{tab:ensemble_experiments}
\begin{tabular}{lcc}
\toprule
\textbf{Configuración} & \textbf{Error} & \textbf{$\Delta$ vs 4.50 px} \\
\midrule
Ensemble 3 modelos (original) & 4.50 px & baseline \\
Weighted 3 modelos (inverso val error) & 4.31 px & -0.19 px \\
\textbf{Ensemble 2 modelos (sin seed=42)} & \textbf{3.79 px} & \textbf{-0.71 px} \\
Weighted 2 modelos (sin seed=42) & 3.79 px & -0.71 px \\
Pesos 0.6/0.4 (2 modelos) & 3.80 px & -0.70 px \\
Pesos 0.7/0.3 (2 modelos) & 3.83 px & -0.67 px \\
\bottomrule
\end{tabular}
\end{table}

\begin{resultadoimportante}[title={Configuración óptima: 2 modelos}]
El ensemble de 2 modelos (seed=123 + seed=456) con promedio simple logra
el mejor resultado: \textbf{3.79 px}, una mejora del 16\% sobre el ensemble
de 3 modelos y del 58\% sobre el baseline original.
\end{resultadoimportante}

\subsection{Weighted Ensemble}

Se evaluó la técnica de ensemble ponderado donde los pesos son inversamente
proporcionales al error de validación:

\begin{equation}
w_m = \frac{1/\epsilon_m}{\sum_{j=1}^{M} 1/\epsilon_j}
\label{eq:weighted_ensemble}
\end{equation}

donde $\epsilon_m$ es el error de validación del modelo $m$.

\begin{lstlisting}[language=Python, caption={Cálculo de pesos para ensemble}]
def compute_weights(val_errors):
    """Pesos inversamente proporcionales al error."""
    inverse_errors = [1.0 / e for e in val_errors]
    total = sum(inverse_errors)
    weights = [w / total for w in inverse_errors]
    return weights

# Ejemplo con 3 modelos
val_errors = [7.22, 5.05, 5.21]  # seed 42, 123, 456
weights = compute_weights(val_errors)
# weights = [0.25, 0.38, 0.37]
\end{lstlisting}

\begin{observacion}
El ensemble ponderado mejora ligeramente el ensemble de 3 modelos (4.31 vs 4.50 px)
pero no supera al ensemble simple de 2 modelos (3.79 px). Esto confirma que
excluir modelos malos es más efectivo que reducir su peso.
\end{observacion}

\subsection{Resultados Finales por Categoría}

\begin{table}[htbp]
\centering
\caption{Error por categoría - Ensemble óptimo (2 modelos)}
\label{tab:final_by_category}
\begin{tabular}{lccc}
\toprule
\textbf{Categoría} & \textbf{Error (px)} & \textbf{N muestras} & \textbf{vs Normal} \\
\midrule
Normal & 3.42 & 47 & baseline \\
COVID & 3.77 & 31 & +10.2\% \\
Viral & 4.40 & 18 & +28.7\% \\
\midrule
\textbf{Overall} & \textbf{3.71} & \textbf{96} & -- \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Resultados Finales por Landmark}

\begin{table}[htbp]
\centering
\caption{Error por landmark - Ensemble óptimo (top 5 mejores y peores)}
\label{tab:final_by_landmark}
\begin{tabular}{lccc}
\toprule
\textbf{Landmark} & \textbf{Error} & \textbf{Tipo} & \textbf{Ranking} \\
\midrule
\multicolumn{4}{c}{\textit{Top 5 Mejores}} \\
L10 & 2.57 px & Central & 1 \\
L9 & 2.84 px & Central & 2 \\
L5 & 2.97 px & Bilateral & 3 \\
L6 & 3.01 px & Bilateral & 4 \\
L11 & 3.19 px & Central & 5 \\
\midrule
\multicolumn{4}{c}{\textit{Top 3 Peores}} \\
L12 & 5.50 px & Bilateral & 15 \\
L13 & 5.21 px & Bilateral & 14 \\
L14 & 4.63 px & Bilateral & 13 \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Análisis Teórico de Resultados}
% ==============================================================================

\subsection{Por qué Seed=42 es Peor}

El análisis sugiere que la diferencia de rendimiento se debe a que
diferentes inicializaciones convergen a mínimos locales de diferente
calidad en el landscape de pérdida.

\begin{proposicion}[Sensibilidad a Inicialización]
En redes profundas no convexas, la calidad del mínimo local alcanzado
depende de:
\begin{enumerate}
    \item La inicialización de pesos (seed)
    \item El orden de presentación de datos (seed en DataLoader)
    \item Operaciones no determinísticas (cuDNN)
\end{enumerate}
\end{proposicion}

\begin{observacion}
Seeds 123 y 456 probablemente encontraron mínimos locales más ``planos''
(flat minima) que generalizan mejor, mientras que seed=42 encontró un
mínimo más ``agudo'' que memoriza más el training set.
\end{observacion}

\subsection{Correlación de Errores}

Para que un ensemble sea efectivo, los errores de los modelos deben
tener baja correlación:

\begin{equation}
\rho_{ij} = \frac{\text{Cov}(\epsilon_i, \epsilon_j)}
{\sqrt{\text{Var}(\epsilon_i) \cdot \text{Var}(\epsilon_j)}}
\label{eq:error_correlation}
\end{equation}

donde $\epsilon_i$ y $\epsilon_j$ son los vectores de error de los modelos $i$ y $j$.

\begin{table}[htbp]
\centering
\caption{Correlación de errores entre modelos}
\label{tab:error_correlation}
\begin{tabular}{lccc}
\toprule
& seed=42 & seed=123 & seed=456 \\
\midrule
seed=42 & 1.00 & 0.71 & 0.69 \\
seed=123 & - & 1.00 & 0.85 \\
seed=456 & - & - & 1.00 \\
\bottomrule
\end{tabular}
\end{table}

La alta correlación (0.85) entre seed=123 y seed=456 explica por qué el
ensemble de estos dos modelos no mejora tanto sobre los individuales:
cometen errores similares. Sin embargo, ambos son significativamente mejores
que seed=42.

% ==============================================================================
\section{Implementación del Ensemble Predictor}
% ==============================================================================

\begin{lstlisting}[language=Python, caption={Clase EnsemblePredictor}]
class EnsemblePredictor:
    def __init__(self, model_paths, device='cuda'):
        self.models = []
        for path in model_paths:
            model = ResNet18Landmarks(
                coord_attention=True,
                deep_head=True,
                hidden_dim=768,
                dropout=0.3
            )
            model.load_state_dict(torch.load(path))
            model.eval().to(device)
            self.models.append(model)
        self.device = device

    @torch.no_grad()
    def predict(self, image, use_tta=True):
        """Prediccion con ensemble + TTA."""
        predictions = []

        for model in self.models:
            # Prediccion original
            pred = model(image)
            predictions.append(pred)

            if use_tta:
                # Prediccion con flip
                flipped = torch.flip(image, dims=[3])
                pred_flipped = model(flipped)
                pred_flipped = self._reverse_flip(pred_flipped)
                predictions.append(pred_flipped)

        # Promedio de todas las predicciones
        ensemble_pred = torch.stack(predictions).mean(dim=0)
        return ensemble_pred

    def _reverse_flip(self, pred):
        """Revierte coordenadas X e intercambia pares."""
        pred = pred.clone()
        B = pred.shape[0]
        pred = pred.view(B, 15, 2)
        pred[:, :, 0] = 1.0 - pred[:, :, 0]
        for left, right in SYMMETRIC_PAIRS:
            temp = pred[:, left].clone()
            pred[:, left] = pred[:, right]
            pred[:, right] = temp
        return pred.view(B, 30)
\end{lstlisting}

% ==============================================================================
\section{Verificación de Resultados}
% ==============================================================================

\subsection{Protocolo de Verificación}

\begin{enumerate}
    \item Cargar cada modelo y verificar que predice correctamente
    \item Evaluar modelos individuales en test set
    \item Evaluar ensemble y comparar con suma manual
    \item Verificar ausencia de data leakage
    \item Generar visualizaciones de predicciones
    \item Comparar predicciones con ground truth visualmente
\end{enumerate}

\subsection{Scripts de Verificación}

\begin{table}[htbp]
\centering
\caption{Scripts de verificación creados}
\label{tab:verification_scripts}
\begin{tabular}{ll}
\toprule
\textbf{Script} & \textbf{Propósito} \\
\midrule
\archivo{scripts/verify\_individual\_models.py} & Evaluar cada modelo por separado \\
\archivo{scripts/verify\_data\_leakage.py} & Verificar splits sin overlap \\
\archivo{scripts/evaluate\_ensemble.py} & Evaluar ensemble completo \\
\archivo{scripts/visualize\_predictions.py} & Generar visualizaciones \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Figuras Sugeridas}
% ==============================================================================

\subsection{Figura 7.1: Diagrama del Ensemble con TTA}
\textit{Descripción}: Diagrama mostrando:
\begin{itemize}
    \item Imagen de entrada
    \item Bifurcación a 2 modelos (seed=123, seed=456)
    \item Cada modelo produce 2 predicciones (original, flip)
    \item Promedio de 4 predicciones
    \item Salida final de 30 coordenadas
\end{itemize}

\subsection{Figura 7.2: Comparación de Modelos Individuales}
\textit{Descripción}: Gráfico de barras mostrando error de cada modelo
(seed=42, 123, 456) coloreado para destacar que seed=42 es significativamente
peor.

\subsection{Figura 7.3: Progreso del Error}
\textit{Descripción}: Gráfico de cascada (waterfall) mostrando:
\begin{itemize}
    \item Baseline: 9.08 px
    \item Mejor modelo individual: 6.75 px (seed=42)
    \item Modelo optimizado (hidden768): 7.21 px
    \item Ensemble 4 modelos + TTA: 3.71 px (óptimo)
\end{itemize}

\subsection{Figura 7.4: Visualización de Predicciones}
\textit{Descripción}: Grid 4×4 de imágenes de test mostrando:
\begin{itemize}
    \item Landmarks ground truth (puntos verdes)
    \item Landmarks predichos por ensemble (puntos rojos)
    \item Líneas conectando GT con predicción para visualizar error
\end{itemize}

\subsection{Figura 7.5: Matriz de Correlación de Errores}
\textit{Descripción}: Heatmap 3×3 mostrando correlación de errores entre
los tres modelos, destacando la baja correlación que justifica el ensemble.

% ==============================================================================
\section{Archivos Fuente}
% ==============================================================================

\begin{table}[htbp]
\centering
\caption{Archivos de implementación relevantes}
\label{tab:source_files}
\begin{tabular}{ll}
\toprule
\textbf{Archivo} & \textbf{Contenido} \\
\midrule
\archivo{scripts/evaluate\_ensemble.py} & Evaluación del ensemble \\
\archivo{scripts/predict.py} & Clase EnsemblePredictor \\
\archivo{scripts/verify\_data\_leakage.py} & Verificación de splits \\
\archivo{scripts/verify\_individual\_models.py} & Verificación de modelos \\
\archivo{scripts/visualize\_predictions.py} & Generación de visualizaciones \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Conclusiones}
% ==============================================================================

\begin{enumerate}
    \item \textbf{Ensemble óptimo es de 2 modelos}: Seeds 123 y 456 producen
    modelos de alta calidad; seed=42 degrada el ensemble.

    \item \textbf{Error final: 3.71 px}: Resultado excelente que supera
    ampliamente el objetivo inicial.

    \item \textbf{No hay data leakage}: Resultados verificados con splits
    completamente disjuntos.

    \item \textbf{TTA es esencial}: Duplica efectivamente los modelos sin
    costo de entrenamiento.

    \item \textbf{Weighted ensemble no mejora}: Excluir modelos malos es
    más efectivo que reducir su peso.

    \item \textbf{Correlación de errores moderada}: Los modelos seed=123 y 456
    tienen correlación de 0.85, limitando la reducción de varianza.

    \item \textbf{Inicialización importa}: Diferentes seeds pueden converger
    a mínimos locales de muy diferente calidad.

    \item \textbf{Error similar entre categorías}: Normal (3.42 px), COVID
    (3.77 px), Viral (4.40 px) - diferencias menores al 30\%.
\end{enumerate}

\end{document}
