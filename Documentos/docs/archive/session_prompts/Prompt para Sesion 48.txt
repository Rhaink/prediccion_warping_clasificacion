# PROMPT PARA SESION 48 - CORRECCION DE HALLAZGOS INTROSPECCION FINAL

**Fecha de creacion:** 2025-12-11
**Sesion anterior:** Sesion 47 (introspeccion final con 5 agentes)
**Rama:** feature/restructure-production

---

## CONTEXTO

En la Sesion 47 se realizo una introspeccion exhaustiva con 5 agentes paralelos que identificaron 23 problemas organizados por prioridad. Este prompt detalla las correcciones necesarias para dejar el proyecto listo para produccion.

---

## PROBLEMAS A CORREGIR (ORDENADOS POR PRIORIDAD)

### PRIORIDAD 1: CRITICOS (Hacer primero)

#### 1.1 Corregir per_category_landmarks en GROUND_TRUTH.json

**Archivo:** `GROUND_TRUTH.json`
**Lineas:** 152-157

**Actual (INCORRECTO - mezcla sesiones 12 y 13):**
```json
"per_category_landmarks": {
    "ensemble_4_tta": {
        "COVID": 3.83,
        "Normal": 3.53,
        "Viral_Pneumonia": 4.42
    }
}
```

**Correcto (valores de Sesion 13 - 4 modelos):**
```json
"per_category_landmarks": {
    "description": "Error por categoria con ensemble 4 modelos + TTA (Sesion 13)",
    "ensemble_4_tta": {
        "COVID": 3.77,
        "Normal": 3.42,
        "Viral_Pneumonia": 4.40
    }
}
```

**Fuente:** `docs/sesiones/SESION_13_ENSEMBLE_4_MODELOS.md` lineas 73-75

---

#### 1.2 Unificar valores de landmark errors entre scripts de visualizacion

**Problema:** `generate_bloque6_resultados.py` y `generate_results_figures.py` tienen valores diferentes

**Accion:**
1. Determinar la fuente oficial de errores por landmark
2. Crear constante en `GROUND_TRUTH.json` con los 15 valores
3. Actualizar ambos scripts para leer de GROUND_TRUTH.json

**Agregar a GROUND_TRUTH.json:**
```json
"per_landmark_errors": {
    "description": "Error por landmark con ensemble 4 modelos + TTA",
    "source": "SESION_13_ENSEMBLE_4_MODELOS",
    "values": {
        "L1": null, "L2": null, "L3": null, "L4": null, "L5": null,
        "L6": null, "L7": null, "L8": null, "L9": null, "L10": null,
        "L11": null, "L12": null, "L13": null, "L14": null, "L15": null
    }
}
```

**NOTA:** Buscar valores reales en logs de Sesion 13 o ejecutar evaluacion.

---

#### 1.3 Documentar/eliminar valores inventados en generate_bloque5_ensemble_tta.py

**Archivo:** `scripts/visualization/generate_bloque5_ensemble_tta.py`
**Lineas:** 453-456

**Valores sin fuente (mediana, maximo):**
- 8.15 px, 3.45 px, 3.31 px, 3.18 px (mediana)
- 28.4 px, 15.2 px, 14.1 px, 13.5 px (maximo)

**Opciones:**
1. Ejecutar evaluacion para obtener valores reales
2. Eliminar columnas de mediana/maximo de la tabla
3. Marcar claramente como "estimados"

---

#### 1.4 Marcar distribucion sintetica como generada

**Archivo:** `scripts/visualization/generate_bloque6_resultados.py`
**Lineas:** 446-451

**Agregar comentario claro:**
```python
# NOTA: Distribucion SINTETICA generada para visualizacion.
# NO son datos experimentales reales. Solo ilustrativa.
# Para datos reales, ver GROUND_TRUTH.json
errors = np.concatenate([...])
```

---

### PRIORIDAD 2: ALTOS (Importantes)

#### 2.1 Corregir 98.81% a 98.84% en scripts session30

**Archivos:**
- `scripts/session30_cross_evaluation.py` linea 8
- `scripts/session30_robustness_figure.py` linea 287
- `scripts/session30_error_analysis.py` lineas 41, 403, 511, 627

**Buscar y reemplazar:** `98.81` -> `98.84`

---

#### 2.2 Corregir factor robustez 30.5 a 30.45

**Archivos:**
- `scripts/create_thesis_figures.py` linea 238
- `docs/sesiones/SESION_34_VISUAL_GALLERY.md` linea 61

**Buscar y reemplazar:** `30.5` -> `30.45`

---

#### 2.3 Eliminar import F no usado

**Archivo:** `src_v2/models/resnet_landmark.py`
**Linea:** 9

**Eliminar:**
```python
import torch.nn.functional as F
```

---

#### 2.4 Usar SYMMETRIC_PAIRS en lugar de BILATERAL_PAIRS

**Archivo:** `src_v2/models/hierarchical.py`

**Cambios:**
1. Eliminar definicion de `BILATERAL_PAIRS` (lineas 55-61)
2. Importar `SYMMETRIC_PAIRS` de constants.py
3. Cambiar `self.BILATERAL_PAIRS` a `SYMMETRIC_PAIRS`

---

#### 2.5 Reemplazar magic number 3 en losses.py

**Archivo:** `src_v2/models/losses.py`
**Linea:** 221

**Actual:**
```python
loss = total_dist / 3
```

**Correcto:**
```python
loss = total_dist / len(CENTRAL_LANDMARKS)
```

---

#### 2.6 Corregir tolerancias en test_evaluation_metrics.py

**Archivo:** `tests/test_evaluation_metrics.py`

**Cambios:**
- Linea 132: `abs=1e-5` -> `abs=0.5` (segun GROUND_TRUTH tolerances)
- Linea 213: `abs=1e-6` -> `abs=0.01`

**Agregar comentario:**
```python
# Tolerancia de GROUND_TRUTH.json: landmark_error_px.absolute = 0.5
```

---

#### 2.7 Mejorar manejo de skips en test_robustness_comparative.py

**Archivo:** `tests/test_robustness_comparative.py`

**Opcion 1 - Decorador explÃ­cito:**
```python
@pytest.mark.skipif(
    not Path("outputs/robustness_test_results.json").exists(),
    reason="Robustness data not available - run test-robustness first"
)
def test_warped_more_robust_to_jpeg_than_original(self, robustness_results):
```

**Opcion 2 - Fixture con warning:**
```python
@pytest.fixture
def robustness_results(self):
    results = {}
    missing = []
    if not Path("outputs/robustness_test_results.json").exists():
        missing.append("robustness_test_results.json")
    if missing:
        warnings.warn(f"Missing robustness data files: {missing}")
    return results
```

---

#### 2.8 Subir umbral de robustez en test

**Archivo:** `tests/test_robustness_comparative.py`
**Linea:** 83

**Actual:**
```python
assert ratio >= 5
```

**Correcto:**
```python
# GROUND_TRUTH.json: jpeg_q50_vs_original = 30.45
# Permitimos 30% de variacion: 30.45 * 0.7 = 21.3
assert ratio >= 20, f"Expected at least 20x robustness (GROUND_TRUTH=30.45x), got {ratio:.1f}x"
```

---

### PRIORIDAD 3: MEDIOS (Mejoras de calidad)

#### 3.1 Refactorizar vector perpendicular en data/utils.py

**Archivo:** `src_v2/data/utils.py`
**Linea:** 267

**Actual:**
```python
perp = np.array([-eje_unit[1], eje_unit[0]])
```

**Opcion 1 - Crear version NumPy en geometry.py:**
```python
def compute_perpendicular_vector_np(axis_vec: np.ndarray) -> np.ndarray:
    """Version NumPy de compute_perpendicular_vector."""
    axis_len = np.linalg.norm(axis_vec) + 1e-8
    axis_unit = axis_vec / axis_len
    return np.array([-axis_unit[1], axis_unit[0]])
```

---

#### 3.2 Extraer indices de landmarks centrales a constante

**Archivo:** `src_v2/constants.py`

**Agregar:**
```python
# Landmarks centrales con sus posiciones t sobre el eje L1-L2
CENTRAL_LANDMARKS_T: List[Tuple[int, float]] = [
    (8, 0.25),   # L9
    (9, 0.50),   # L10
    (10, 0.75),  # L11
]
```

**Actualizar:** `src_v2/models/hierarchical.py` linea 207

---

#### 3.3 Usar constantes para learning rates

**Archivo:** `src_v2/models/hierarchical.py`
**Linea:** 250

**Cambiar:**
```python
def get_trainable_params(
    self,
    backbone_lr: float = DEFAULT_PHASE2_BACKBONE_LR,
    head_lr: float = DEFAULT_PHASE2_HEAD_LR
):
```

---

#### 3.4 Mejorar assertion en test_cli_integration.py

**Archivo:** `tests/test_cli_integration.py`
**Linea:** 61

**Actual:**
```python
assert result.exit_code in [0, 1]
```

**Opcion recomendada - Diferencias los casos:**
```python
if result.exit_code == 1:
    # Fallo controlado por dataset pequeno - aceptable en test sintetico
    assert "split" in result.stdout.lower() or "insufficient" in result.stdout.lower(), \
        f"Unexpected failure (code 1): {result.stdout}"
else:
    assert result.exit_code == 0, f"Training crashed: {result.stdout}"
```

---

#### 3.5 Importar valores de GROUND_TRUTH en tests

**Archivo:** `tests/test_robustness_comparative.py`

**Agregar al inicio:**
```python
import json
from pathlib import Path

def load_ground_truth():
    gt_path = Path(__file__).parent.parent / "GROUND_TRUTH.json"
    with open(gt_path) as f:
        return json.load(f)

GROUND_TRUTH = load_ground_truth()
```

**Usar en tests:**
```python
orig_deg = GROUND_TRUTH["robustness"]["jpeg_q50"]["original_100"]
warp_deg = GROUND_TRUTH["robustness"]["jpeg_q50"]["warped_47"]
```

---

### PRIORIDAD 4: BAJOS (Post-sesion)

#### 4.1 Corregir porcentaje Viral

**Archivo:** `scripts/visualization/generate_bloque6_resultados.py`
**Linea:** 124

**Cambiar:** `'mejora': 51` -> `'mejora': 50` o `'mejora': 50.5`

---

#### 4.2 Agregar tests para funciones de warp.py

**Archivo:** `tests/test_processing.py` (nuevo o existente)

**Funciones a testear:**
- `_triangle_area_2x()`
- `scale_landmarks_from_centroid()`
- `get_affine_transform_matrix()`
- `warp_triangle()`

---

## RESUMEN DE TAREAS

### Sesion 48 - Tareas Criticas:
1. [ ] Corregir per_category_landmarks en GROUND_TRUTH.json
2. [ ] Unificar valores de landmark errors o documentar diferencias
3. [ ] Documentar valores inventados en scripts de visualizacion
4. [ ] Marcar distribucion sintetica como generada

### Sesion 48 - Tareas Altas:
5. [ ] Corregir 98.81% a 98.84% en scripts session30
6. [ ] Corregir factor robustez 30.5 a 30.45
7. [ ] Eliminar import F no usado en resnet_landmark.py
8. [ ] Usar SYMMETRIC_PAIRS en hierarchical.py
9. [ ] Reemplazar magic number 3 en losses.py
10. [ ] Corregir tolerancias en test_evaluation_metrics.py
11. [ ] Mejorar manejo de skips en tests
12. [ ] Subir umbral de robustez en test

### Sesion 48 - Tareas Medias:
13. [ ] Refactorizar vector perpendicular en data/utils.py
14. [ ] Extraer CENTRAL_LANDMARKS_T a constantes
15. [ ] Usar constantes para learning rates
16. [ ] Mejorar assertions en test_cli_integration.py
17. [ ] Importar GROUND_TRUTH en tests

### Post-Sesion 48:
18. [ ] Corregir porcentaje Viral
19. [ ] Agregar tests para funciones de warp.py

---

## VERIFICACION FINAL

Despues de las correcciones:
```bash
# Ejecutar tests
.venv/bin/python -m pytest tests/ -v

# Verificar GROUND_TRUTH.json
cat GROUND_TRUTH.json | python -m json.tool

# Verificar no hay 98.81 en scripts
grep -r "98.81" scripts/

# Verificar no hay 30.5 incorrecto
grep -rn "30\.5" scripts/ docs/ | grep -v "30.45"

# Verificar imports limpios
.venv/bin/python -c "from src_v2.models.resnet_landmark import *; print('OK')"
```

**Meta:** 613+ tests pasando, valores consistentes con GROUND_TRUTH.json.

---

## ARCHIVOS DE REFERENCIA

- **GROUND_TRUTH.json**: Fuente de verdad (a corregir)
- **docs/sesiones/SESION_47_INTROSPECCION_FINAL.md**: Hallazgos detallados
- **docs/sesiones/SESION_13_ENSEMBLE_4_MODELOS.md**: Valores correctos per-category
- **docs/REFERENCIA_SESIONES_FUTURAS.md**: Documento maestro

---

## NOTAS IMPORTANTES

1. **VERIFICAR antes de corregir** valores per-category contra logs de Sesion 13
2. **NO eliminar archivos** historicos de documentacion - son evidencia del proceso
3. **Ejecutar tests** despues de cada modificacion importante
4. Los valores [3.77, 3.42, 4.40] son de Sesion 13 (4 modelos), NO Sesion 12 (2 modelos)
5. El valor 30.45x es el calculo exacto de 16.14/0.53

---

**FIN DEL PROMPT SESION 48**
