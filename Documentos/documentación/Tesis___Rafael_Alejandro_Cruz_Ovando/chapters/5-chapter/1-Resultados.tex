\chapter{Resultados y Discusión}
\label{cap:resultados_discusion}
Este capítulo presenta los resultados experimentales obtenidos de la implementación y evaluación de la metodología MaShDL-CNN Hybrid propuesta para la alineación y normalización de la forma de la región pulmonar, así como los resultados de la subsiguiente tarea de clasificación de neumonía y COVID-19. Los hallazgos se analizan en detalle, se discuten en el contexto de los objetivos de la tesis y se comparan con enfoques previos y alternativos. El objetivo es demostrar cuantitativa y cualitativamente la eficacia del sistema desarrollado y validar las hipótesis planteadas.

\section{Resultados de la Etapa de Alineación y Normalización de la Forma Pulmonar (MaShDL-CNN Hybrid)}
\label{sec:resultados_alineacion_normalizacion}
La primera fase de la evaluación se centró en el rendimiento del componente MaShDL-CNN Hybrid para la predicción de los coeficientes de forma $b_k$ del Modelo Estadístico de Forma (SSM) y la calidad de la segmentación pulmonar resultante. Estos resultados se derivan de los experimentos descritos en la Sección~\ref{sec:experimentos_optimizacion_alineacion}, utilizando los scripts \code{train_mashdl_cnn_hybrid.py} para el entrenamiento, \code{generate_predictions_cnn.py} para la predicción de $b_k$, \code{main_desdiscretizer.py} para la conversión a valores continuos, y \code{evaluate_segmentation.py} para el cálculo del coeficiente de Dice.

\subsection{Rendimiento en la Predicción de Coeficientes de Forma $b_k$}
\label{ssec:resultados_prediccion_bk}
La capacidad del modelo MaShDL-CNN Hybrid para aprender el mapeo desde la apariencia local de los parches 2D hacia los coeficientes de forma $b_k$ se midió principalmente mediante la exactitud de validación (ValAcc) en la clasificación de los bins discretizados de $b_k$. El informe de progreso (Sección 4.2) documenta varias iteraciones experimentales.

\subsubsection{Línea Base y Primeras Iteraciones (Parches $Q=25$)}
\label{sssec:resultados_bk_q25}
Los experimentos iniciales se realizaron con parches de entrada de tamaño $Q=25 \times 25$ píxeles.
\begin{itemize}
    \item \textbf{Corrida Inicial (Benchmark):} Con una arquitectura Sub-CNN de 2 capas convolucionales (filtros \code{[32,64]}), $\text{dim\_features\_per\_patch}=64$ y una DNN con capas ocultas \code{[128,64]}, se observó:
    \begin{itemize}
        \item Para 3 modos $b_k$ entrenados durante $\sim$30-60 épocas (detenido por \textit{Early Stopping}), la ValAcc promedio fue de aproximadamente \num{0.6378}.
        \item Al entrenar para 10 modos $b_k$, la ValAcc promedio general disminuyó a \num{0.5236}. Se observó un buen rendimiento para los primeros modos ($k_0-k_4$), pero un decaimiento significativo para los modos superiores ($k_5-k_9$). Esto sugiere que los parches de $Q=25$ podrían no capturar suficiente información para discriminar las variaciones más sutiles asociadas con los modos de mayor orden.
    \end{itemize}
    \item \textbf{Experimento 1 (CNN más Profunda - 3 capas):} Utilizando $Q=25$ y 5 modos $b_k$, se incrementó la profundidad de la Sub-CNN a 3 capas (filtros \code{[32,64,128]}) manteniendo $\text{dim\_features\_per\_patch}=64$ y la DNN \code{[128,64]}. Esto resultó en una mejora marginal en la ValAcc promedio para los modos $k_0-k_4$, alcanzando aproximadamente \num{0.6260} (un incremento desde $\approx \num{0.6202}$ con 2 capas para los mismos 5 modos).
    \item \textbf{Experimento 2 (CNN 3 capas + Mayor \code{dim_features_per_patch} y DNN más Grande):} Manteniendo $Q=25$ y 5 modos $b_k$ con la CNN de 3 capas, se aumentó $\text{dim\_features\_per\_patch}$ a 128 y la DNN a \code{[256,128]}. Este cambio no produjo una mejora clara, con una ValAcc promedio ligeramente inferior de \num{0.6226} y un aumento en la pérdida de validación, sugiriendo un posible sobreajuste o que la información adicional no era beneficiosa con parches de $Q=25$.
\end{itemize}
La Tabla~\ref{tab:resultados_valacc_q25} resume estos hallazgos para $Q=25$. Las curvas de entrenamiento (pérdida y exactitud vs. épocas) generadas por \code{plot_training_history} en \code{train_mashdl_cnn_hybrid.py} (ver Figura~\ref{fig:curvas_entrenamiento_q25_ejemplo}) ilustran la dinámica de aprendizaje para estas configuraciones.

\begin{tableH}
    \centering
    \caption[Resultados de Exactitud de Validación (ValAcc) para la predicción de $b_k$ con parches $Q=25$]{Resumen de la Exactitud de Validación (ValAcc) promedio obtenida para diferentes configuraciones del modelo MaShDL-CNN Hybrid utilizando parches de entrada de tamaño $Q=25 \times 25$. Los resultados se basan en el informe de progreso.}
    \label{tab:resultados_valacc_q25}
    \sisetup{round-mode=places,round-precision=4} % Para siunitx, si se desea redondear
    \begin{tabular}{@{}l c c c c S[table-format=1.4]@{}}
        \toprule
        Configuración Experimental & \shortstack{Modos $b_k$\\Entrenados} & \shortstack{Capas\\CNN} & \shortstack{Filtros CNN\\(\code{config})} & \shortstack{Dim. Feat.\\por Parche} & \shortstack{DNN Unidades\\(\code{config})} & {ValAcc Promedio} \\
        \midrule
        Benchmark (100 épocas) & 3 & 2 & \code{[32,64]} & 64 & \code{[128,64]} & 0.6378 \\
        Benchmark (100 épocas) & 10 & 2 & \code{[32,64]} & 64 & \code{[128,64]} & 0.5236 \\
        Exp. 1 (vs. 2 capas, 5 modos) & 5 & 3 & \code{[32,64,128]} & 64 & \code{[128,64]} & 0.6260 \\
        Exp. 2 & 5 & 3 & \code{[32,64,128]} & 128 & \code{[256,128]} & 0.6226 \\
        \bottomrule
    \end{tabular}
    \vspace{0.2cm}
    \footnotesize{\textit{Nota: La ValAcc es promedio sobre los modos $b_k$ entrenados para cada configuración.}}
\end{tableH}

\subsubsection{Resultados Esperados del Experimento con Parches $Q=41$ (Experimento 3)}
\label{sssec:resultados_esperados_bk_q41}
Como se detalló en la Sección~\ref{ssec:exp_q41}, el Experimento 3, que utiliza parches de $Q=41 \times 41$ y un aumento de datos más exhaustivo (\code{AUGMENTATION_PROBABILITY = 1.0}), está diseñado para abordar las limitaciones observadas con $Q=25$.
\begin{itemize}
    \item \textbf{Hipótesis:} Se espera que los parches más grandes capturen mayor información contextual y espacial, lo que debería permitir a la Sub-CNN aprender características más discriminantes, especialmente para los modos de variación $b_k$ más sutiles y de orden superior.
    \item \textbf{Métricas a Evaluar:}
    \begin{itemize}
        \item ValAcc promedio y por modo para los $b_k$ (se espera una mejora significativa, especialmente para $k \ge 4$).
        \item Curvas de entrenamiento (se observará si la convergencia es más estable o si se alcanzan mayores niveles de ValAcc).
    \end{itemize}
\end{itemize}
Los resultados de este experimento, una vez completados, se presentarán en un formato similar a la Tabla~\ref{tab:resultados_valacc_q25} y la Figura~\ref{fig:curvas_entrenamiento_q25_ejemplo}, permitiendo una comparación directa del impacto del tamaño del parche. Se anticipa que la ValAcc para la predicción de $b_k$ mejorará notablemente con $Q=41$.

\subsection{Rendimiento de la Segmentación Pulmonar (Coeficiente de Dice)}
\label{ssec:resultados_segmentacion_dice}
El rendimiento final de la etapa de alineación y normalización se mide por la calidad de la segmentación pulmonar, evaluada mediante el coeficiente de Dice (DSC) entre la máscara predicha por el sistema y la máscara Ground Truth (GT) generada consistentemente (ver Sección~\ref{sec:generacion_gt_masks_metodologia}). Los resultados de DSC son calculados por el script \code{evaluate_segmentation.py}.

\subsubsection{Resultados con Parches $Q=25$}
\label{sssec:resultados_dice_q25}
El informe de progreso (Sección 4.6) proporciona los siguientes resultados de DSC para configuraciones con parches $Q=25$ y una Sub-CNN de 2 capas, entrenada durante 100 épocas (con \textit{Early Stopping}):
\begin{itemize}
    \item \textbf{Utilizando 3 modos $b_k$ predichos para la reconstrucción:}
    \begin{itemize}
        \item Estrategia de máscara ``Dos Contornos'': DSC Promedio $\approx \num{0.652}$, DSC Mediana $\approx \num{0.764}$.
        \item Estrategia de máscara ``Convex Hull All'': DSC Promedio $\approx \num{0.674}$, DSC Mediana $\approx \num{0.793}$.
    \end{itemize}
    \item \textbf{Utilizando 10 modos $b_k$ predichos para la reconstrucción:}
    \begin{itemize}
        \item Estrategia de máscara ``Dos Contornos'': DSC Promedio $\approx \num{0.652}$, DSC Mediana $\approx \num{0.779}$.
        \item Estrategia de máscara ``Convex Hull All'': DSC Promedio $\approx \num{0.674}$, DSC Mediana $\approx \num{0.802}$.
    \end{itemize}
\end{itemize}
Estos resultados se resumen en la Tabla~\ref{tab:resultados_dice_q25_configuraciones}. Se observa que, para $Q=25$, aumentar el número de modos $b_k$ predichos de 3 a 10 no produjo una mejora significativa en el DSC promedio. Esto es consistente con la observación de que la predicción de los modos $b_k$ superiores era deficiente con parches pequeños. La estrategia de ``Convex Hull All'' consistentemente produjo un DSC promedio ligeramente superior, aunque la mediana fue similar para ambas.

\begin{tableH}
    \centering
    \caption[Resultados del Coeficiente de Dice (DSC) para segmentación pulmonar con $Q=25$]{Resumen de los scores del Coeficiente de Dice (DSC) promedio y mediana para diferentes configuraciones de reconstrucción, utilizando modelos MaShDL-CNN Hybrid entrenados con parches $Q=25$ y una Sub-CNN de 2 capas.}
    \label{tab:resultados_dice_q25_configuraciones}
    \sisetup{round-mode=places,round-precision=3}
    \begin{tabular}{@{}l c c S[table-format=1.3]@{}}
        \toprule
        Estrategia de Máscara Predicha & \shortstack{Modos $b_k$\\Usados} & Métrica DSC & {Valor} \\
        \midrule
        \multirow{2}{*}{Dos Contornos} & \multirow{2}{*}{3} & Promedio & 0.652 \\
                                     &                    & Mediana  & 0.764 \\
        \midrule
        \multirow{2}{*}{Convex Hull All} & \multirow{2}{*}{3} & Promedio & 0.674 \\
                                       &                    & Mediana  & 0.793 \\
        \midrule
        \multirow{2}{*}{Dos Contornos} & \multirow{2}{*}{10} & Promedio & 0.652 \\
                                     &                     & Mediana  & 0.779 \\
        \midrule
        \multirow{2}{*}{Convex Hull All} & \multirow{2}{*}{10} & Promedio & 0.674 \\
                                       &                     & Mediana  & 0.802 \\
        \bottomrule
    \end{tabular}
\end{tableH}

La Figura~\ref{fig:ejemplos_segmentacion_q25} muestra ejemplos visuales de segmentaciones obtenidas con $Q=25$, ilustrando tanto casos exitosos como aquellos con errores, que pueden estar relacionados con la predicción inexacta de la forma.

\subsubsection{Resultados Esperados con Parches $Q=41$ (Experimento 3)}
\label{sssec:resultados_esperados_dice_q41}
Se espera que los modelos entrenados con parches $Q=41$ (Experimento 3) produzcan una mejora sustancial en el Coeficiente de Dice.
\begin{itemize}
    \item \textbf{Hipótesis:} Si la ValAcc para la predicción de los $b_k$ (especialmente los modos superiores) mejora con $Q=41$, la forma reconstruida será más precisa, lo que se traducirá directamente en un mayor DSC.
    \item \textbf{Análisis:} Se compararán los DSC promedio y mediana obtenidos con $Q=41$ (para, e.g., 5 o 7 modos $b_k$ predichos) con los resultados de $Q=25$. También se analizará si la estrategia de ``Dos Contornos'' se beneficia más de la predicción mejorada de modos finos en comparación con ``Convex Hull All''.
\end{itemize}
Se generará una tabla similar a la Tabla~\ref{tab:resultados_dice_q25_configuraciones} para presentar estos resultados y se realizarán análisis visuales comparativos.

\subsection{Discusión de los Resultados de Alineación y Normalización}
\label{ssec:discusion_resultados_alineacion}
Los resultados preliminares con parches $Q=25$ indican que el pipeline MaShDL-CNN Hybrid es viable, logrando scores de Dice (e.g., $\approx \num{0.67}$ promedio, $\approx \num{0.80}$ mediana con Convex Hull) que representan una mejora sobre el estancamiento previo en $\num{0.57}-\num{0.61}$ con el método basado en perfiles 1D. Esto valida la hipótesis de que el uso de información 2D y CNNs es beneficioso.

Sin embargo, la dificultad para predecir los modos de variación $b_k$ de orden superior con $Q=25$ sugiere que el contexto local capturado por estos parches más pequeños es insuficiente para las deformaciones más finas. Los experimentos con la arquitectura de la CNN (aumentar profundidad o capacidad) sobre $Q=25$ no produjeron ganancias significativas, reforzando la idea de que el tamaño del parche (y por ende, la cantidad de información de entrada) es un factor limitante más crítico en este escenario.

El Experimento 3 con $Q=41$ es, por lo tanto, fundamental. Si este experimento demuestra una mejora tanto en la ValAcc de los $b_k$ como en el Coeficiente de Dice de la segmentación, confirmará que un mayor contexto local es clave. La discusión también deberá considerar el costo computacional incremental de usar parches más grandes y arquitecturas potencialmente más profundas.

Otro punto de discusión es la elección de la estrategia para generar la máscara final a partir de los 144 puntos predichos. ``Convex Hull All'' tiende a producir máscaras más suaves y puede ser más robusta a errores aislados en la predicción de landmarks individuales, lo que podría explicar su ligero mejor rendimiento promedio. Sin embargo, ``Dos Contornos'' tiene el potencial de capturar concavidades (como la incisura cardíaca) si los landmarks son muy precisos. Una mejor predicción de $b_k$ con $Q=41$ podría hacer que ``Dos Contornos'' se vuelva más competitiva o incluso superior.

Finalmente, la generación de máscaras Ground Truth consistentes (\code{generate_gt_masks_from_144pts.py}) fue un paso metodológico crucial. Asegurar que la GT se derive de la misma representación de 144 puntos que el SSM garantiza que el DSC mida fielmente la capacidad del modelo para replicar la forma definida por el SSM, en lugar de discrepar debido a definiciones de GT inconsistentes.

\section{Resultados de la Detección de Neumonía y COVID-19}
\label{sec:resultados_deteccion_enfermedad}
Esta sección presentará los resultados de la tarea final de clasificación de enfermedades (sano, neumonía, COVID-19) utilizando las regiones pulmonares segmentadas y normalizadas por el sistema MaShDL-CNN Hybrid (y los sistemas de comparación). Los clasificadores a evaluar son KNN, MLP y una CNN específica para enfermedad, como se describió en la Sección~\ref{ssec:clasificadores_a_evaluar}.
(Nota: Dado que estos resultados dependen de la finalización de la optimización del MaShDL-CNN Hybrid y de la implementación/entrenamiento de los clasificadores de enfermedad, esta sección se estructurará para presentar los tipos de resultados que se generarán. Los valores numéricos se completarán una vez que los experimentos estén concluidos.)

\subsection{Rendimiento del Clasificador Baseline (Sin Alineación/Normalización)}
\label{ssec:resultados_baseline_enfermedad}
Se presentarán los resultados de los clasificadores (KNN, MLP, CNN de enfermedad) entrenados con características extraídas directamente de las imágenes CXR originales o de una ROI definida de forma simple (ver Sección~\ref{ssec:escenarios_comparacion}).
\begin{itemize}
    \item Se reportarán métricas como Precisión, Sensibilidad, Especificidad, F1-Score y AUC para cada clasificador y cada clase.
    \item Se incluirán Matrices de Confusión y Curvas ROC.
\end{itemize}
Estos resultados servirán como el punto de partida para evaluar el beneficio de los métodos de normalización.

\begin{tableH}
    \centering
    \caption[Rendimiento de los clasificadores de enfermedad SIN alineación/normalización (Baseline)]{Métricas de rendimiento para los clasificadores KNN, MLP y CNN de enfermedad, entrenados y evaluados sobre el conjunto de prueba sin aplicar el proceso de alineación y normalización de la forma pulmonar.}
    \label{tab:resultados_clasificacion_baseline}
    \begin{tabular}{@{}l l c c c c c@{}}
        \toprule
        Clasificador & Clase & Precisión & Sensibilidad & Especificidad & F1-Score & AUC \\
        \midrule
        \multirow{3}{*}{KNN} & Sano & $P_{KNN,S}$ & $R_{KNN,S}$ & $S_{KNN,S}$ & $F1_{KNN,S}$ & $AUC_{KNN,S}$ \\
                             & Neumonía & $P_{KNN,P}$ & $R_{KNN,P}$ & $S_{KNN,P}$ & $F1_{KNN,P}$ & $AUC_{KNN,P}$ \\
                             & COVID-19 & $P_{KNN,C}$ & $R_{KNN,C}$ & $S_{KNN,C}$ & $F1_{KNN,C}$ & $AUC_{KNN,C}$ \\
        \midrule
        \multirow{3}{*}{MLP} & Sano & $P_{MLP,S}$ & $R_{MLP,S}$ & $S_{MLP,S}$ & $F1_{MLP,S}$ & $AUC_{MLP,S}$ \\
                             & Neumonía & $P_{MLP,P}$ & $R_{MLP,P}$ & $S_{MLP,P}$ & $F1_{MLP,P}$ & $AUC_{MLP,P}$ \\
                             & COVID-19 & $P_{MLP,C}$ & $R_{MLP,C}$ & $S_{MLP,C}$ & $F1_{MLP,C}$ & $AUC_{MLP,C}$ \\
        \midrule
        \multirow{3}{*}{CNN Enf.} & Sano & $P_{CNN,S}$ & $R_{CNN,S}$ & $S_{CNN,S}$ & $F1_{CNN,S}$ & $AUC_{CNN,S}$ \\
                             & Neumonía & $P_{CNN,P}$ & $R_{CNN,P}$ & $S_{CNN,P}$ & $F1_{CNN,P}$ & $AUC_{CNN,P}$ \\
                             & COVID-19 & $P_{CNN,C}$ & $R_{CNN,C}$ & $S_{CNN,C}$ & $F1_{CNN,C}$ & $AUC_{CNN,C}$ \\
        \bottomrule
    \end{tabular}
    \vspace{0.2cm}
    \footnotesize{\textit{Nota: Los valores $P, R, S, F1, AUC$ serán completados con los resultados experimentales.}}
\end{tableH}

\subsection{Rendimiento del Clasificador con Alineación MaShDL Original (Perfiles 1D)}
\label{ssec:resultados_mashdl_original_enfermedad}
Se presentarán los resultados de los mismos clasificadores utilizando características extraídas de las regiones pulmonares alineadas por el método MaShDL anterior (basado en perfiles de intensidad 1D, entrenado con \code{train_mashdl_classifiers_v12_mod6_profile_input.py}). El formato de presentación de resultados (tablas, figuras) será idéntico al del escenario baseline para facilitar la comparación.

\subsection{Rendimiento del Clasificador con Alineación MaShDL-CNN Hybrid}
\label{ssec:resultados_mashdl_cnn_hybrid_enfermedad} % Título corregido para esta subsección
Finalmente, se presentarán los resultados de los clasificadores utilizando características extraídas de las regiones pulmonares alineadas y normalizadas por el sistema MaShDL-CNN Hybrid propuesto (idealmente, con la configuración óptima obtenida del Experimento 3 con $Q=41$).
\begin{itemize}
    \item Se espera que estos resultados muestren una mejora en las métricas de clasificación en comparación con los dos escenarios anteriores.
    \item La Tabla~\ref{tab:resultados_clasificacion_mashdl_cnn} (similar a la Tabla~\ref{tab:resultados_clasificacion_baseline}, necesitará su propia etiqueta y caption) resumirá estos hallazgos.
    \item La Figura~\ref{fig:curvas_roc_comparativas} mostrará las curvas ROC para el mejor clasificador en los tres escenarios (Baseline, MaShDL Original, MaShDL-CNN Hybrid) para una clase de interés (e.g., COVID-19), permitiendo una comparación visual directa de los AUCs.
\end{itemize}

% \begin{figureH}
%     \centering
%     \includegraphics[width=0.7\linewidth]{ruta/a/tu/curvas_roc_comparativas.png} % REEMPLAZA
%     \caption[Curvas ROC comparativas para la detección de COVID-19]{Curvas ROC comparativas para la detección de COVID-19 utilizando el mejor clasificador (e.g., CNN de enfermedad) en tres escenarios: (1) Sin alineación (Baseline), (2) Con alineación MaShDL Original (Perfiles 1D), y (3) Con alineación MaShDL-CNN Hybrid (Parches 2D). Se indican los valores de AUC para cada curva.}
%     \label{fig:curvas_roc_comparativas}
% \end{figureH}

\subsection{Análisis Comparativo y Estadístico de los Clasificadores de Enfermedad}
\label{ssec:analisis_comparativo_clasificadores}
Se realizará un análisis comparativo detallado del rendimiento de los clasificadores en los tres escenarios.
\begin{itemize}
    \item Se discutirán las diferencias observadas en las métricas y se intentará atribuirlas al impacto de la normalización de forma.
    \item Se podrán aplicar pruebas de significancia estadística (e.g., test t de Student pareado, ANOVA, o pruebas no paramétricas como Wilcoxon signed-rank test) para determinar si las diferencias de rendimiento entre los escenarios son estadísticamente significativas \cite{demvsar2006statistical}.
    \item Se analizarán las matrices de confusión para identificar qué tipos de errores de clasificación son más comunes en cada escenario y si la normalización ayuda a reducir confusiones específicas entre clases.
\end{itemize}

\section{Discusión General}
\label{sec:discusion_general_resultados}
En esta sección final del capítulo, se sintetizarán e interpretarán los hallazgos clave de ambas fases de evaluación (alineación/normalización y detección de enfermedad).
\begin{itemize}
    \item \textbf{Validación de la Hipótesis:} Se discutirá en qué medida los resultados validan la hipótesis central de la tesis: que el enfoque MaShDL-CNN Hybrid mejora la alineación de forma y, consecuentemente, la detección de patologías.
    \item \textbf{Cumplimiento de Objetivos (Parcial):} Se evaluará cómo los resultados presentados contribuyen al cumplimiento de los objetivos específicos relacionados con el diseño, implementación y evaluación del método de alineación y la comparación de clasificadores.
    \item \textbf{Comparación con el Estado del Arte:} Se contrastarán cualitativamente los resultados obtenidos (tanto de Dice como de clasificación de enfermedad) con los reportados en la literatura para tareas similares (revisados en el Capítulo~\ref{cap:marco_teorico}). Se destacarán las fortalezas y posibles ventajas del método propuesto.
    \item \textbf{Impacto del Tamaño del Parche ($Q$) y Aumento de Datos:} Se profundizará en la discusión sobre cómo el Experimento 3 ($Q=41$) influyó en los resultados finales de segmentación y, potencialmente, en la clasificación de enfermedad.
    \item \textbf{Limitaciones del Estudio:} Se identificarán y discutirán las limitaciones de los experimentos realizados, por ejemplo, relacionadas con el tamaño o la diversidad de los conjuntos de datos, las elecciones arquitectónicas, o los recursos computacionales.
    \item \textbf{Análisis de Casos de Fallo:} Se presentarán y analizarán ejemplos de imágenes donde el sistema MaShDL-CNN Hybrid tuvo un rendimiento subóptimo (bajo Dice o clasificación incorrecta) para identificar posibles causas y áreas de mejora futura.
\end{itemize}
Esta discusión sentará las bases para las conclusiones y recomendaciones de trabajo futuro que se presentarán en el Capítulo~\ref{cap:conclusiones_trabajo_futuro}.