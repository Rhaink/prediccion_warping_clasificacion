% % Asegúrate de que estos comandos están definidos en tu preámbulo:
% % \newcommand{\mat}[1]{\mathbf{#1}}   
% % \newcommand{\vect}[1]{\bm{#1}} % Requiere \usepackage{bm}
% % \newcommand{\transpose}{\mathsf{T}}
% % \newcommand{\R}{\mathbb{R}} 
% % \newcommand{\Ktotal}{K_{\text{total}}} % Si definiste K_total como macro

% \section{Predicción y Desdiscretización de Coeficientes de Forma }
% \label{sec:prediccion_desdiscretizacion_b}

% Una vez que los $m$ clasificadores basados en Redes Neuronales Convolucionales (CNN) híbridas han sido entrenados individualmente para cada modo de variación $k \in \{0, \dots, m-1\}$ (Sección~\ref{sec:entrenamiento_cnn}), estos se emplean para inferir los parámetros de forma $\vect{b} = (b_0, \dots, b_{m-1})^\transpose$ para nuevas imágenes. Este proceso inferencial es fundamental y consta de dos etapas secuenciales: la predicción de los bins discretos para cada coeficiente $b_k$ y la subsecuente conversión de estos bins a valores continuos que puedan ser utilizados por el Modelo Estadístico de Forma (SSM).

% \subsection{Predicción de Bins de Coeficientes $b_k$}
% \label{sec:prediccion_bins_bk}

% Dada una imagen de prueba $\mat{I}$, el primer paso consiste en obtener una estimación de su pose global. Para ello, se recurre al módulo de Estimación de Pose Inicial (ESL, Sección~\ref{sec:esl_matematica}), el cual proporciona una transformación $\mathcal{T}_{ESL}$. Esta transformación alinea una forma de referencia con la estructura anatómica de interés en la imagen $\mat{I}$. La forma de referencia es usualmente la forma media del SSM, $\overline{\vect{s}}$ (un vector de $\R^{K_{total}d}$, donde $d=2$), que se remodela a una matriz $\overline{\mat{S}} \in \R^{K_{total} \times d}$. La aplicación de $\mathcal{T}_{ESL}$ a cada landmark (fila) de $\overline{\mat{S}}$ produce un conjunto de $K_{total}$ coordenadas de landmarks en el espacio de la imagen:
% \begin{equation}
% \mat{S}'_{\text{img,mean}} = \mathcal{T}_{ESL}(\overline{\mat{S}}),
% \label{eq:mean_shape_to_image} % Etiqueta para esta transformación
% \end{equation}
% donde $\mat{S}'_{\text{img,mean}} \in \R^{K_{total} \times d}$ son las coordenadas de los landmarks de la forma media proyectados sobre la imagen.

% Posteriormente, para cada uno de los $K_{total}$ landmarks de $\mat{S}'_{\text{img,mean}}$, se extrae un parche de imagen $P_i \in \R^{Q \times Q \times C_{in}}$ (donde $i \in \{1, \dots, K_{total}\}$, $Q$ es la dimensión del parche, y $C_{in}$ el número de canales). Este conjunto de $K_{total}$ parches, $\mathcal{P} = \{P_1, P_2, \dots, P_{K_{total}}\}$, constituye la entrada local de apariencia para las CNN.

% Si durante la fase de entrenamiento se empleó una reducción de dimensionalidad mediante Análisis de Componentes Principales (PCA) sobre los parches (o sobre características extraídas de ellos), la misma transformación PCA, $\mathcal{F}_{\text{PCA},k}$, se aplica a los parches extraídos de la imagen de prueba antes de introducirlos al clasificador del modo $k$.

% El conjunto de $K_{total}$ parches $\mathcal{P}$ (o sus representaciones transformadas) se introduce en cada uno de los $m$ clasificadores CNN previamente entrenados, $\text{CNN}_0, \text{CNN}_1, \dots, \text{CNN}_{m-1}$. Cada clasificador $\text{CNN}_k$, especializado en el modo de variación $b_k$, procesa la información de los parches para producir un vector de $B$ logits (valores no normalizados), $\vect{z}_k = (z_{k,0}, z_{k,1}, \dots, z_{k,B-1})^\transpose$. Estos logits se transforman en un vector de probabilidades $\vect{p}_k = (p_{k,0}, p_{k,1}, \dots, p_{k,B-1})^\transpose$ mediante la función softmax (referenciar Ecuación~\eqref{eq:softmax} si es la misma, o mantener la nueva si hay matices):
% \begin{equation}
% p_{k,j} = \frac{e^{z_{k,j}}}{\sum_{l=0}^{B-1} e^{z_{k,l}}}, \quad \text{para } j \in \{0, \dots, B-1\}.
% \label{eq:softmax_prediccion} 
% \end{equation}
% donde $p_{k,j}$ representa la probabilidad estimada por $\text{CNN}_k$ de que el coeficiente $b_k$ pertenezca al $j$-ésimo bin discreto. El índice del bin predicho para el modo $k$, denotado como $\hat{y}_k$, se determina seleccionando el bin con la máxima probabilidad a posteriori:
% \begin{equation}
% \hat{y}_k = \arg\max_{j \in \{0, \dots, B-1\}} p_{k,j}.
% \label{eq:argmax_prediccion_bin}
% \end{equation}
% Este procedimiento se repite para todos los $m$ modos de variación principales, resultando en un vector de índices de bin predichos $\hat{\vect{y}} = (\hat{y}_0, \hat{y}_1, \dots, \hat{y}_{m-1})^\transpose$. Este vector $\hat{\vect{y}}$ es una representación discreta de la forma estimada para la imagen $\mat{I}$.

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.9\textwidth]{Figures/prediccion_flujo.png} 
%     \caption{Diagrama de flujo ilustrando el proceso de predicción de bins para los coeficientes $b_k$. (1) Una imagen de entrada $\mat{I}$ es procesada por el módulo ESL para obtener la pose $\mathcal{T}_{ESL}$. (2) La forma media $\overline{\mat{S}}$ (remodelada de $\overline{\vect{s}}$) se transforma a $\mat{S}'_{\text{img,mean}}$ usando $\mathcal{T}_{ESL}$. (3) Se extraen $K_{total}$ parches $P_i$ centrados en los landmarks de $\mat{S}'_{\text{img,mean}}$. (4) (Opcional) Se aplica PCA a los parches. (5) Los parches (o sus features) alimentan la $\text{CNN}_k$ específica del modo. (6) La $\text{CNN}_k$ produce probabilidades $\vect{p}_k$ sobre los $B$ bins. (7) Se selecciona el bin $\hat{y}_k$ con máxima probabilidad. (8) El proceso se repite para los $m$ modos, generando el vector $\hat{\vect{y}}$.}
%     \label{fig:prediccion_flujo}
% \end{figure}

% \subsection{Desdiscretización de Coeficientes $b_k$}
% \label{sec:desdiscretizacion_bk}

% Los índices de bin predichos $\hat{y}_k$ contenidos en el vector $\hat{\vect{y}}$ son representaciones categóricas y deben ser convertidos nuevamente a valores continuos para los coeficientes $b_k$. Estos valores continuos son necesarios para reconstruir una instancia de forma del SSM, $\vect{s} \approx \overline{\vect{s}} + \mat{P} \vect{b}$ (ver Ecuación~\eqref{eq:ssm_reconstruction}). El proceso de desdiscretización se fundamenta en la definición de los bordes de los bins establecida durante la fase de entrenamiento.

% Recordemos que, para cada modo $k$, el coeficiente $b_k$ exhibe una varianza $\lambda_k$ (el $k$-ésimo valor propio de la matriz de covarianza de las formas alineadas), y por lo tanto una desviación estándar $\sigma_k = \sqrt{\lambda_k}$. El rango de variación significativo para $b_k$ se establece típicamente como $[-c \cdot \sigma_k, c \cdot \sigma_k]$, donde $c$ es un factor de cobertura (comúnmente $c=3$). Sean $R_{k,\text{min}} = -c \cdot \sigma_k$ y $R_{k,\text{max}} = c \cdot \sigma_k$ los límites inferior y superior de este rango para el modo $k$.

% Este rango $[R_{k,\text{min}}, R_{k,\text{max}}]$ se dividió en $B$ intervalos (bins) de igual amplitud durante la fase de discretización para el entrenamiento de las CNN. La amplitud de cada bin para el modo $k$ es:
% \begin{equation}
% w_k = \frac{R_{k,\text{max}} - R_{k,\text{min}}}{B} = \frac{2c\sigma_k}{B}.
% \label{eq:bin_width_k} % Etiqueta para ancho de bin
% \end{equation}
% Los bordes de los $B$ bins se definen entonces como una secuencia de $B+1$ puntos equiespaciados $e_{k,0}, e_{k,1}, \dots, e_{k,B}$, donde:
% \begin{equation}
% e_{k,j} = R_{k,\text{min}} + j \cdot w_k, \quad \text{para } j \in \{0, 1, \dots, B\}.
% \label{eq:bordes_bin}
% \end{equation}
% Así, el $j$-ésimo bin (indexado desde $j=0$) para el modo $k$ corresponde al intervalo $[e_{k,j}, e_{k,j+1}]$.

% Si el clasificador $\text{CNN}_k$ predice el índice de bin $\hat{y}_k$ para el coeficiente $b_k$, el valor continuo estimado para $b_k$, denotado como $\hat{b}_k$, se obtiene calculando el punto medio de dicho bin:
% \begin{equation}
% \hat{b}_k = \frac{e_{k,\hat{y}_k} + e_{k,\hat{y}_k+1}}{2} = R_{k,\text{min}} + (\hat{y}_k + 0.5) \cdot w_k.
% \label{eq:desdiscretizacion_bk_continuo}
% \end{equation}
% Este cálculo se realiza para cada uno de los $m$ modos para los cuales se obtuvo una predicción de bin, resultando en el vector de coeficientes de forma continuos estimados $\hat{\vect{b}} = (\hat{b}_0, \hat{b}_1, \dots, \hat{b}_{m-1})^\transpose$. Este vector $\hat{\vect{b}}$ constituye la estimación inicial de la forma de la estructura anatómica en la imagen de prueba y sirve como el punto de partida para el subsecuente proceso de ajuste iterativo del SSM (descrito en una sección posterior, e.g., Sección~\ref{sec:ajuste_asm}).

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.7\textwidth]{Figures/desdiscretizacion_proceso.png}
%     \caption{Ilustración del proceso de desdiscretización para un único coeficiente $b_k$. El eje horizontal representa el rango continuo del coeficiente, delimitado por $R_{k,\text{min}} = -c\sigma_k$ y $R_{k,\text{max}} = c\sigma_k$. Este rango se divide en $B$ bins (en este ejemplo, $B=3$, con ancho $w_k$). Si la CNN predice el bin $\hat{y}_k=1$ (el segundo bin, resaltado), el valor continuo $\hat{b}_k$ se estima como el centro de este bin, $e_{k,1} + w_k/2$, según la Ecuación~\eqref{eq:desdiscretizacion_bk_continuo}.}
%     \label{fig:desdiscretizacion_proceso}
% \end{figure}

% Es crucial destacar que la fidelidad de esta estimación inicial $\hat{\vect{b}}$ es altamente dependiente del rendimiento discriminativo de los clasificadores CNN y de la precisión de la estimación de pose inicial ESL. Inexactitudes acumuladas en estas etapas pueden resultar en un vector $\hat{\vect{b}}$ que se desvíe significativamente de la forma real del objeto, lo cual podría comprometer la capacidad del subsecuente algoritmo de ajuste fino para converger a una segmentación precisa.

\section{Predicción y Desdiscretización de Coeficientes de Forma}
\label{sec:prediccion_desdiscretizacion_b_simplified}

Una vez entrenadas las $m$ CNNs (Sección~\ref{sec:entrenamiento_cnn_simplified}), se usan para inferir los parámetros de forma $\vect{b}$ para nuevas imágenes. Esto implica predecir los bins discretos para cada coeficiente $b_k$ y luego convertirlos a valores continuos.

\subsection{Predicción de Bins de Coeficientes $b_k$}
\label{sec:prediccion_bins_bk_simplified}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{Figures/prediccion_flujo.png} 
    \caption{Flujo de predicción de bins: (1) Imagen de entrada. (2) ESL para pose. (3) Proyección de forma media. (4) Extracción de parches. (5) (Opcional PCA). (6) Entrada a CNNs. (7) Predicción de bins $\hat{y}_k$.}
    \label{fig:prediccion_flujo_simplified}
\end{figure}

Para una imagen de prueba $\mat{I}$:
\begin{enumerate}
    \item Se estima la pose global $\mathcal{T}_{ESL}$ usando el módulo ESL (Sección~\ref{sec:esl_simplified}).
    \item La forma media del SSM, $\mean{\mat{S}}$, se transforma al espacio de la imagen usando esta pose:
    \begin{equation}
    \mat{S}'_{\text{img,mean}} = \mathcal{T}_{ESL}(\mean{\mat{S}}).
    \label{eq:mean_shape_to_image_simplified}
    \end{equation}
    \item Se extraen $\Ktotal$ parches de imagen $P_i$ (de $Q \times Q$ píxeles) centrados en los landmarks de $\mat{S}'_{\text{img,mean}}$.
    \item Este conjunto de parches, $\set{P} = \{P_1, \dots, P_{\Ktotal}\}$, (opcionalmente tras aplicar PCA si se usó en el entrenamiento) se introducen en cada una de las $m$ CNNs entrenadas ($\text{CNN}_0, \dots, \text{CNN}_{m-1}$).
    \item Cada $\text{CNN}_k$ produce probabilidades $\vect{p}_k$ sobre los $B$ posibles bins para el coeficiente $b_k$, usando la función softmax (similar a Ecuación~\eqref{eq:softmax_simplified} de una sección anterior):
    \begin{equation}
    p_{k,j} = \frac{e^{z_{k,j}}}{\sum_{l=0}^{B-1} e^{z_{k,l}}}.
    \label{eq:softmax_prediccion_simplified} 
    \end{equation}
    \item El bin predicho $\hat{y}_k$ para el modo $k$ es el que tiene la máxima probabilidad:
    \begin{equation}
    \hat{y}_k = \arg\max_{j \in \{0, \dots, B-1\}} p_{k,j}.
    \label{eq:argmax_prediccion_bin_simplified}
    \end{equation}
\end{enumerate}
Esto resulta en un vector de índices de bin predichos $\hat{\vect{y}} = (\hat{y}_0, \dots, \hat{y}_{m-1})^T$.

\subsection{Desdiscretización de Coeficientes $b_k$}
\label{sec:desdiscretizacion_bk_simplified}

Los índices de bin predichos $\hat{y}_k$ se convierten a valores continuos $\hat{b}_k$ para reconstruir la forma del SSM (Ecuación~\eqref{eq:ssm_reconstruction_simplified} de una sección anterior).
El rango de variación de $b_k$ es típicamente $[-c \sigma_k, c \sigma_k]$, donde $\sigma_k = \sqrt{\lambda_k}$ es la desviación estándar del modo $k$. Sean $R_{k,\text{min}}$ y $R_{k,\text{max}}$ los límites de este rango.
La amplitud de cada uno de los $B$ bins para el modo $k$ es:
\begin{equation}
w_k = \frac{R_{k,\text{max}} - R_{k,\text{min}}}{B}.
\label{eq:bin_width_k_simplified}
\end{equation}
Si $\hat{y}_k$ es el bin predicho, el valor continuo estimado $\hat{b}_k$ es el centro de ese bin:
\begin{equation}
\hat{b}_k = R_{k,\text{min}} + (\hat{y}_k + 0.5) \cdot w_k.
\label{eq:desdiscretizacion_bk_continuo_simplified}
\end{equation}
Esto se hace para todos los $m$ modos, obteniendo el vector de coeficientes continuos $\hat{\vect{b}} = (\hat{b}_0, \dots, \hat{b}_{m-1})^T$. Este $\hat{\vect{b}}$ es la estimación inicial de la forma.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/desdiscretizacion_proceso.png}
    \caption{Desdiscretización: El rango de $b_k$ se divide en $B$ bins. Si se predice el bin $\hat{y}_k$, $\hat{b}_k$ es el centro de ese bin.}
    \label{fig:desdiscretizacion_proceso_simplified}
\end{figure}

La calidad de $\hat{\vect{b}}$ depende del rendimiento de las CNNs y de la precisión de la ESL.
