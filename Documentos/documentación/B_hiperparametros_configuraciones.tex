% ==============================================================================
% APÉNDICE B - HIPERPARÁMETROS Y CONFIGURACIONES
% Proyecto: Detección de COVID-19 mediante Landmarks Anatómicos
% Nivel: Doctoral/Científico - Completo y Detallado
% ==============================================================================

\documentclass[12pt,a4paper]{article}
\input{00_preambulo}

\title{Apéndice B:\\
Hiperparámetros y Configuraciones Completas}
\author{Documentación del Proceso de Desarrollo}
\date{Apéndice Técnico}

\begin{document}
\maketitle

\begin{abstract}
Este apéndice documenta exhaustivamente todos los hiperparámetros y
configuraciones utilizados en cada etapa del proyecto. Se incluyen
los parámetros de entrenamiento de redes neuronales, configuraciones
de data augmentation, parámetros de optimización, y configuraciones
de evaluación. Esta información permite la reproducibilidad completa
de los experimentos.
\end{abstract}

\tableofcontents
\newpage

% ==============================================================================
\section{Configuración de Hardware y Software}
% ==============================================================================

\subsection{Entorno de Hardware}

\begin{table}[htbp]
\centering
\caption{Especificaciones de hardware}
\label{tab:hardware_specs}
\begin{tabular}{ll}
\toprule
\textbf{Componente} & \textbf{Especificación} \\
\midrule
GPU & NVIDIA RTX 3080 (10 GB VRAM) \\
CPU & AMD Ryzen 9 5900X (12 cores) \\
RAM & 64 GB DDR4 3200 MHz \\
Almacenamiento & NVMe SSD 1TB \\
Sistema Operativo & Ubuntu 22.04 LTS \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Entorno de Software}

\begin{table}[htbp]
\centering
\caption{Versiones de software}
\label{tab:software_versions}
\begin{tabular}{ll}
\toprule
\textbf{Paquete} & \textbf{Versión} \\
\midrule
Python & 3.10.12 \\
PyTorch & 2.1.0 \\
torchvision & 0.16.0 \\
CUDA & 12.1 \\
cuDNN & 8.9.0 \\
NumPy & 1.24.3 \\
SciPy & 1.11.3 \\
scikit-learn & 1.3.1 \\
OpenCV & 4.8.1 \\
Pillow & 10.0.1 \\
matplotlib & 3.8.0 \\
pandas & 2.1.1 \\
albumentations & 1.3.1 \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Configuración del Dataset}
% ==============================================================================

\subsection{Parámetros de División}

\begin{table}[htbp]
\centering
\caption{Configuración de splits del dataset}
\label{tab:dataset_splits}
\begin{tabular}{lccccc}
\toprule
\textbf{Split} & \textbf{Proporción} & \textbf{Imágenes} & \textbf{COVID} & \textbf{Normal} & \textbf{VP} \\
\midrule
Train & 75\% & 717 & 229 & 351 & 137 \\
Validation & 15\% & 144 & 46 & 70 & 28 \\
Test & 10\% & 96 & 31 & 47 & 18 \\
\midrule
\textbf{Total} & 100\% & 957 & 306 & 468 & 183 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Preprocesamiento de Imágenes}

\begin{table}[htbp]
\centering
\caption{Parámetros de preprocesamiento}
\label{tab:preprocessing_params}
\begin{tabular}{ll}
\toprule
\textbf{Parámetro} & \textbf{Valor} \\
\midrule
Tamaño de entrada (landmarks) & 224 × 224 píxeles \\
Tamaño de entrada (clasificación) & 224 × 224 píxeles \\
Canales & 3 (RGB, replicado de grayscale) \\
Normalización media & [0.485, 0.456, 0.406] (ImageNet) \\
Normalización std & [0.229, 0.224, 0.225] (ImageNet) \\
Interpolación resize & Bilinear \\
Preservar aspect ratio & No (resize directo) \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Predicción de Landmarks}
% ==============================================================================

\subsection{Arquitecturas Evaluadas}

\begin{table}[htbp]
\centering
\caption{Configuración de arquitecturas para landmarks}
\label{tab:landmark_architectures_config}
\begin{tabular}{lcccc}
\toprule
\textbf{Arquitectura} & \textbf{Backbone} & \textbf{Pretrained} & \textbf{Output} & \textbf{Params} \\
\midrule
ResNet-18 & ResNet-18 & ImageNet & 30 (15×2) & 11.2M \\
ResNet-50 & ResNet-50 & ImageNet & 30 & 23.5M \\
DenseNet-121 & DenseNet-121 & ImageNet & 30 & 7.0M \\
EfficientNet-B0 & EfficientNet-B0 & ImageNet & 30 & 4.0M \\
MobileNetV2 & MobileNetV2 & ImageNet & 30 & 2.2M \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Hiperparámetros de Entrenamiento - Landmarks}

\begin{table}[htbp]
\centering
\caption{Hiperparámetros para entrenamiento de landmarks}
\label{tab:landmark_hyperparams}
\begin{tabular}{ll}
\toprule
\textbf{Hiperparámetro} & \textbf{Valor} \\
\midrule
\multicolumn{2}{l}{\textbf{Optimizador}} \\
Tipo & AdamW \\
Learning rate inicial & $1 \times 10^{-4}$ \\
Weight decay & $1 \times 10^{-4}$ \\
Betas & (0.9, 0.999) \\
Epsilon & $1 \times 10^{-8}$ \\
\midrule
\multicolumn{2}{l}{\textbf{Scheduler}} \\
Tipo & CosineAnnealingWarmRestarts \\
$T_0$ (período inicial) & 10 épocas \\
$T_{mult}$ (multiplicador) & 2 \\
$\eta_{min}$ (LR mínimo) & $1 \times 10^{-6}$ \\
\midrule
\multicolumn{2}{l}{\textbf{Entrenamiento}} \\
Épocas máximas & 100 \\
Batch size & 32 \\
Early stopping patience & 15 épocas \\
Gradient clipping & 1.0 (max norm) \\
\midrule
\multicolumn{2}{l}{\textbf{Función de pérdida}} \\
Tipo & MSELoss \\
Reducción & mean \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Data Augmentation - Landmarks}

\begin{table}[htbp]
\centering
\caption{Configuración de data augmentation para landmarks}
\label{tab:landmark_augmentation}
\begin{tabular}{llc}
\toprule
\textbf{Transformación} & \textbf{Parámetros} & \textbf{Probabilidad} \\
\midrule
HorizontalFlip & -- & 0.5 \\
Rotate & limit=15° & 0.3 \\
ShiftScaleRotate & shift=0.1, scale=0.1, rotate=10° & 0.3 \\
RandomBrightnessContrast & brightness=0.2, contrast=0.2 & 0.3 \\
GaussNoise & var\_limit=(10, 50) & 0.2 \\
GaussianBlur & blur\_limit=(3, 7) & 0.2 \\
CLAHE & clip\_limit=4.0 & 0.2 \\
\bottomrule
\end{tabular}
\end{table}

\begin{observacion}[Augmentation con landmarks]
Todas las transformaciones geométricas (flip, rotate, shift, scale) se
aplican simultáneamente a la imagen y a las coordenadas de landmarks
usando \texttt{albumentations} con \texttt{keypoint\_params}.
\end{observacion}

\subsection{Configuración del Ensemble}

\begin{table}[htbp]
\centering
\caption{Modelos en el ensemble de landmarks}
\label{tab:landmark_ensemble}
\begin{tabular}{lccc}
\toprule
\textbf{Modelo} & \textbf{Peso} & \textbf{MAE Individual} & \textbf{Checkpoint} \\
\midrule
ResNet-50 & 0.30 & 3.96 px & best\_resnet50.pth \\
DenseNet-121 & 0.25 & 3.90 px & best\_densenet121.pth \\
EfficientNet-B0 & 0.30 & 3.86 px & best\_efficientnet.pth \\
ResNet-18 & 0.15 & 4.11 px & best\_resnet18.pth \\
\midrule
\textbf{Ensemble} & 1.00 & \textbf{3.79 px} & -- \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Análisis de Forma (GPA)}
% ==============================================================================

\subsection{Parámetros del GPA}

\begin{table}[htbp]
\centering
\caption{Configuración del análisis GPA}
\label{tab:gpa_config}
\begin{tabular}{ll}
\toprule
\textbf{Parámetro} & \textbf{Valor} \\
\midrule
Número de formas & 957 \\
Landmarks por forma & 15 \\
Dimensiones & 2 \\
Tolerancia de convergencia & $1 \times 10^{-6}$ \\
Máximo iteraciones & 100 \\
Normalización de escala & Centroid size \\
Reflexiones permitidas & No \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Resultados de Convergencia}

\begin{table}[htbp]
\centering
\caption{Convergencia del GPA}
\label{tab:gpa_convergence}
\begin{tabular}{ccc}
\toprule
\textbf{Iteración} & \textbf{Error Procrustes} & \textbf{Cambio} \\
\midrule
0 & 0.0456 & -- \\
1 & 0.0238 & 0.0218 \\
2 & 0.0234 & 0.0004 \\
3 & 0.0234 & $< 10^{-6}$ \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Warping Piecewise Affine}
% ==============================================================================

\subsection{Parámetros de Triangulación}

\begin{table}[htbp]
\centering
\caption{Configuración de triangulación Delaunay}
\label{tab:delaunay_config}
\begin{tabular}{ll}
\toprule
\textbf{Parámetro} & \textbf{Valor} \\
\midrule
Landmarks anatómicos & 15 \\
Puntos de borde & 8 \\
Total de puntos & 23 \\
Triángulos resultantes & 34 (total), 18 (internos) \\
Algoritmo & scipy.spatial.Delaunay \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Puntos de Borde Añadidos}

\begin{table}[htbp]
\centering
\caption{Coordenadas de puntos de borde (imagen 224×224)}
\label{tab:boundary_points}
\begin{tabular}{ccc}
\toprule
\textbf{ID} & \textbf{x} & \textbf{y} \\
\midrule
15 & 0 & 0 \\
16 & 112 & 0 \\
17 & 223 & 0 \\
18 & 223 & 112 \\
19 & 223 & 223 \\
20 & 112 & 223 \\
21 & 0 & 223 \\
22 & 0 & 112 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Parámetros de Warping}

\begin{table}[htbp]
\centering
\caption{Configuración del proceso de warping}
\label{tab:warping_config}
\begin{tabular}{ll}
\toprule
\textbf{Parámetro} & \textbf{Valor} \\
\midrule
Interpolación & Bilinear \\
Modo de borde & Constant (valor=0) \\
Valor de relleno & 0 (negro) \\
Dtype de salida & float32 → uint8 \\
Preservar rango & Sí [0, 255] \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Clasificación de COVID-19}
% ==============================================================================

\subsection{Arquitecturas Evaluadas}

\begin{table}[htbp]
\centering
\caption{Arquitecturas de clasificación}
\label{tab:classification_architectures}
\begin{tabular}{lcccc}
\toprule
\textbf{Arquitectura} & \textbf{Params} & \textbf{FLOPs} & \textbf{Input} & \textbf{Pretrained} \\
\midrule
AlexNet & 61.1M & 0.71G & 224×224 & ImageNet \\
VGG-16 & 138.4M & 15.5G & 224×224 & ImageNet \\
ResNet-18 & 11.7M & 1.82G & 224×224 & ImageNet \\
ResNet-50 & 25.6M & 4.12G & 224×224 & ImageNet \\
DenseNet-121 & 8.0M & 2.88G & 224×224 & ImageNet \\
MobileNetV2 & 3.5M & 0.32G & 224×224 & ImageNet \\
EfficientNet-B0 & 5.3M & 0.39G & 224×224 & ImageNet \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Hiperparámetros de Entrenamiento - Clasificación}

\begin{table}[htbp]
\centering
\caption{Hiperparámetros para clasificación}
\label{tab:classification_hyperparams}
\begin{tabular}{ll}
\toprule
\textbf{Hiperparámetro} & \textbf{Valor} \\
\midrule
\multicolumn{2}{l}{\textbf{Optimizador}} \\
Tipo & SGD con momentum \\
Learning rate inicial & $1 \times 10^{-3}$ \\
Momentum & 0.9 \\
Weight decay & $1 \times 10^{-4}$ \\
Nesterov & True \\
\midrule
\multicolumn{2}{l}{\textbf{Scheduler}} \\
Tipo & StepLR \\
Step size & 10 épocas \\
Gamma & 0.1 \\
\midrule
\multicolumn{2}{l}{\textbf{Entrenamiento}} \\
Épocas máximas & 50 \\
Batch size & 32 \\
Early stopping patience & 10 épocas \\
\midrule
\multicolumn{2}{l}{\textbf{Función de pérdida}} \\
Tipo & CrossEntropyLoss \\
Class weights & [1.0, 1.0, 1.0] (balanceado) \\
Label smoothing & 0.1 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Data Augmentation - Clasificación}

\begin{table}[htbp]
\centering
\caption{Augmentation para clasificación (imágenes originales)}
\label{tab:classification_augmentation}
\begin{tabular}{llc}
\toprule
\textbf{Transformación} & \textbf{Parámetros} & \textbf{Probabilidad} \\
\midrule
HorizontalFlip & -- & 0.5 \\
RandomRotation & degrees=10 & 1.0 \\
ColorJitter & brightness=0.2, contrast=0.2 & 0.5 \\
RandomAffine & translate=(0.1, 0.1), scale=(0.9, 1.1) & 0.5 \\
GaussianBlur & kernel\_size=3 & 0.2 \\
RandomErasing & p=0.1, scale=(0.02, 0.1) & 0.1 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Augmentation para clasificación (imágenes warped)}
\label{tab:classification_augmentation_warped}
\begin{tabular}{llc}
\toprule
\textbf{Transformación} & \textbf{Parámetros} & \textbf{Probabilidad} \\
\midrule
HorizontalFlip & -- & 0.5 \\
ColorJitter & brightness=0.1, contrast=0.1 & 0.3 \\
GaussianBlur & kernel\_size=3 & 0.1 \\
\bottomrule
\end{tabular}
\end{table}

\begin{observacion}[Augmentation reducida para warped]
Las imágenes warped ya están geométricamente normalizadas, por lo que
se reduce la augmentation geométrica para no deshacer la normalización.
\end{observacion}

\subsection{Modificaciones de Arquitectura}

\begin{table}[htbp]
\centering
\caption{Modificaciones al clasificador final}
\label{tab:classifier_modifications}
\begin{tabular}{ll}
\toprule
\textbf{Componente} & \textbf{Configuración} \\
\midrule
Capa pre-final & AdaptiveAvgPool2d((1, 1)) \\
Dropout & 0.5 \\
Capa final & Linear(in\_features, 3) \\
Activación & Softmax (implícito en CrossEntropyLoss) \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Análisis de Robustez}
% ==============================================================================

\subsection{Perturbaciones Evaluadas}

\begin{table}[htbp]
\centering
\caption{Configuración de perturbaciones}
\label{tab:perturbation_config}
\begin{tabular}{lll}
\toprule
\textbf{Perturbación} & \textbf{Parámetro} & \textbf{Valores} \\
\midrule
JPEG Compression & Quality & [10, 20, 30, 50, 70] \\
Gaussian Blur & Sigma & [1, 2, 3, 4, 5] \\
Gaussian Noise & Sigma & [10, 25, 50, 75, 100] \\
Salt \& Pepper & Amount & [0.01, 0.02, 0.05, 0.1] \\
Contrast & Factor & [0.5, 0.7, 0.8, 1.2, 1.3, 1.5] \\
Brightness & Delta & [-50, -30, -20, +20, +30, +50] \\
Rotation & Degrees & [±2, ±5, ±10, ±15] \\
Scale & Factor & [0.8, 0.9, 1.1, 1.2] \\
Translation & Pixels & [±5, ±10, ±20] \\
Crop & Percent & [5\%, 10\%, 15\%, 20\%] \\
Occlusion & Size & [10×10, 20×20, 30×30, 50×50] \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Protocolo de Evaluación}

\begin{table}[htbp]
\centering
\caption{Protocolo de análisis de robustez}
\label{tab:robustness_protocol}
\begin{tabular}{ll}
\toprule
\textbf{Parámetro} & \textbf{Valor} \\
\midrule
Dataset de evaluación & Test set (n=96) \\
Repeticiones por nivel & 1 (determinístico cuando posible) \\
Métrica principal & Accuracy \\
Métricas secundarias & F1-Score, AUC-ROC \\
Análisis estadístico & ANOVA de dos factores \\
Nivel de significancia & $\alpha = 0.05$ \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Validación Externa}
% ==============================================================================

\subsection{Dataset FedCOVIDx}

\begin{table}[htbp]
\centering
\caption{Configuración de validación externa}
\label{tab:external_validation_config}
\begin{tabular}{ll}
\toprule
\textbf{Parámetro} & \textbf{Valor} \\
\midrule
Dataset & FedCOVIDx \\
Imágenes totales & 8,482 \\
Clases originales & 2 (COVID-positive, COVID-negative) \\
Mapeo de clases & 3→2 (COVID vs. Non-COVID) \\
Preprocesamiento & Igual que entrenamiento \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Mapeo de Clases}

\begin{table}[htbp]
\centering
\caption{Esquema de mapeo 3→2 clases}
\label{tab:class_mapping}
\begin{tabular}{ll}
\toprule
\textbf{Clase Original (3)} & \textbf{Clase Mapeada (2)} \\
\midrule
COVID & COVID-Positive \\
Normal & COVID-Negative \\
Viral Pneumonia & COVID-Negative \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Configuraciones de Reproducibilidad}
% ==============================================================================

\subsection{Seeds Aleatorios}

\begin{table}[htbp]
\centering
\caption{Seeds para reproducibilidad}
\label{tab:random_seeds}
\begin{tabular}{ll}
\toprule
\textbf{Componente} & \textbf{Seed} \\
\midrule
Python random & 42 \\
NumPy & 42 \\
PyTorch & 42 \\
CUDA & 42 \\
torch.backends.cudnn.deterministic & True \\
torch.backends.cudnn.benchmark & False \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Código de Configuración de Seeds}

\begin{lstlisting}[language=Python, caption={Configuración de reproducibilidad}]
import random
import numpy as np
import torch

def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
\end{lstlisting}

% ==============================================================================
\section{Configuración de Checkpoints}
% ==============================================================================

\subsection{Estrategia de Guardado}

\begin{table}[htbp]
\centering
\caption{Configuración de checkpoints}
\label{tab:checkpoint_config}
\begin{tabular}{ll}
\toprule
\textbf{Parámetro} & \textbf{Valor} \\
\midrule
Guardar mejor modelo & Sí (por validación) \\
Métrica de selección & val\_loss (landmarks), val\_acc (clasificación) \\
Guardar último modelo & Sí \\
Guardar cada N épocas & 10 \\
Formato & PyTorch state\_dict (.pth) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Contenido del Checkpoint}

\begin{lstlisting}[language=Python, caption={Estructura del checkpoint}]
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'scheduler_state_dict': scheduler.state_dict(),
    'best_val_metric': best_metric,
    'train_losses': train_losses,
    'val_losses': val_losses,
    'config': config_dict
}
torch.save(checkpoint, path)
\end{lstlisting}

% ==============================================================================
\section{Resumen de Configuraciones Óptimas}
% ==============================================================================

\begin{table}[htbp]
\centering
\caption{Resumen de configuraciones óptimas por tarea}
\label{tab:optimal_configs}
\begin{tabular}{p{3cm}p{4cm}p{5cm}}
\toprule
\textbf{Tarea} & \textbf{Arquitectura} & \textbf{Configuración Clave} \\
\midrule
Landmarks (accuracy) & Ensemble (4 modelos) & AdamW, lr=$10^{-4}$, CosineWarmRestarts \\
Landmarks (eficiencia) & EfficientNet-B0 & AdamW, lr=$10^{-4}$, 100 épocas \\
Clasificación (original) & MobileNetV2 & SGD, lr=$10^{-3}$, StepLR \\
Clasificación (warped) & ResNet-18 & SGD, lr=$10^{-3}$, augment reducido \\
\bottomrule
\end{tabular}
\end{table}

% ==============================================================================
\section{Conclusiones}
% ==============================================================================

Este apéndice ha documentado exhaustivamente todas las configuraciones e
hiperparámetros utilizados en el proyecto. Los puntos clave incluyen:

\begin{enumerate}
    \item \textbf{Optimización de landmarks}: AdamW con cosine annealing
    y warm restarts proporciona la mejor convergencia.

    \item \textbf{Data augmentation adaptada}: Augmentation geométrica completa
    para imágenes originales, reducida para warped.

    \item \textbf{Reproducibilidad}: Seeds fijos y configuración determinística
    de CUDA permiten reproducir exactamente los resultados.

    \item \textbf{Checkpointing robusto}: Guardado de estado completo permite
    resumir entrenamiento y análisis post-hoc.
\end{enumerate}

Todas las configuraciones están disponibles en los archivos de configuración
del repositorio para facilitar la reproducibilidad.

\end{document}
