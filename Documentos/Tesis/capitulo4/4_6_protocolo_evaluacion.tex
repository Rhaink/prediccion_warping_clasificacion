% =============================================================================
% CAPÍTULO 4: METODOLOGÍA
% Sección 4.6: Protocolo de Evaluación Experimental
% =============================================================================

\section{Protocolo de Evaluación Experimental}
\label{sec:protocolo_evaluacion}

Esta sección describe los protocolos de evaluación empleados para medir el rendimiento de cada componente del sistema propuesto. Se definen métricas específicas para la predicción de landmarks, la clasificación de enfermedades, y se establecen protocolos para evaluar la robustez ante perturbaciones, la capacidad de generalización entre dominios, y la validación en conjuntos de datos externos.

\subsection{Métricas de Evaluación para Predicción de Landmarks}
\label{subsec:metricas_landmarks}

La evaluación del modelo de predicción de landmarks utiliza métricas basadas en el error euclidiano entre las coordenadas predichas y las anotaciones de referencia (valores de referencia).

\subsubsection{Error Euclidiano Medio}

La métrica principal es el error euclidiano medio (MED, por sus siglas en inglés \textit{Mean Euclidean Distance}), calculado en píxeles sobre imágenes de $224 \times 224$:

\begin{equation}
    \text{MED} = \frac{1}{N \cdot L} \sum_{i=1}^{N} \sum_{j=1}^{L} \sqrt{(x_{i,j} - \hat{x}_{i,j})^2 + (y_{i,j} - \hat{y}_{i,j})^2}
    \label{eq:med}
\end{equation}

\noindent donde $N$ es el número de imágenes, $L=15$ es el número de landmarks, $(x_{i,j}, y_{i,j})$ son las coordenadas de referencia del landmark $j$ en la imagen $i$, y $(\hat{x}_{i,j}, \hat{y}_{i,j})$ son las coordenadas predichas.

Dado que las coordenadas se almacenan normalizadas en el rango $[0, 1]$, la desnormalización se realiza multiplicando por el tamaño de imagen:

\begin{equation}
    \text{error}_{i,j} = \sqrt{((x_{i,j} - \hat{x}_{i,j}) \cdot S)^2 + ((y_{i,j} - \hat{y}_{i,j}) \cdot S)^2}
    \label{eq:error_pixels}
\end{equation}

\noindent donde $S = 224$ es el tamaño de la imagen de entrada al modelo.

\subsubsection{Error por Landmark Individual}

Para identificar landmarks problemáticos, se calcula el error medio por cada uno de los 15 landmarks:

\begin{equation}
    \text{MED}_j = \frac{1}{N} \sum_{i=1}^{N} \sqrt{(x_{i,j} - \hat{x}_{i,j})^2 + (y_{i,j} - \hat{y}_{i,j})^2} \cdot S
    \label{eq:error_per_landmark}
\end{equation}

Este análisis permite identificar patrones sistemáticos de error. Por ejemplo, landmarks del eje central (L9, L10, L11) típicamente presentan menor error que landmarks en los bordes de la silueta pulmonar (L12, L13 en los bordes superiores, y L14, L15 en los ángulos costofrénicos).

\subsubsection{Error por Categoría Diagnóstica}

El error se analiza también por categoría diagnóstica (COVID-19, Normal, Neumonía Viral) para detectar posibles sesgos del modelo hacia patrones específicos de cada condición:

\begin{equation}
    \text{MED}_c = \frac{1}{N_c \cdot L} \sum_{i \in \mathcal{C}_c} \sum_{j=1}^{L} \text{error}_{i,j}
    \label{eq:error_per_category}
\end{equation}

\noindent donde $\mathcal{C}_c$ es el conjunto de índices de imágenes pertenecientes a la categoría $c$, y $N_c = |\mathcal{C}_c|$.

\subsubsection{Distribución de Errores y Percentiles}

Además de las métricas de tendencia central, se reportan estadísticos de distribución que caracterizan el comportamiento del modelo en casos extremos:

\begin{itemize}
    \item \textbf{Desviación estándar:} Mide la dispersión de errores alrededor de la media.
    \item \textbf{Mediana (P50):} Valor central robusto a outliers.
    \item \textbf{Percentiles P75, P90, P95:} Caracterizan la cola de la distribución de errores.
\end{itemize}

La Tabla \ref{tab:percentiles_landmarks} presenta la interpretación de los percentiles en el contexto de calidad de predicción.

\begin{table}[htbp]
    \centering
    \caption{Interpretación de percentiles de error en predicción de landmarks.}
    \label{tab:percentiles_landmarks}
    \begin{tabular}{lcp{7cm}}
        \toprule
        \textbf{Percentil} & \textbf{Umbral} & \textbf{Interpretación} \\
        \midrule
        P50 (Mediana) & $< 5$ px & 50\% de predicciones con error menor a 5 píxeles \\
        P75 & $< 8$ px & 75\% de predicciones aceptables para warping \\
        P90 & $< 10$ px & 90\% dentro de tolerancia visual \\
        P95 & $< 15$ px & 95\% sin errores severos \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Tasa de Éxito por Umbral}

Para evaluar la proporción de predicciones que alcanzan diferentes niveles de precisión, se calcula la tasa de éxito bajo umbrales específicos:

\begin{equation}
    \text{SR}_\tau = \frac{1}{N \cdot L} \sum_{i=1}^{N} \sum_{j=1}^{L} \mathbb{1}[\text{error}_{i,j} < \tau]
    \label{eq:success_rate}
\end{equation}

\noindent donde $\mathbb{1}[\cdot]$ es la función indicadora y $\tau$ es el umbral en píxeles. Los umbrales estándar utilizados son $\tau \in \{5, 8, 10, 15\}$ píxeles.

\subsection{Métricas de Evaluación para Clasificación}
\label{subsec:metricas_clasificacion}

La evaluación del clasificador emplea métricas estándar de clasificación multiclase, con consideraciones específicas para el desbalance de clases presente en el conjunto de datos.

\subsubsection{Accuracy}

La exactitud (accuracy) mide la proporción de predicciones correctas sobre el total. Para clasificación multiclase con $K$ clases:

\begin{equation}
    \text{Accuracy} = \frac{\sum_{c=1}^{K} \text{TP}_c}{N} = \frac{\text{Predicciones correctas}}{\text{Total de muestras}}
    \label{eq:accuracy}
\end{equation}

\noindent donde $\text{TP}_c$ representa los verdaderos positivos de la clase $c$ (muestras de clase $c$ correctamente clasificadas) y $N$ es el número total de muestras.

Si bien es una métrica intuitiva, puede ser engañosa en conjuntos de datos desbalanceados donde un clasificador trivial que predice siempre la clase mayoritaria alcanzaría alta accuracy.

\subsubsection{Precision, Recall y F1-Score por Clase}

Para cada clase $c$, se calculan:

\begin{align}
    \text{Precision}_c &= \frac{\text{TP}_c}{\text{TP}_c + \text{FP}_c} \label{eq:precision} \\
    \text{Recall}_c &= \frac{\text{TP}_c}{\text{TP}_c + \text{FN}_c} \label{eq:recall} \\
    \text{F1}_c &= 2 \cdot \frac{\text{Precision}_c \cdot \text{Recall}_c}{\text{Precision}_c + \text{Recall}_c} \label{eq:f1}
\end{align}

\noindent donde $\text{TP}_c$, $\text{FP}_c$ y $\text{FN}_c$ son los verdaderos positivos, falsos positivos y falsos negativos para la clase $c$, respectivamente.

\subsubsection{F1-Score Macro vs F1-Score Weighted}
\label{subsubsec:f1_macro_weighted}

Para obtener una métrica global a partir de los F1-Scores por clase, existen dos estrategias de agregación:

\textbf{F1-Macro:} Promedia los F1-Scores de todas las clases con peso uniforme:

\begin{equation}
    \text{F1-Macro} = \frac{1}{K} \sum_{c=1}^{K} \text{F1}_c
    \label{eq:f1_macro}
\end{equation}

\textbf{F1-Weighted:} Promedia ponderando por el número de muestras de cada clase:

\begin{equation}
    \text{F1-Weighted} = \sum_{c=1}^{K} \frac{n_c}{N} \cdot \text{F1}_c
    \label{eq:f1_weighted}
\end{equation}

\noindent donde $n_c$ es el número de muestras de la clase $c$ y $N$ es el total de muestras.

\textbf{Justificación del uso de F1-Macro:} En este trabajo se selecciona F1-Macro como métrica principal por las siguientes razones:

\begin{enumerate}
    \item \textbf{Equidad entre clases:} En el contexto médico, el rendimiento en clases minoritarias (Neumonía Viral, 9\% del conjunto de datos) es tan importante como en clases mayoritarias (Normal, 67\%). F1-Macro pondera equitativamente el rendimiento en cada clase.

    \item \textbf{Detección de sesgos:} F1-Weighted puede enmascarar un rendimiento deficiente en clases minoritarias. Un modelo con F1-Weighted de 0.95 podría tener F1 de 0.50 en la clase minoritaria sin que esto se refleje significativamente en la métrica agregada.

    \item \textbf{Consistencia con el manejo de desbalance:} El uso de pesos de clase durante el entrenamiento (Sección \ref{subsec:config_entrenamiento_clasificador}) tiene como objetivo mejorar el rendimiento en clases minoritarias; F1-Macro refleja directamente este objetivo.

    \item \textbf{Práctica estándar:} La literatura de clasificación de imágenes médicas con conjuntos de datos desbalanceados recomienda el uso de F1-Macro \cite{sokolova2009systematic, grandini2020metrics}.
\end{enumerate}

La Tabla \ref{tab:f1_macro_vs_weighted} ilustra la diferencia entre ambas métricas con un ejemplo hipotético.

\begin{table}[htbp]
    \centering
    \caption{Comparación entre F1-Macro y F1-Weighted en un escenario de desbalance.}
    \label{tab:f1_macro_vs_weighted}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Clase} & \textbf{Muestras (\%)} & \textbf{F1} & \textbf{Contrib. Macro} & \textbf{Contrib. Weighted} \\
        \midrule
        COVID-19 & 24\% & 0.98 & 0.327 & 0.235 \\
        Normal & 67\% & 0.99 & 0.330 & 0.663 \\
        Neumonía Viral & 9\% & 0.85 & 0.283 & 0.077 \\
        \midrule
        \textbf{Total} & 100\% & — & \textbf{0.940} & \textbf{0.975} \\
        \bottomrule
    \end{tabular}
\end{table}

Como se observa, F1-Weighted (0.975) enmascara el rendimiento inferior en Neumonía Viral, mientras que F1-Macro (0.940) refleja más fielmente el rendimiento equilibrado entre clases.

\subsubsection{Matriz de Confusión}

La matriz de confusión $\mathbf{C} \in \mathbb{R}^{K \times K}$ proporciona un diagnóstico detallado del comportamiento del clasificador, donde $C_{ij}$ representa el número de muestras de la clase verdadera $i$ clasificadas como clase $j$:

\begin{equation}
    \mathbf{C} = \begin{bmatrix}
        C_{11} & C_{12} & C_{13} \\
        C_{21} & C_{22} & C_{23} \\
        C_{31} & C_{32} & C_{33}
    \end{bmatrix}
    \label{eq:confusion_matrix}
\end{equation}

Los elementos diagonales $C_{ii}$ corresponden a clasificaciones correctas, mientras que los elementos fuera de la diagonal revelan patrones de confusión entre clases.

\subsection{Protocolo de Evaluación de Robustez}
\label{subsec:protocolo_robustez}

Para evaluar la robustez del sistema ante perturbaciones que pueden ocurrir durante la adquisición, transmisión o almacenamiento de imágenes radiográficas, se define un protocolo de evaluación sistemático.

\subsubsection{Tipos de Perturbaciones}

Se evalúan tres tipos de perturbaciones que simulan condiciones realistas de degradación de imagen:

\textbf{1. Compresión JPEG:}

La compresión JPEG es un estándar ampliamente utilizado en sistemas PACS (Picture Archiving and Communication System) hospitalarios. Se evalúan dos niveles de calidad:

\begin{itemize}
    \item \textbf{JPEG Q50:} Compresión moderada. El parámetro de calidad 50 (escala 0-100) introduce artefactos de bloque visibles pero mantiene la mayoría del contenido diagnóstico.

    \item \textbf{JPEG Q30:} Compresión agresiva. El parámetro de calidad 30 introduce artefactos severos que pueden afectar la interpretación clínica.
\end{itemize}

El procedimiento técnico de aplicación es:

\begin{enumerate}
    \item Cargar imagen en formato original (PNG o sin compresión).
    \item Codificar la imagen usando el códec JPEG con el parámetro de calidad especificado.
    \item Decodificar la imagen JPEG comprimida.
    \item Aplicar el proceso de preprocesamiento estándar (CLAHE, normalización).
    \item Evaluar el modelo sobre la imagen procesada.
\end{enumerate}

\textbf{2. Desenfoque Gaussiano:}

El desenfoque simula condiciones de adquisición subóptimas como movimiento del paciente o desenfoque del equipo. Se aplica un filtro Gaussiano definido por:

\begin{equation}
    G(x, y) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2 + y^2}{2\sigma^2}}
    \label{eq:gaussian_kernel}
\end{equation}

El tamaño del núcleo se determina automáticamente a partir del parámetro $\sigma$ según la convención de OpenCV, garantizando que el núcleo capture adecuadamente la distribución Gaussiana.

Se evalúan dos niveles de desenfoque:

\begin{itemize}
    \item \textbf{Blur $\sigma=1$:} Desenfoque leve, simula movimiento mínimo del paciente.
    \item \textbf{Blur $\sigma=2$:} Desenfoque moderado, simula condiciones de adquisición problemáticas.
\end{itemize}

El procedimiento técnico es:

\begin{enumerate}
    \item Cargar imagen original.
    \item Aplicar filtro Gaussiano con el $\sigma$ especificado (el tamaño del núcleo se calcula automáticamente).
    \item Aplicar el proceso de preprocesamiento estándar.
    \item Evaluar el modelo sobre la imagen procesada.
\end{enumerate}

\textbf{3. Ruido Gaussiano} (opcional):

Para completitud, se puede evaluar también ruido aditivo Gaussiano con diferentes niveles de desviación estándar ($\sigma = 0.05, 0.10$).

\subsubsection{Métricas de Robustez}

La robustez se cuantifica mediante la degradación de rendimiento respecto al línea base sin perturbaciones:

\begin{equation}
    \text{Degradación}_p = \text{Accuracy}_{\text{línea base}} - \text{Accuracy}_p
    \label{eq:degradation}
\end{equation}

\noindent donde $p$ indica el tipo y nivel de perturbación.

Para comparar la robustez entre diferentes configuraciones del sistema (por ejemplo, clasificador entrenado con imágenes originales vs. normalizadas), se calcula el factor de mejora:

\begin{equation}
    \text{Factor de Mejora}_p = \frac{\text{Degradación}_p^{\text{original}}}{\text{Degradación}_p^{\text{warped}}}
    \label{eq:improvement_factor}
\end{equation}

Un factor de mejora mayor a 1 indica que el sistema con imágenes normalizadas es más robusto ante la perturbación $p$.

La Tabla \ref{tab:protocolo_robustez} resume el protocolo de evaluación de robustez.

\begin{table}[htbp]
    \centering
    \caption{Protocolo de evaluación de robustez.}
    \label{tab:protocolo_robustez}
    \begin{tabular}{llcc}
        \toprule
        \textbf{Perturbación} & \textbf{Parámetros} & \textbf{Severidad} & \textbf{Escenario Simulado} \\
        \midrule
        JPEG Q50 & quality=50 & Moderada & Compresión PACS estándar \\
        JPEG Q30 & quality=30 & Severa & Transmisión de baja calidad \\
        Blur $\sigma=1$ & $\sigma$=1.0 (núcleo automático) & Leve & Movimiento del paciente \\
        Blur $\sigma=2$ & $\sigma$=2.0 (núcleo automático) & Moderada & Desenfoque del equipo \\
        \bottomrule
    \end{tabular}
\end{table}

La Figura \ref{fig:perturbaciones_robustez} ilustra ejemplos de las perturbaciones aplicadas y sus efectos visuales sobre una imagen radiográfica.

\begin{figure}[htbp]
    \centering
    % [PENDIENTE: Insertar ejemplos de perturbaciones]
    \fbox{\parbox{0.9\textwidth}{\centering\vspace{3cm}
    [Ejemplos de perturbaciones de robustez]\\
    (a) Original $\rightarrow$ (b) JPEG Q50 $\rightarrow$ (c) JPEG Q30 $\rightarrow$ (d) Blur $\sigma$=1 $\rightarrow$ (e) Blur $\sigma$=2
    \vspace{3cm}}}
    \caption{Ejemplos de perturbaciones aplicadas para evaluación de robustez. (a) Imagen original sin perturbación; (b) compresión JPEG Q50 con artefactos de bloque leves; (c) compresión JPEG Q30 con artefactos severos; (d) desenfoque Gaussiano $\sigma=1$; (e) desenfoque Gaussiano $\sigma=2$.}
    \label{fig:perturbaciones_robustez}
\end{figure}

\subsection{Protocolo de Evaluación Cruzada (Cross-Evaluation)}
\label{subsec:protocolo_cross_evaluation}

Para evaluar la capacidad de generalización del sistema, se define un protocolo de evaluación cruzada que mide el rendimiento de modelos entrenados en un dominio cuando se evalúan en otro dominio.

\subsubsection{Definición de Dominios}

Se definen dos dominios de datos:

\begin{itemize}
    \item \textbf{Dominio Original:} Imágenes radiográficas sin normalización geométrica.
    \item \textbf{Dominio Warped:} Imágenes normalizadas geométricamente mediante el proceso de warping.
\end{itemize}

\subsubsection{Matriz de Evaluación Cruzada}

Se entrenan clasificadores independientes en cada dominio y se evalúan en ambos dominios, generando una matriz de evaluación $2 \times 2$:

\begin{equation}
    \mathbf{E} = \begin{bmatrix}
        \text{Acc}_{O \to O} & \text{Acc}_{O \to W} \\
        \text{Acc}_{W \to O} & \text{Acc}_{W \to W}
    \end{bmatrix}
    \label{eq:cross_eval_matrix}
\end{equation}

\noindent donde:
\begin{itemize}
    \item $\text{Acc}_{O \to O}$: Accuracy del modelo original evaluado en datos originales (in-domain).
    \item $\text{Acc}_{O \to W}$: Accuracy del modelo original evaluado en datos warped (cross-domain).
    \item $\text{Acc}_{W \to O}$: Accuracy del modelo warped evaluado en datos originales (cross-domain).
    \item $\text{Acc}_{W \to W}$: Accuracy del modelo warped evaluado en datos warped (in-domain).
\end{itemize}

\subsubsection{Métricas de Generalización}

A partir de la matriz de evaluación cruzada, se calculan métricas que cuantifican la capacidad de generalización:

\textbf{Gap de Generalización:} Diferencia entre rendimiento in-domain y cross-domain:

\begin{align}
    \text{Gap}_O &= \text{Acc}_{O \to O} - \text{Acc}_{O \to W} \label{eq:gap_original} \\
    \text{Gap}_W &= \text{Acc}_{W \to W} - \text{Acc}_{W \to O} \label{eq:gap_warped}
\end{align}

Un gap menor indica mejor capacidad de generalización del modelo.

\textbf{Factor de Mejora en Generalización:}

\begin{equation}
    \text{Factor de Mejora} = \frac{\text{Gap}_O}{\text{Gap}_W}
    \label{eq:generalization_factor}
\end{equation}

Un factor mayor a 1 indica que el modelo entrenado con imágenes normalizadas generaliza mejor a dominios diferentes.

La Figura \ref{fig:cross_evaluation_esquema} ilustra el esquema de evaluación cruzada.

\begin{figure}[htbp]
    \centering
    % [PENDIENTE: Insertar diagrama de cross-evaluation]
    \fbox{\parbox{0.9\textwidth}{\centering\vspace{3cm}
    [Esquema de evaluación cruzada]\\
    Modelo Original $\rightarrow$ Eval. Original (in-domain) / Eval. Warped (cross-domain)\\
    Modelo Warped $\rightarrow$ Eval. Original (cross-domain) / Eval. Warped (in-domain)
    \vspace{3cm}}}
    \caption{Esquema de evaluación cruzada entre dominios original y warped. Los cuadrantes diagonales representan evaluación in-domain, mientras que los cuadrantes off-diagonal representan evaluación cross-domain.}
    \label{fig:cross_evaluation_esquema}
\end{figure}

\subsection{Protocolo de Validación Externa}
\label{subsec:protocolo_validacion_externa}

Para evaluar la capacidad de generalización del sistema a datos completamente nuevos, se define un protocolo de validación en un conjunto de datos externo independiente.

\subsubsection{Conjunto de Datos de Validación Externa}

Se utiliza el conjunto de datos FedCOVIDx \cite{kumar2021fedcovidx} como conjunto de validación externa, el cual presenta las siguientes características:

\begin{table}[htbp]
    \centering
    \caption{Características del conjunto de datos de validación externa FedCOVIDx.}
    \label{tab:fedcovidx}
    \begin{tabular}{ll}
        \toprule
        \textbf{Característica} & \textbf{Valor} \\
        \midrule
        Número de muestras & 8,482 \\
        Clases & 2 (Positivo/Negativo para COVID-19) \\
        Distribución & Balanceado ($\sim$50/50) \\
        Fuentes institucionales & BIMCV ($\sim$95\%), RICORD, RSNA \\
        Resolución & Variable (300--3000 píxeles) \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Mapeo de Clases}

Dado que el clasificador fue entrenado con 3 clases mientras que el conjunto de datos externo tiene 2 clases, se define un mapeo para evaluar el rendimiento en clasificación binaria:

\begin{equation}
    \begin{cases}
        P(\text{Positivo}) = P(\text{COVID-19}) \\
        P(\text{Negativo}) = P(\text{Normal}) + P(\text{Viral Pneumonia})
    \end{cases}
    \label{eq:class_mapping}
\end{equation}

La predicción final se determina por:

\begin{equation}
    \hat{y} = \begin{cases}
        \text{Positivo} & \text{si } P(\text{COVID-19}) \geq 0.5 \\
        \text{Negativo} & \text{en otro caso}
    \end{cases}
    \label{eq:binary_prediction}
\end{equation}

\subsubsection{Procedimiento de Evaluación}

El protocolo de validación externa sigue los siguientes pasos:

\begin{enumerate}
    \item \textbf{Preprocesamiento:} Aplicar el mismo proceso de preprocesamiento usado durante el entrenamiento (CLAHE con clip\_limit=2.0, tile\_size=4).

    \item \textbf{Predicción de Landmarks:} Para evaluar en el dominio warped, primero se predicen los landmarks usando el ensemble de modelos de landmarks con TTA.

    \item \textbf{Normalización Geométrica:} Aplicar el proceso de warping a las imágenes externas usando los landmarks predichos.

    \item \textbf{Clasificación:} Evaluar el clasificador en las imágenes procesadas.

    \item \textbf{Mapeo de Predicciones:} Convertir las probabilidades de 3 clases a predicción binaria según la Ecuación \ref{eq:binary_prediction}.

    \item \textbf{Cálculo de Métricas:} Calcular accuracy, sensibilidad, especificidad, F1-Score y AUC-ROC.
\end{enumerate}

\subsubsection{Métricas de Validación Externa}

Para la clasificación binaria en el conjunto de datos externo, se reportan métricas específicas:

\begin{align}
    \text{Sensibilidad} &= \frac{\text{TP}}{\text{TP} + \text{FN}} \label{eq:sensitivity} \\
    \text{Especificidad} &= \frac{\text{TN}}{\text{TN} + \text{FP}} \label{eq:specificity} \\
    \text{AUC-ROC} &= \int_0^1 \text{TPR}(t) \, d\text{FPR}(t) \label{eq:auc_roc}
\end{align}

La sensibilidad mide la capacidad de detectar casos positivos (COVID-19), mientras que la especificidad mide la capacidad de identificar correctamente casos negativos.

\subsection{Test-Time Augmentation para Predicción de Landmarks}
\label{subsec:tta_evaluacion}

Durante la evaluación del modelo de landmarks, se emplea Test-Time Augmentation (TTA) para mejorar la precisión de las predicciones mediante el promediado de múltiples vistas de la misma imagen.

\subsubsection{Procedimiento de TTA}

El procedimiento implementado utiliza flip horizontal:

\begin{enumerate}
    \item \textbf{Predicción original:} Obtener predicción $\hat{\mathbf{p}}$ para la imagen original.

    \item \textbf{Flip de imagen:} Aplicar reflexión horizontal a la imagen de entrada.

    \item \textbf{Predicción flip:} Obtener predicción $\hat{\mathbf{p}}'$ para la imagen reflejada.

    \item \textbf{Corrección de coordenadas:} Revertir el flip en las coordenadas predichas:
    \begin{align}
        \hat{x}'_j &\leftarrow 1 - \hat{x}'_j \\
        \text{Intercambiar pares simétricos:} & \quad (L3 \leftrightarrow L4), (L5 \leftrightarrow L6), \ldots
    \end{align}

    \item \textbf{Promediado:} Calcular la predicción final como promedio:
    \begin{equation}
        \hat{\mathbf{p}}_{\text{TTA}} = \frac{\hat{\mathbf{p}} + \hat{\mathbf{p}}'_{\text{corregido}}}{2}
        \label{eq:tta_averaging}
    \end{equation}
\end{enumerate}

Los pares simétricos intercambiados son: (L3, L4), (L5, L6), (L7, L8), (L12, L13), (L14, L15).

\subsection{Resumen del Protocolo de Evaluación}
\label{subsec:resumen_protocolo}

La Tabla \ref{tab:resumen_protocolo_evaluacion} consolida los protocolos de evaluación definidos en esta sección.

\begin{table}[htbp]
    \centering
    \caption{Resumen de protocolos de evaluación experimental.}
    \label{tab:resumen_protocolo_evaluacion}
    \begin{tabular}{p{3.5cm}p{4cm}p{5cm}}
        \toprule
        \textbf{Protocolo} & \textbf{Métricas Principales} & \textbf{Objetivo} \\
        \midrule
        Evaluación de Landmarks & MED (px), Error por landmark, Percentiles & Medir precisión de predicción de puntos anatómicos \\
        \midrule
        Evaluación de Clasificación & Accuracy, F1-Macro, Matriz de confusión & Medir rendimiento de clasificación multiclase \\
        \midrule
        Evaluación de Robustez & Degradación (\%), Factor de mejora & Cuantificar resistencia a perturbaciones \\
        \midrule
        Cross-Evaluation & Gap de generalización, Factor de mejora & Medir capacidad de transferencia entre dominios \\
        \midrule
        Validación Externa & Accuracy, Sensibilidad, Especificidad, AUC & Evaluar generalización a datos externos \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Consideraciones Éticas y Limitaciones}
\label{subsec:consideraciones_eticas}

\textbf{Disclaimer de Uso.} El sistema presentado en este trabajo es un \textbf{prototipo de investigación} desarrollado exclusivamente con fines académicos y \textbf{NO ha sido validado para uso clínico o diagnóstico}. Los resultados experimentales corresponden a evaluaciones sobre conjuntos de datos públicos bajo condiciones controladas de laboratorio y no deben interpretarse como evidencia de eficacia diagnóstica en entornos clínicos reales.

El sistema NO pretende reemplazar el criterio médico profesional. Cualquier implementación en entornos clínicos requeriría:

\begin{enumerate}
    \item Validación prospectiva en poblaciones locales con aprobación de comité de ética institucional.
    \item Certificación regulatoria según las normativas aplicables (e.g., COFEPRIS en México, FDA en Estados Unidos).
    \item Integración con flujos de trabajo clínicos supervisados por profesionales de la salud.
    \item Evaluación continua del rendimiento en condiciones reales de operación.
\end{enumerate}

Los conjuntos de datos utilizados (COVID-19 Radiography Database, FedCOVIDx) son de acceso público y no contienen información identificable de pacientes.

% Referencias temporales para esta sección
% \cite{sokolova2009systematic} - Sokolova & Lapalme, A systematic analysis of performance measures (2009)
% \cite{grandini2020metrics} - Grandini et al., Metrics for Multi-Class Classification (2020)
% \cite{kumar2021fedcovidx} - Kumar et al., FedCOVIDx (2021)
