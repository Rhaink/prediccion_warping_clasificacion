# Grad-CAM: Explicabilidad Visual para COVID-19 Detection

## Documento de Referencia para Exposici√≥n

---

## ¬øQu√© es Grad-CAM?

**Grad-CAM** (Gradient-weighted Class Activation Mapping) es una t√©cnica de **explicabilidad e interpretabilidad** para modelos de deep learning en visi√≥n por computadora.

### Definici√≥n Simple

Las **zonas de atenci√≥n** (o "regiones de activaci√≥n") son **mapas de calor que muestran qu√© partes de la radiograf√≠a de t√≥rax fueron m√°s importantes para que el modelo llegara a su predicci√≥n**.

### Interpretaci√≥n de Colores

- **üî¥ Rojo/Amarillo**: Regiones donde el modelo "puso m√°s atenci√≥n" y que tuvieron mayor influencia en la decisi√≥n
- **üîµ Azul/P√∫rpura**: Regiones con menos influencia en la predicci√≥n
- **‚ö´ Negro**: √Åreas que el modelo consider√≥ irrelevantes para la clasificaci√≥n

---

## Funcionamiento T√©cnico

### Pipeline de Grad-CAM

```
Input Image (224√ó224)
    ‚Üì
[ResNet-18 Forward Pass]
    ‚Üì
Capture Activations @ layer4 (√∫ltima capa convolucional)
    ‚Üì
[Backward Pass on Predicted Class]
    ‚Üì
Compute Gradients ‚Üí Global Average Pooling
    ‚Üì
Weighted Combination: weights √ó activations
    ‚Üì
ReLU + Normalization [0, 1]
    ‚Üì
Resize to 224√ó224 + Apply Colormap
    ‚Üì
Overlay on Image (Œ±=0.4 transparency)
```

### Detalles de Implementaci√≥n

**Archivo**: `src_v2/visualization/gradcam.py`

**Target Layer**: `backbone.layer4` (√∫ltima capa convolucional de ResNet-18)

**Ecuaci√≥n clave**:
```python
# L√≠neas 201-205
weights = gradients.mean(dim=(2, 3), keepdim=True)  # Global Average Pooling
cam = (weights * activations).sum(dim=1)             # Weighted combination
cam = ReLU(cam)                                      # Keep only positive
cam = normalize(cam)                                 # [0, 1] range
```

**Par√°metros de visualizaci√≥n**:
- Colormap: `jet` (rojo = alta activaci√≥n, azul = baja)
- Transparencia (alpha): `0.4` (40% heatmap, 60% imagen original)
- Resoluci√≥n final: `224√ó224` p√≠xeles

---

## Justificaci√≥n en Diagn√≥stico M√©dico

### ¬øPor qu√© es importante Grad-CAM en aplicaciones m√©dicas?

#### 1. **Confianza Cl√≠nica**
- Los m√©dicos necesitan entender **por qu√©** el modelo hizo una predicci√≥n
- No es suficiente con un porcentaje de confianza
- Permite auditor√≠a visual de las decisiones del modelo

#### 2. **Validaci√≥n de Aprendizaje Correcto**
- Verifica que el modelo aprende patrones **cl√≠nicamente relevantes**:
  - ‚úÖ Consolidaciones pulmonares
  - ‚úÖ Opacidades en vidrio esmerilado (COVID-19)
  - ‚úÖ Infiltrados intersticiales (Neumon√≠a Viral)
- Detecta si aprende **artefactos espurios**:
  - ‚ùå Marcadores de texto
  - ‚ùå Tubos endotraqueales
  - ‚ùå Bordes de la imagen

#### 3. **Detecci√≥n de Sesgos**
- Identifica si el modelo usa caracter√≠sticas no relacionadas con patolog√≠a pulmonar
- Ejemplo: Si activa en la esquina superior (donde suele estar metadata), hay sesgo

#### 4. **Comunicaci√≥n con Stakeholders**
- Facilita explicar el sistema a personal m√©dico sin background en ML
- Genera confianza en la adopci√≥n cl√≠nica del sistema

---

## Integraci√≥n en Nuestro Pipeline

### Posici√≥n en el Sistema

```
1. Imagen Original (224√ó224)
         ‚Üì
2. Detecci√≥n de 15 Landmarks Anat√≥micos
         ‚Üì
3. Normalizaci√≥n Geom√©trica (Piecewise Affine Warping)
         ‚Üì
4. Clasificaci√≥n ResNet-18 (COVID/Normal/Viral Pneumonia)
         ‚Üì
5. üî• Grad-CAM: Visualizaci√≥n de Regiones de Atenci√≥n üî•
```

### Implementaci√≥n en GUI

**Archivo**: `src_v2/gui/app.py`

**Interfaz Gradio** - Tab "Demostraci√≥n Completa":

```python
# L√≠nea 124-128
img_gradcam = gr.Image(
    label="4Ô∏è‚É£ GradCAM: Regiones de Atenci√≥n",
    type="pil",
    height=300
)
```

**Pipeline de inferencia** (`src_v2/gui/inference_pipeline.py:167-170`):

```python
# Classify + GradCAM generation
probabilities, gradcam_heatmap, predicted_class_idx = manager.classify_with_gradcam(
    warped,
    target_class=None  # Use predicted class
)
```

---

## Interpretaci√≥n de Resultados por Clase

### COVID-19
**Patrones esperados**:
- Activaci√≥n en **periferias pulmonares** (subpleural)
- Opacidades en **vidrio esmerilado** (ground-glass opacities)
- Distribuci√≥n **bilateral** y **posterior**

**Ejemplo visual**:
```
[Imagen de radiograf√≠a]
    ‚Üì
[Grad-CAM muestra rojo en bases pulmonares bilaterales]
    ‚Üí Consistente con patr√≥n COVID-19
```

### Neumon√≠a Viral (No-COVID)
**Patrones esperados**:
- Infiltrados **difusos** o **focales**
- Consolidaciones en **zonas centrales**
- Patr√≥n **intersticial**

### Normal
**Patrones esperados**:
- Activaci√≥n **difusa y d√©bil**
- Sin focos espec√≠ficos de alta activaci√≥n
- Baja intensidad general del heatmap

---

## M√©trica Complementaria: Pulmonary Focus Score (PFS)

### Definici√≥n

**Archivo**: `src_v2/visualization/gradcam.py:238-284`

```python
PFS = sum(heatmap * lung_mask) / sum(heatmap)
```

### Interpretaci√≥n

| PFS Value | Significado |
|-----------|-------------|
| **1.0** | Toda la atenci√≥n est√° en tejido pulmonar (‚úÖ ideal) |
| **0.8-0.99** | Alta focalizaci√≥n pulmonar (‚úÖ aceptable) |
| **0.5-0.79** | Atenci√≥n dividida pulm√≥n/no-pulm√≥n (‚ö†Ô∏è revisar) |
| **< 0.5** | M√°s atenci√≥n en no-pulm√≥n (‚ùå problem√°tico) |

### Uso del PFS

- **Validaci√≥n autom√°tica** de calidad de Grad-CAM
- **M√©trica cuantitativa** de interpretabilidad
- **Detecci√≥n de modelos** que aprenden artefactos

---

## Ejemplo de Explicaci√≥n para Exposici√≥n

### Script Recomendado

> "Cuando un radi√≥logo o m√©dico carga una imagen en nuestro sistema, obtiene no solo una predicci√≥n (ej. 'COVID-19 con 95% de confianza'), sino tambi√©n un **mapa visual de explicabilidad** generado con Grad-CAM.
>
> Este mapa muestra en **colores c√°lidos (rojo/amarillo)** las regiones de la radiograf√≠a que el modelo consider√≥ m√°s relevantes para llegar a esa decisi√≥n. Por ejemplo, si predice COVID-19, esperamos ver activaci√≥n en las **periferias pulmonares** donde t√≠picamente aparecen las opacidades en vidrio esmerilado caracter√≠sticas de esta enfermedad.
>
> Esto es fundamental en aplicaciones m√©dicas porque:
> 1. **Genera confianza** - El m√©dico puede verificar que el modelo est√° mirando las zonas correctas
> 2. **Detecta errores** - Si el modelo activa en √°reas no pulmonares, sabemos que hay un problema
> 3. **Facilita la adopci√≥n cl√≠nica** - Los m√©dicos no usan 'cajas negras', necesitan entender el razonamiento"

---

## Aspectos T√©cnicos Avanzados

### ¬øPor qu√© layer4?

**Raz√≥n**: Es la **√∫ltima capa convolucional** antes del Global Average Pooling y la capa fully connected.

**Ventajas**:
- Tiene el **mayor campo receptivo** (puede "ver" toda la imagen)
- Sus activaciones son las **m√°s sem√°nticas** (representan conceptos de alto nivel)
- Mantiene cierta **resoluci√≥n espacial** (7√ó7 en ResNet-18) que se puede mapear a la imagen original

### Soporte Multi-Arquitectura

**Archivo**: `src_v2/visualization/gradcam.py:20-28`

Nuestro sistema soporta m√∫ltiples backbones:

```python
TARGET_LAYER_MAP = {
    "resnet18": "backbone.layer4",
    "resnet50": "backbone.layer4",
    "densenet121": "backbone.features.denseblock4",
    "efficientnet_b0": "backbone.features.8",
    "vgg16": "backbone.features.30",
    # ...
}
```

Esto permite **cambiar de arquitectura** sin modificar la l√≥gica de Grad-CAM.

---

## Limitaciones y Consideraciones

### Limitaciones de Grad-CAM

1. **Resoluci√≥n limitada**: El mapa de activaci√≥n original es de baja resoluci√≥n (7√ó7), se interpola a 224√ó224
2. **Solo activaciones positivas**: ReLU elimina contribuciones negativas (que tambi√©n son informativas)
3. **Promedio espacial**: Puede perder detalles finos de localizaci√≥n

### Alternativas Consideradas

- **Grad-CAM++**: Mejor localizaci√≥n de m√∫ltiples objetos (no necesario para pulmones)
- **Score-CAM**: Sin gradientes (m√°s lento)
- **Layer-CAM**: Similar rendimiento, mayor complejidad

**Decisi√≥n**: Grad-CAM cl√°sico es suficiente para nuestro caso de uso y bien validado en literatura m√©dica.

---

## Referencias Clave

### Paper Original

**Selvaraju et al. (2017)**
*"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization"*
ICCV 2017
https://arxiv.org/abs/1610.02391

### Aplicaciones en COVID-19

- **Brunese et al. (2020)**: "Explainable Deep Learning for Pulmonary Disease and Coronavirus COVID-19 Detection from X-rays"
- **Wang et al. (2020)**: "COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest X-Ray Images"

---

## Preguntas Frecuentes (Q&A para Expo)

### Q1: ¬øGrad-CAM es siempre correcto?

**A**: No. Grad-CAM muestra **lo que el modelo est√° usando**, no necesariamente **lo que deber√≠a usar**. Si el modelo aprende incorrectamente, Grad-CAM revelar√° ese error (lo cual es valioso).

### Q2: ¬øPuede Grad-CAM mejorar la precisi√≥n del modelo?

**A**: No directamente. Es una herramienta de **interpretabilidad**, no de mejora de rendimiento. Sin embargo, puede ayudar a **identificar problemas** que luego se corrigen (ej. data augmentation para eliminar sesgos).

### Q3: ¬øPor qu√© no usar solo Grad-CAM sin normalizaci√≥n geom√©trica?

**A**: Grad-CAM se aplica **despu√©s del warping** porque queremos ver qu√© regiones del **pulm√≥n normalizado** son importantes. La normalizaci√≥n mejora la consistencia anat√≥mica, lo que hace las activaciones m√°s interpretables.

### Q4: ¬øQu√© pasa si dos radiograf√≠as diferentes tienen Grad-CAMs similares pero predicciones distintas?

**A**: Esto podr√≠a indicar:
1. Diferencias sutiles no capturadas visualmente en el heatmap (resoluci√≥n limitada)
2. Caracter√≠sticas fuera del campo de atenci√≥n principal
3. Problema potencial del modelo (necesita revisi√≥n)

### Q5: ¬øEs Grad-CAM suficiente para validaci√≥n cl√≠nica?

**A**: Es **una herramienta**, no la √∫nica. La validaci√≥n completa requiere:
- M√©tricas cuantitativas (sensitivity, specificity)
- Revisi√≥n por radi√≥logos expertos
- Estudios multic√©ntricos
- Grad-CAM es complementario a estos enfoques

---

## C√≥digo de Referencia R√°pida

### Generar Grad-CAM manualmente

```python
from src_v2.visualization.gradcam import GradCAM, get_target_layer, overlay_heatmap

# Inicializar
model = load_classifier("path/to/checkpoint.pt")
target_layer = get_target_layer(model, "resnet18")
gradcam = GradCAM(model, target_layer)

# Generar heatmap
heatmap, pred_class, confidence = gradcam(input_tensor, target_class=None)

# Visualizar
overlay = overlay_heatmap(image, heatmap, alpha=0.5, colormap="jet")

# IMPORTANTE: Limpiar hooks
gradcam.remove_hooks()
```

### Calcular PFS

```python
from src_v2.visualization.gradcam import calculate_pfs

pfs_score = calculate_pfs(heatmap, lung_mask)
print(f"Pulmonary Focus Score: {pfs_score:.2%}")
```

---

## Checklist para la Exposici√≥n

- [ ] Explicar qu√© es Grad-CAM en 2 frases
- [ ] Mostrar ejemplo visual con colores (rojo = alta activaci√≥n)
- [ ] Justificar por qu√© es importante en medicina
- [ ] Demostrar en vivo con la GUI
- [ ] Mencionar que se aplica despu√©s del warping
- [ ] Explicar PFS si hay preguntas t√©cnicas
- [ ] Tener preparada respuesta sobre limitaciones
- [ ] Conectar con validaci√≥n cl√≠nica general del sistema

---

## Notas Adicionales

### Performance

- Tiempo de generaci√≥n: ~50-100ms adicionales
- Impacto en memoria GPU: m√≠nimo (hooks livianos)
- Se genera solo cuando se solicita (no en quick mode)

### Extensiones Futuras

1. **Grad-CAM a m√∫ltiples capas** (layer1-layer4) para ver evoluci√≥n jer√°rquica
2. **Integraci√≥n de PFS en GUI** con umbral de alerta
3. **Comparaci√≥n Grad-CAM** antes/despu√©s del warping
4. **Exportar heatmaps** a formato DICOM para PACS

---

**√öltima actualizaci√≥n**: 2026-01-18
**Versi√≥n del sistema**: v2.1.0
**Contacto**: Rafael Cruz - Tesis de Maestr√≠a
