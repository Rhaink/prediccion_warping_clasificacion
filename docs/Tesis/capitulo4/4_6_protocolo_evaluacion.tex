% =============================================================================
% CAPÍTULO 4: METODOLOGÍA
% Sección 4.6: Protocolo de Evaluación Experimental
% =============================================================================

\section{Protocolo de Evaluación Experimental}
\label{sec:protocolo_evaluacion}

Esta sección describe los protocolos de evaluación empleados para medir el rendimiento de cada componente del sistema propuesto. Se definen métricas específicas para la predicción de landmarks y la clasificación de enfermedades pulmonares.

\subsection{Métricas de Evaluación para Predicción de Landmarks}
\label{subsec:metricas_landmarks}

La evaluación del modelo de predicción de landmarks utiliza métricas basadas en el error euclidiano entre las coordenadas predichas y las anotaciones de referencia (valores de referencia).

\subsubsection{Error Euclidiano Medio}

La métrica principal es el error euclidiano medio (MED, por sus siglas en inglés \textit{Mean Euclidean Distance}), calculado en píxeles sobre imágenes de $224 \times 224$:

\begin{equation}
    \text{MED} = \frac{1}{N \cdot L} \sum_{i=1}^{N} \sum_{j=1}^{L} \sqrt{(x_{i,j} - \hat{x}_{i,j})^2 + (y_{i,j} - \hat{y}_{i,j})^2}
    \label{eq:med}
\end{equation}

\noindent donde $N$ es el número de imágenes, $L=15$ es el número de landmarks, $(x_{i,j}, y_{i,j})$ son las coordenadas de referencia del landmark $j$ en la imagen $i$, y $(\hat{x}_{i,j}, \hat{y}_{i,j})$ son las coordenadas predichas.

Dado que las coordenadas se almacenan normalizadas en el rango $[0, 1]$, la desnormalización se realiza multiplicando por el tamaño de imagen:

\begin{equation}
    \text{error}_{i,j} = \sqrt{((x_{i,j} - \hat{x}_{i,j}) \cdot S)^2 + ((y_{i,j} - \hat{y}_{i,j}) \cdot S)^2}
    \label{eq:error_pixels}
\end{equation}

\noindent donde $S = 224$ es el tamaño de la imagen de entrada al modelo.

\subsubsection{Error por Landmark Individual}

Para identificar landmarks problemáticos, se calcula el error medio por cada uno de los 15 landmarks:

\begin{equation}
    \text{MED}_j = \frac{1}{N} \sum_{i=1}^{N} \sqrt{(x_{i,j} - \hat{x}_{i,j})^2 + (y_{i,j} - \hat{y}_{i,j})^2} \cdot S
    \label{eq:error_per_landmark}
\end{equation}

Este análisis permite identificar patrones sistemáticos de error. Por ejemplo, landmarks del eje central (L9, L10, L11) típicamente presentan menor error que landmarks en los bordes de la silueta pulmonar (L12, L13 en los bordes superiores, y L14, L15 en los ángulos costofrénicos).

\subsubsection{Error por Categoría Diagnóstica}

El error se analiza también por categoría diagnóstica (COVID-19, Normal, Neumonía Viral) para detectar posibles sesgos del modelo hacia patrones específicos de cada condición:

\begin{equation}
    \text{MED}_c = \frac{1}{N_c \cdot L} \sum_{i \in \mathcal{C}_c} \sum_{j=1}^{L} \text{error}_{i,j}
    \label{eq:error_per_category}
\end{equation}

\noindent donde $\mathcal{C}_c$ es el conjunto de índices de imágenes pertenecientes a la categoría $c$, y $N_c = |\mathcal{C}_c|$.

\subsubsection{Distribución de Errores y Percentiles}

Además de las métricas de tendencia central, se reportan estadísticos de distribución que caracterizan el comportamiento del modelo en casos extremos:

\begin{itemize}
    \item \textbf{Desviación estándar:} Mide la dispersión de errores alrededor de la media.
    \item \textbf{Mediana (P50):} Valor central robusto a outliers.
    \item \textbf{Percentiles P75, P90, P95:} Caracterizan la cola de la distribución de errores.
\end{itemize}

La Tabla \ref{tab:percentiles_landmarks} presenta la interpretación de los percentiles en el contexto de calidad de predicción.

\begin{table}[htbp]
    \centering
    \caption{Interpretación de percentiles de error en predicción de landmarks.}
    \label{tab:percentiles_landmarks}
    \begin{tabular}{lcp{7cm}}
        \toprule
        \textbf{Percentil} & \textbf{Umbral} & \textbf{Interpretación} \\
        \midrule
        P50 (Mediana) & $< 5$ px & 50\% de predicciones con error menor a 5 píxeles \\
        P75 & $< 8$ px & 75\% de predicciones aceptables para warping \\
        P90 & $< 10$ px & 90\% dentro de tolerancia visual \\
        P95 & $< 15$ px & 95\% sin errores severos \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Tasa de Éxito por Umbral}

Para evaluar la proporción de predicciones que alcanzan diferentes niveles de precisión, se calcula la tasa de éxito bajo umbrales específicos:

\begin{equation}
    \text{SR}_\tau = \frac{1}{N \cdot L} \sum_{i=1}^{N} \sum_{j=1}^{L} \mathbb{1}[\text{error}_{i,j} < \tau]
    \label{eq:success_rate}
\end{equation}

\noindent donde $\mathbb{1}[\cdot]$ es la función indicadora y $\tau$ es el umbral en píxeles. Los umbrales estándar utilizados son $\tau \in \{5, 8, 10, 15\}$ píxeles.

\subsection{Métricas de Evaluación para Clasificación}
\label{subsec:metricas_clasificacion}

La evaluación del clasificador emplea métricas estándar de clasificación multiclase, con consideraciones específicas para el desbalance de clases presente en el conjunto de datos.

\subsubsection{Accuracy}

La exactitud (accuracy) mide la proporción de predicciones correctas sobre el total. Para clasificación multiclase con $K$ clases:

\begin{equation}
    \text{Accuracy} = \frac{\sum_{c=1}^{K} \text{TP}_c}{N} = \frac{\text{Predicciones correctas}}{\text{Total de muestras}}
    \label{eq:accuracy}
\end{equation}

\noindent donde $\text{TP}_c$ representa los verdaderos positivos de la clase $c$ (muestras de clase $c$ correctamente clasificadas) y $N$ es el número total de muestras.

Si bien es una métrica intuitiva, puede ser engañosa en conjuntos de datos desbalanceados donde un clasificador trivial que predice siempre la clase mayoritaria alcanzaría alta accuracy.

\subsubsection{Precision, Recall y F1-Score por Clase}

Para cada clase $c$, se calculan:

\begin{align}
    \text{Precision}_c &= \frac{\text{TP}_c}{\text{TP}_c + \text{FP}_c} \label{eq:precision} \\
    \text{Recall}_c &= \frac{\text{TP}_c}{\text{TP}_c + \text{FN}_c} \label{eq:recall} \\
    \text{F1}_c &= 2 \cdot \frac{\text{Precision}_c \cdot \text{Recall}_c}{\text{Precision}_c + \text{Recall}_c} \label{eq:f1}
\end{align}

\noindent donde $\text{TP}_c$, $\text{FP}_c$ y $\text{FN}_c$ son los verdaderos positivos, falsos positivos y falsos negativos para la clase $c$, respectivamente.

\subsubsection{F1-Score Macro vs F1-Score Weighted}
\label{subsubsec:f1_macro_weighted}

Para obtener una métrica global a partir de los F1-Scores por clase, existen dos estrategias de agregación:

\textbf{F1-Macro:} Promedia los F1-Scores de todas las clases con peso uniforme:

\begin{equation}
    \text{F1-Macro} = \frac{1}{K} \sum_{c=1}^{K} \text{F1}_c
    \label{eq:f1_macro}
\end{equation}

\textbf{F1-Weighted:} Promedia ponderando por el número de muestras de cada clase:

\begin{equation}
    \text{F1-Weighted} = \sum_{c=1}^{K} \frac{n_c}{N} \cdot \text{F1}_c
    \label{eq:f1_weighted}
\end{equation}

\noindent donde $n_c$ es el número de muestras de la clase $c$ y $N$ es el total de muestras.

\textbf{Justificación del uso de F1-Macro:} En este trabajo se selecciona F1-Macro como métrica principal por las siguientes razones:

\begin{enumerate}
    \item \textbf{Equidad entre clases:} En el contexto médico, el rendimiento en clases minoritarias (Neumonía Viral, 9\% del conjunto de datos) es tan importante como en clases mayoritarias (Normal, 67\%). F1-Macro pondera equitativamente el rendimiento en cada clase.

    \item \textbf{Detección de sesgos:} F1-Weighted puede enmascarar un rendimiento deficiente en clases minoritarias. Un modelo con F1-Weighted de 0.95 podría tener F1 de 0.50 en la clase minoritaria sin que esto se refleje significativamente en la métrica agregada.

    \item \textbf{Consistencia con el manejo de desbalance:} El uso de pesos de clase durante el entrenamiento (Sección \ref{subsec:config_entrenamiento_clasificador}) tiene como objetivo mejorar el rendimiento en clases minoritarias; F1-Macro refleja directamente este objetivo.

    \item \textbf{Práctica estándar:} La literatura de clasificación de imágenes médicas con conjuntos de datos desbalanceados recomienda el uso de F1-Macro \cite{sokolova2009systematic, grandini2020metrics}.
\end{enumerate}

La Tabla \ref{tab:f1_macro_vs_weighted} ilustra la diferencia entre ambas métricas con un ejemplo hipotético.

\begin{table}[htbp]
    \centering
    \caption{Comparación entre F1-Macro y F1-Weighted en un escenario de desbalance.}
    \label{tab:f1_macro_vs_weighted}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Clase} & \textbf{Muestras (\%)} & \textbf{F1} & \textbf{Contrib. Macro} & \textbf{Contrib. Weighted} \\
        \midrule
        COVID-19 & 24\% & 0.98 & 0.327 & 0.235 \\
        Normal & 67\% & 0.99 & 0.330 & 0.663 \\
        Neumonía Viral & 9\% & 0.85 & 0.283 & 0.077 \\
        \midrule
        \textbf{Total} & 100\% & — & \textbf{0.940} & \textbf{0.975} \\
        \bottomrule
    \end{tabular}
\end{table}

Como se observa, F1-Weighted (0.975) enmascara el rendimiento inferior en Neumonía Viral, mientras que F1-Macro (0.940) refleja más fielmente el rendimiento equilibrado entre clases.

\subsubsection{Matriz de Confusión}

La matriz de confusión $\mathbf{C} \in \mathbb{R}^{K \times K}$ proporciona un diagnóstico detallado del comportamiento del clasificador, donde $C_{ij}$ representa el número de muestras de la clase verdadera $i$ clasificadas como clase $j$:

\begin{equation}
    \mathbf{C} = \begin{bmatrix}
        C_{11} & C_{12} & C_{13} \\
        C_{21} & C_{22} & C_{23} \\
        C_{31} & C_{32} & C_{33}
    \end{bmatrix}
    \label{eq:confusion_matrix}
\end{equation}

Los elementos diagonales $C_{ii}$ corresponden a clasificaciones correctas, mientras que los elementos fuera de la diagonal revelan patrones de confusión entre clases.

\subsection{Test-Time Augmentation para Predicción de Landmarks}
\label{subsec:tta_evaluacion}

Durante la evaluación del modelo de landmarks, se emplea Test-Time Augmentation (TTA) para mejorar la precisión de las predicciones mediante el promediado de múltiples vistas de la misma imagen.

\subsubsection{Procedimiento de TTA}

El procedimiento implementado utiliza flip horizontal:

\begin{enumerate}
    \item \textbf{Predicción original:} Obtener predicción $\hat{\mathbf{p}}$ para la imagen original.

    \item \textbf{Flip de imagen:} Aplicar reflexión horizontal a la imagen de entrada.

    \item \textbf{Predicción flip:} Obtener predicción $\hat{\mathbf{p}}'$ para la imagen reflejada.

    \item \textbf{Corrección de coordenadas:} Revertir el flip en las coordenadas predichas:
    \begin{align}
        \hat{x}'_j &\leftarrow 1 - \hat{x}'_j \\
        \text{Intercambiar pares simétricos:} & \quad (L3 \leftrightarrow L4), (L5 \leftrightarrow L6), \ldots
    \end{align}

    \item \textbf{Promediado:} Calcular la predicción final como promedio:
    \begin{equation}
        \hat{\mathbf{p}}_{\text{TTA}} = \frac{\hat{\mathbf{p}} + \hat{\mathbf{p}}'_{\text{corregido}}}{2}
        \label{eq:tta_averaging}
    \end{equation}
\end{enumerate}

Los pares simétricos intercambiados son: (L3, L4), (L5, L6), (L7, L8), (L12, L13), (L14, L15).

\subsection{Resumen del Protocolo de Evaluación}
\label{subsec:resumen_protocolo}

La Tabla \ref{tab:resumen_protocolo_evaluacion} consolida los protocolos de evaluación definidos en esta sección.

\begin{table}[htbp]
    \centering
    \caption{Resumen de protocolos de evaluación experimental.}
    \label{tab:resumen_protocolo_evaluacion}
    \begin{tabular}{p{3.5cm}p{4cm}p{5cm}}
        \toprule
        \textbf{Protocolo} & \textbf{Métricas Principales} & \textbf{Objetivo} \\
        \midrule
        Evaluación de Landmarks & MED (px), Error por landmark, Percentiles & Medir precisión de predicción de puntos anatómicos \\
        \midrule
        Evaluación de Clasificación & Accuracy, F1-Macro, Matriz de confusión & Medir rendimiento de clasificación multiclase \\
        \bottomrule
    \end{tabular}
\end{table}


% Referencias temporales para esta sección
% \cite{sokolova2009systematic} - Sokolova & Lapalme, A systematic analysis of performance measures (2009)
% \cite{grandini2020metrics} - Grandini et al., Metrics for Multi-Class Classification (2020)
% \cite{kumar2021fedcovidx} - Kumar et al., FedCOVIDx (2021)
