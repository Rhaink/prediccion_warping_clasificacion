% =============================================================================
% CAPÍTULO 4: METODOLOGÍA
% Sección 4.5: Clasificación de Enfermedades Pulmonares
% =============================================================================

\section{Clasificación de Enfermedades Pulmonares}
\label{sec:clasificacion}

Una vez que las imágenes han sido normalizadas geométricamente mediante el proceso de warping descrito en la sección anterior, el siguiente paso del sistema es la clasificación automática en una de tres categorías diagnósticas: COVID-19, Normal o Neumonía Viral. Esta sección describe la arquitectura ResNet-18 seleccionada, la estrategia de aprendizaje por transferencia empleada y la configuración del entrenamiento.

\subsection{Arquitectura del Clasificador}
\label{subsec:arquitectura_clasificador}

Para la tarea de clasificación se seleccionó ResNet-18 \cite{he2016deep} como arquitectura base, inicializada con pesos preentrenados en ImageNet \cite{deng2009imagenet}. ResNet-18 ofrece un balance óptimo entre capacidad de representación y eficiencia computacional para este problema.

\subsubsection{Justificación de ResNet-18}

La selección de ResNet-18 se fundamenta en las siguientes características:

\begin{enumerate}
    \item \textbf{Consistencia arquitectónica:} Utiliza la misma familia de arquitectura que el modelo de predicción de landmarks (ResNet-18 con Coordinate Attention), facilitando la integración y mantenimiento del sistema completo.

    \item \textbf{Eficiencia computacional:} Con 11.2 millones de parámetros, permite iteraciones rápidas durante el entrenamiento y la experimentación sin comprometer significativamente el rendimiento.

    \item \textbf{Conexiones residuales:} Las conexiones de salto (skip connections) mitigan el problema de desvanecimiento de gradiente, permitiendo entrenar modelos más profundos de manera efectiva \cite{he2016deep}.

    \item \textbf{Rendimiento comprobado:} ResNet-18 ha demostrado buen desempeño en múltiples tareas de clasificación de imágenes médicas, incluyendo diagnóstico de enfermedades torácicas en radiografías \cite{rajpurkar2017chexnet}.
\end{enumerate}

\subsubsection{Rendimiento Obtenido}

La Tabla \ref{tab:rendimiento_resnet18} presenta el rendimiento del clasificador ResNet-18 en el conjunto de datos normalizado geométricamente.

\begin{table}[htbp]
    \centering
    \caption{Rendimiento del clasificador ResNet-18 en el conjunto de prueba con imágenes normalizadas geométricamente.}
    \label{tab:rendimiento_resnet18}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Arquitectura} & \textbf{Accuracy} & \textbf{F1-Macro} & \textbf{F1-Weighted} & \textbf{Parámetros} \\
        \midrule
        ResNet-18 & 98.05\% & 97.12\% & 98.04\% & 11.2M \\
        \bottomrule
    \end{tabular}
\end{table}

El clasificador alcanza 98.05\% de \textit{accuracy} en el conjunto de prueba, con F1-Macro de 97.12\% y F1-Weighted de 98.04\%. El F1-Macro, que pondera equitativamente el rendimiento en cada clase, es particularmente relevante dado el desbalance del conjunto de datos (67\% Normal, 24\% COVID-19, 9\% Neumonía Viral).

\subsection{Estrategia de Aprendizaje por Transferencia}
\label{subsec:transfer_learning_clasificacion}

El entrenamiento del clasificador emplea aprendizaje por transferencia desde ImageNet, una estrategia que ha demostrado ser efectiva para tareas de clasificación de imágenes médicas donde los conjuntos de datos disponibles son típicamente pequeños \cite{raghu2019transfusion}.

\subsubsection{Adaptación de la Arquitectura}

Para adaptar las arquitecturas preentrenadas a la tarea de clasificación de tres clases, se modifica únicamente la capa de clasificación final:

\begin{enumerate}
    \item \textbf{Carga de pesos:} Se cargan los pesos preentrenados en ImageNet para todas las capas convolucionales y de pooling.

    \item \textbf{Reemplazo del clasificador:} La capa fully connected original (diseñada para 1000 clases de ImageNet) se reemplaza por una nueva capa con la estructura:
    \begin{equation}
        \text{Clasificador} = \text{Dropout}(p=0.3) \rightarrow \text{Linear}(d_{\text{in}}, 3)
    \end{equation}
    donde $d_{\text{in}}$ es la dimensión de las características del backbone (512 para ResNet-18, 1280 para EfficientNet-B0).

    \item \textbf{Inicialización:} Los pesos de la nueva capa se inicializan aleatoriamente mientras que el resto de la red mantiene los pesos de ImageNet.
\end{enumerate}

\subsubsection{Ajuste fino de la Red Completa}

A diferencia del modelo de landmarks que utiliza un esquema de dos fases (backbone congelado seguido de ajuste fino), el clasificador se entrena con ajuste fino completo desde el inicio. Esta decisión se justifica por:

\begin{itemize}
    \item \textbf{Conjunto de datos más grande:} El conjunto de imágenes normalizadas (15,153 imágenes) es significativamente mayor que el conjunto de datos de landmarks (957 imágenes).
    \item \textbf{Tarea más estándar:} La clasificación de imágenes es más similar a las tareas de ImageNet que la regresión de coordenadas.
    \item \textbf{Regularización implícita:} El preprocesamiento CLAHE y la normalización geométrica reducen la variabilidad, actuando como regularización implícita.
\end{itemize}

\subsection{Configuración del Entrenamiento}
\label{subsec:config_entrenamiento_clasificador}

El entrenamiento del clasificador sigue un protocolo estándar de clasificación de imágenes con adaptaciones específicas para el desbalance de clases presente en el conjunto de datos.

\subsubsection{Distribución del Conjunto de Datos}

El conjunto de datos de imágenes normalizadas se divide en tres subconjuntos siguiendo la estrategia de partición estratificada descrita en la Sección \ref{sec:dataset_preprocesamiento}. La Tabla \ref{tab:distribucion_clasificador} muestra la distribución de clases.

\begin{table}[htbp]
    \centering
    \caption{Distribución del conjunto de datos para entrenamiento del clasificador.}
    \label{tab:distribucion_clasificador}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Clase} & \textbf{Train} & \textbf{Val} & \textbf{Test} & \textbf{Total (\%)} \\
        \midrule
        COVID-19 & 2,712 & 542 & 362 & 3,616 (24\%) \\
        Normal & 7,644 & 1,529 & 1,020 & 10,193 (67\%) \\
        Neumonía Viral & 1,008 & 200 & 136 & 1,344 (9\%) \\
        \midrule
        \textbf{Total} & 11,364 & 2,271 & 1,518 & \textbf{15,153} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Manejo del Desbalance de Clases}

El conjunto de datos presenta un desbalance significativo, con la clase Normal representando el 67\% de las muestras mientras que Neumonía Viral solo representa el 9\%. Para mitigar el sesgo hacia las clases mayoritarias, se utilizan pesos de clase inversamente proporcionales a su frecuencia:

\begin{equation}
    w_c = \frac{N}{K \cdot n_c}
    \label{eq:class_weights}
\end{equation}

\noindent donde $N$ es el número total de muestras, $K$ es el número de clases (3), y $n_c$ es el número de muestras de la clase $c$.

Aplicando la Ecuación \ref{eq:class_weights} al conjunto de entrenamiento:

\begin{table}[htbp]
    \centering
    \caption{Pesos de clase calculados para balanceo del entrenamiento.}
    \label{tab:class_weights}
    \begin{tabular}{lcc}
        \toprule
        \textbf{Clase} & \textbf{Muestras (Train)} & \textbf{Peso} \\
        \midrule
        COVID-19 & 2,712 & 1.40 \\
        Normal & 7,644 & 0.50 \\
        Neumonía Viral & 1,008 & 3.76 \\
        \bottomrule
    \end{tabular}
\end{table}

Estos pesos se incorporan en la función de pérdida Cross-Entropy:

\begin{equation}
    \mathcal{L}_{\text{CE}} = -\sum_{c=1}^{K} w_c \cdot y_c \cdot \log(\hat{y}_c)
\end{equation}

\noindent donde $y_c$ es la etiqueta verdadera (one-hot) y $\hat{y}_c$ es la probabilidad predicha para la clase $c$.

\subsubsection{Hiperparámetros de Entrenamiento}

La Tabla \ref{tab:hiperparametros_clasificador} resume la configuración de hiperparámetros utilizada.

\begin{table}[htbp]
    \centering
    \caption{Hiperparámetros del entrenamiento del clasificador.}
    \label{tab:hiperparametros_clasificador}
    \begin{tabular}{ll}
        \toprule
        \textbf{Parámetro} & \textbf{Valor} \\
        \midrule
        Épocas máximas & 50 \\
        Tamaño de lote & 32 \\
        Tasa de aprendizaje inicial & $1 \times 10^{-4}$ \\
        Optimizador & Adam ($\beta_1=0.9$, $\beta_2=0.999$) \\
        Función de pérdida & Cross-Entropy con pesos de clase \\
        Dropout & 0.3 \\
        Parada temprana & Paciencia = 10 épocas \\
        Métrica de monitoreo & F1-Score Macro (validación) \\
        Semilla aleatoria & 42 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Parada Temprana}

Para prevenir el sobreajuste y determinar el momento óptimo de detención del entrenamiento, se implementa parada temprana basado en el F1-Score Macro del conjunto de validación:

\begin{enumerate}
    \item Se monitorea el F1-Score Macro después de cada época.
    \item Si no hay mejora durante 10 épocas consecutivas, el entrenamiento se detiene.
    \item Se guarda el modelo con el mejor F1-Score de validación.
\end{enumerate}

La selección de F1-Score Macro sobre accuracy como métrica de monitoreo se justifica por el desbalance de clases: F1-Macro pondera equitativamente el rendimiento en cada clase, evitando que el modelo optimice solo para la clase mayoritaria.

\subsection{Aumento de Datos}
\label{subsec:augmentation_clasificador}

Durante el entrenamiento se aplican transformaciones de aumento de datos para mejorar la generalización del modelo. Las transformaciones se diseñaron para ser compatibles con las características de las radiografías normalizadas.

\subsubsection{Transformaciones de Entrenamiento}

\begin{enumerate}
    \item \textbf{Conversión a RGB:} Las imágenes en escala de grises se convierten a tres canales replicando el canal de luminancia, requisito de las arquitecturas preentrenadas en ImageNet.

    \item \textbf{Redimensionamiento:} Las imágenes se escalan a $224 \times 224$ píxeles.

    \item \textbf{Flip horizontal} (probabilidad 0.5): Refleja la imagen horizontalmente, simulando variaciones de orientación del paciente.

    \item \textbf{Rotación aleatoria} ($\pm$10 grados): Introduce pequeñas variaciones rotacionales que pueden ocurrir durante la adquisición.

    \item \textbf{Transformación afín aleatoria:}
    \begin{itemize}
        \item Traslación: $\pm$5\% en ambos ejes
        \item Escala: 95\%--105\%
    \end{itemize}

    \item \textbf{Normalización ImageNet:} Se aplican media y desviación estándar de ImageNet:
    \begin{align}
        \mu &= [0.485, 0.456, 0.406] \\
        \sigma &= [0.229, 0.224, 0.225]
    \end{align}
\end{enumerate}

\subsubsection{Transformaciones de Evaluación}

Durante la evaluación y prueba, solo se aplican las transformaciones determinísticas:

\begin{enumerate}
    \item Conversión a RGB
    \item Redimensionamiento a $224 \times 224$
    \item Normalización ImageNet
\end{enumerate}

La Figura \ref{fig:augmentation_clasificador} ilustra ejemplos de las transformaciones aplicadas.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/F4.12_aumento_datos.png}
    \caption{Ejemplos de transformaciones de aumento de datos aplicadas durante el entrenamiento del clasificador. Las transformaciones preservan la integridad diagnóstica de las imágenes mientras aumentan la variabilidad del conjunto de entrenamiento.}
    \label{fig:augmentation_clasificador}
\end{figure}

\subsection{Resumen de la Configuración del Clasificador}
\label{subsec:resumen_clasificador}

La Tabla \ref{tab:resumen_clasificador} consolida la configuración completa del módulo de clasificación.

\begin{table}[htbp]
    \centering
    \caption{Resumen de la configuración del clasificador de enfermedades pulmonares.}
    \label{tab:resumen_clasificador}
    \begin{tabular}{llc}
        \toprule
        \textbf{Categoría} & \textbf{Parámetro} & \textbf{Valor} \\
        \midrule
        \multirow{4}{*}{Arquitectura}
            & Backbone & ResNet-18 \\
            & Preentrenamiento & ImageNet \\
            & Clases de salida & 3 \\
            & Parámetros totales & $\sim$11.2M \\
        \midrule
        \multirow{2}{*}{Regularización}
            & Dropout & 0.3 \\
            & Aumento de datos & Flip, rotación, afín \\
        \midrule
        \multirow{5}{*}{Entrenamiento}
            & Épocas & 50 (con parada temprana) \\
            & Tamaño de lote & 32 \\
            & Tasa de aprendizaje & $1 \times 10^{-4}$ \\
            & Optimizador & Adam \\
            & Pesos de clase & Habilitados \\
        \midrule
        \multirow{2}{*}{Parada Temprana}
            & Paciencia & 10 épocas \\
            & Métrica & F1-Score Macro \\
        \bottomrule
    \end{tabular}
\end{table}

% Referencias temporales para esta sección
% \cite{deng2009imagenet} - Deng et al., ImageNet (CVPR 2009)
% \cite{krizhevsky2012imagenet} - Krizhevsky et al., AlexNet (NIPS 2012)
% \cite{simonyan2014very} - Simonyan & Zisserman, VGG (ICLR 2015)
% \cite{he2016deep} - He et al., ResNet (CVPR 2016)
% \cite{huang2017densely} - Huang et al., DenseNet (CVPR 2017)
% \cite{sandler2018mobilenetv2} - Sandler et al., MobileNetV2 (CVPR 2018)
% \cite{tan2019efficientnet} - Tan & Le, EfficientNet (ICML 2019)
% \cite{rajpurkar2017chexnet} - Rajpurkar et al., CheXNet (arXiv 2017)
% \cite{raghu2019transfusion} - Raghu et al., Transfusion (NeurIPS 2019)
