% =============================================================================
% CAPÍTULO 4: METODOLOGÍA
% Sección 4.5: Clasificación de Enfermedades Pulmonares
% =============================================================================

\section{Clasificación de Enfermedades Pulmonares}
\label{sec:clasificacion}

Una vez que las imágenes han sido normalizadas geométricamente mediante el proceso de deformación descrito en la sección anterior, el siguiente paso del sistema es la clasificación automática. El objetivo es determinar a cuál de las tres categorías diagnósticas pertenece cada radiografía: COVID-19, Normal o Neumonía Viral.

Esta sección describe los componentes principales del módulo de clasificación: el preprocesamiento de contraste aplicado a las imágenes, la arquitectura de red neuronal seleccionada, la estrategia para aprovechar conocimiento previo de otras tareas (aprendizaje por transferencia), y la configuración del proceso de entrenamiento.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.98\textwidth]{Figures/F4.14_flujo_clasificacion.png}
    \caption{Diagrama general del módulo de clasificación. Se muestra el flujo de inferencia desde la imagen normalizada hasta la predicción final, y los componentes usados solo durante entrenamiento (aumento de datos, pesos por clase y entropía cruzada).}
    \label{fig:flujo_clasificacion}
\end{figure}

\subsection{Preprocesamiento de Contraste}
\label{subsec:preprocesamiento_contraste}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{Figures/F4.13_warped_sahs.png}
    \caption{Efecto del preprocesamiento SAHS sobre imágenes normalizadas geométricamente. Cada fila muestra una categoría diagnóstica diferente (COVID-19, Normal, Neumonía Viral). Las columnas muestran: (a) imagen después de la normalización geométrica, histograma original, (b) imagen con SAHS aplicado, e histograma resultante. Se observa cómo SAHS redistribuye las intensidades mejorando el contraste sin amplificar artefactos.}
    \label{fig:warped_sahs}
\end{figure}

Antes de la clasificación, las imágenes normalizadas geométricamente requieren un ajuste de contraste para optimizar la visibilidad de las estructuras pulmonares. Como se describe en la Sección \ref{sec:sahs}, las radiografías de tórax presentan histogramas de intensidad marcadamente asimétricos, lo que hace que técnicas convencionales como CLAHE presenten limitaciones: amplificación de ruido en áreas suaves y alteración de regiones brillantes indicativas de infiltrados pulmonares.

Para abordar estas limitaciones, se aplica el método SAHS (\textit{Statistical Asymmetrical Histogram Stretching}) \cite{cruz2025sahs} a las imágenes deformadas. Este método calcula límites de estiramiento asimétricos que se adaptan a la distribución característica de los histogramas radiográficos, preservando la información diagnóstica relevante.

La elección de SAHS sobre otras técnicas se fundamenta en:

\begin{itemize}
    \item \textbf{Preservación de información diagnóstica:} Los factores asimétricos (2.5 para el límite superior, 2.0 para el inferior) preservan las regiones brillantes características de infiltrados pulmonares.

    \item \textbf{Robustez:} El enfoque estadístico minimiza la influencia de píxeles atípicos causados por ruido o artefactos del proceso de deformación.

    \item \textbf{Eficiencia:} A diferencia de CLAHE, SAHS opera globalmente, reduciendo el costo computacional.
\end{itemize}

La Figura \ref{fig:warped_sahs} muestra el efecto de aplicar SAHS a imágenes normalizadas geométricamente de las tres categorías diagnósticas.

\subsection{Arquitectura del Clasificador}
\label{subsec:arquitectura_clasificador}

Para la tarea de clasificación se seleccionó la arquitectura ResNet-18 \cite{he2016deep}, una red neuronal convolucional diseñada específicamente para el análisis de imágenes. El nombre hace referencia a su profundidad de 18 capas y a su característica distintiva: las conexiones residuales, que permiten que la información fluya de manera más eficiente a través de la red.

Esta arquitectura se inicializa con conocimiento previamente adquirido del conjunto ImageNet \cite{deng2009imagenet}, una base de datos de millones de imágenes cotidianas. Aunque las radiografías difieren de las imágenes de ImageNet, las capas iniciales de la red aprenden a detectar patrones visuales básicos (bordes, texturas, formas) que son útiles para cualquier tarea de análisis de imágenes.

\subsubsection{Justificación de ResNet-18}

La selección de ResNet-18 se fundamenta en las siguientes características:

\begin{enumerate}
    \item \textbf{Consistencia con el sistema:} Se utiliza la misma familia de arquitectura que el modelo de detección de puntos de referencia, lo que facilita la integración y mantenimiento del sistema completo.

    \item \textbf{Eficiencia:} Con 11.2 millones de parámetros ajustables, la red es suficientemente expresiva para capturar patrones complejos, pero lo bastante compacta para entrenar de manera eficiente.

    \item \textbf{Conexiones residuales:} Esta innovación arquitectónica permite que la información se transmita directamente entre capas no consecutivas, evitando que la señal de aprendizaje se degrade en redes profundas \cite{he2016deep}.

    \item \textbf{Rendimiento comprobado:} ResNet-18 ha demostrado buen desempeño en múltiples tareas de clasificación de imágenes médicas, incluyendo el diagnóstico de enfermedades torácicas en radiografías \cite{rajpurkar2017chexnet}.
\end{enumerate}

\subsection{Estrategia de Aprendizaje por Transferencia}
\label{subsec:transfer_learning_clasificacion}

El aprendizaje por transferencia es una técnica que permite aprovechar el conocimiento que una red neuronal ha adquirido en una tarea para aplicarlo a otra diferente. En este caso, se utiliza una red previamente entrenada para reconocer miles de objetos cotidianos (ImageNet) y se adapta para clasificar radiografías de tórax. Esta estrategia es especialmente efectiva cuando se dispone de conjuntos de datos relativamente pequeños, como es común en aplicaciones médicas \cite{raghu2019transfusion}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.98\textwidth]{Figures/F4.18_transfer_learning_clasificador.png}
    \caption{Esquema del aprendizaje por transferencia en el clasificador. Se reutiliza el backbone ResNet-18 preentrenado, se reemplaza la capa final por tres salidas y se realiza ajuste fino completo para adaptar el modelo al diagnóstico de COVID-19, Normal y Neumonía Viral.}
    \label{fig:transfer_learning_clasificador}
\end{figure}

\subsubsection{Adaptación de la Arquitectura}

Para adaptar la red preentrenada a la clasificación de tres categorías diagnósticas, se realizan las siguientes modificaciones:

\begin{enumerate}
    \item \textbf{Conservación del extractor de características:} Se mantienen intactos los parámetros de las capas convolucionales, que han aprendido a identificar patrones visuales relevantes.

    \item \textbf{Reemplazo de la capa de decisión:} La capa final, originalmente diseñada para distinguir entre 1000 categorías de objetos, se reemplaza por una nueva capa que produce tres salidas correspondientes a las categorías diagnósticas (COVID-19, Normal, Neumonía Viral).

    \item \textbf{Inicialización selectiva:} Solo los parámetros de la nueva capa de decisión se inicializan de forma aleatoria; el resto de la red conserva el conocimiento adquirido previamente.
\end{enumerate}

\subsubsection{Ajuste fino de la Red Completa}

El ajuste fino consiste en continuar el entrenamiento de toda la red, permitiendo que los parámetros preentrenados se adapten gradualmente a la nueva tarea. A diferencia del modelo de detección de puntos de referencia, que utiliza un esquema en dos fases, el clasificador se entrena con ajuste fino completo desde el inicio. Esta decisión se justifica por:

\begin{itemize}
    \item \textbf{Mayor volumen de datos:} El conjunto de imágenes normalizadas (15,153 imágenes) es considerablemente mayor que el conjunto utilizado para entrenar el modelo de puntos de referencia (957 imágenes), lo que reduce el riesgo de sobreajuste.
    \item \textbf{Similitud con la tarea original:} La clasificación de imágenes es más similar a las tareas de ImageNet que la predicción de coordenadas específicas.
    \item \textbf{Preprocesamiento estandarizado:} La normalización geométrica aplicadas previamente reducen la variabilidad entre imágenes, facilitando el aprendizaje.
\end{itemize}

\subsection{Configuración del Entrenamiento}
\label{subsec:config_entrenamiento_clasificador}

El proceso de entrenamiento consiste en ajustar los parámetros de la red de manera iterativa, presentándole ejemplos etiquetados para que aprenda a distinguir entre las tres categorías diagnósticas. Esta sección describe los aspectos clave de la configuración, incluyendo cómo se manejan las diferencias en la cantidad de ejemplos disponibles para cada categoría.

\subsubsection{Distribución del Conjunto de Datos}

El conjunto de datos de imágenes normalizadas se divide en tres subconjuntos siguiendo la estrategia de partición descrita en la Sección \ref{sec:dataset_preprocesamiento}. La Tabla \ref{tab:distribucion_clasificador} muestra la distribución por categoría diagnóstica.

\begin{table}[htbp]
    \centering
    \caption{Distribución del conjunto de datos para entrenamiento del clasificador.}
    \label{tab:distribucion_clasificador}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Categoría} & \textbf{Entrenamiento} & \textbf{Validación} & \textbf{Prueba} & \textbf{Total (\%)} \\
        \midrule
        COVID-19 & 2,712 & 542 & 362 & 3,616 (24\%) \\
        Normal & 7,644 & 1,529 & 1,020 & 10,193 (67\%) \\
        Neumonía Viral & 1,008 & 200 & 136 & 1,344 (9\%) \\
        \midrule
        \textbf{Total} & 11,364 & 2,271 & 1,518 & \textbf{15,153} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Manejo del Desbalance de Clases}

Como se observa en la Tabla \ref{tab:distribucion_clasificador}, el conjunto de datos presenta un desbalance considerable: la categoría Normal representa el 67\% de las muestras, mientras que Neumonía Viral solo el 9\%. Sin una corrección adecuada, el modelo tendería a favorecer las categorías más frecuentes, perjudicando la detección de las menos comunes.

Para compensar este desbalance, se asigna a cada categoría un peso inversamente proporcional a su frecuencia. De esta manera, los errores en categorías poco representadas penalizan más al modelo durante el entrenamiento, incentivándolo a prestarles mayor atención. La Tabla \ref{tab:class_weights} muestra los pesos calculados.

\begin{table}[htbp]
    \centering
    \caption{Pesos asignados a cada categoría para compensar el desbalance del conjunto de datos.}
    \label{tab:class_weights}
    \begin{tabular}{lcc}
        \toprule
        \textbf{Categoría} & \textbf{Muestras (Entrenamiento)} & \textbf{Peso} \\
        \midrule
        COVID-19 & 2,712 & 1.40 \\
        Normal & 7,644 & 0.50 \\
        Neumonía Viral & 1,008 & 3.76 \\
        \bottomrule
    \end{tabular}
\end{table}

Estos pesos se incorporan en la función de pérdida, que es la medida que el modelo busca minimizar durante el entrenamiento. Al ponderar los errores de esta manera, se logra que el modelo aprenda a clasificar correctamente todas las categorías, no solo las más frecuentes.

\subsubsection{Parámetros de Entrenamiento}

Los parámetros de entrenamiento controlan aspectos como la velocidad de aprendizaje, el número de ejemplos procesados simultáneamente, y los criterios para detener el entrenamiento. La Tabla \ref{tab:hiperparametros_clasificador} resume la configuración utilizada.

\begin{table}[htbp]
    \centering
    \caption{Parámetros de configuración del entrenamiento del clasificador.}
    \label{tab:hiperparametros_clasificador}
    \begin{tabular}{ll}
        \toprule
        \textbf{Parámetro} & \textbf{Valor} \\
        \midrule
        Épocas máximas & 50 \\
        Tamaño de lote & 32 imágenes \\
        Tasa de aprendizaje & $1 \times 10^{-4}$ \\
        Optimizador & Adam \\
        Función de pérdida & Entropía cruzada con pesos \\
        Dropout & 0.3 (30\% de neuronas desactivadas) \\
        Parada temprana & Paciencia de 10 épocas \\
        Semilla aleatoria & 42 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Parada Temprana}

El sobreajuste ocurre cuando un modelo aprende demasiado bien los ejemplos de entrenamiento, incluyendo sus particularidades y ruido, perdiendo capacidad de generalizar a ejemplos nuevos. Para prevenirlo, se implementa un mecanismo de parada temprana que detiene el entrenamiento cuando el modelo deja de mejorar en el conjunto de validación.

El proceso funciona de la siguiente manera:

\begin{enumerate}
    \item Después de cada pasada completa por el conjunto de entrenamiento (época), se evalúa el rendimiento en el conjunto de validación.
    \item Si transcurren 10 épocas consecutivas sin mejora, el entrenamiento se detiene automáticamente.
    \item Se conserva la versión del modelo que obtuvo el mejor rendimiento en validación.
\end{enumerate}

Como métrica de seguimiento para la parada temprana se utiliza el F1-Score Macro, que promedia el rendimiento en las tres categorías sin favorecer a las más frecuentes. Esta elección evita que el modelo se especialice en la categoría mayoritaria (Normal) durante el entrenamiento.

\subsection{Métricas de Evaluación del Clasificador}
\label{subsec:metricas_evaluacion_clasificador}

La evaluación del rendimiento del clasificador utiliza múltiples métricas complementarias, con la \textbf{exactitud (accuracy)} como indicador principal del rendimiento global.

\subsubsection{Exactitud como Métrica Principal}

La exactitud se adopta como métrica principal de evaluación por las siguientes razones:

\begin{enumerate}
    \item \textbf{Compensación del desbalance:} Aunque el conjunto de datos presenta desbalance entre categorías, este se corrige durante el entrenamiento mediante pesos por clase (Tabla \ref{tab:class_weights}). Esta compensación permite que la exactitud refleje el rendimiento real del modelo sin sesgo hacia la clase mayoritaria.

    \item \textbf{Objetivo de correctitud general:} El propósito del sistema es clasificar correctamente la mayor cantidad de radiografías posible, independientemente de la categoría. La exactitud cuantifica directamente este objetivo.

    \item \textbf{Interpretabilidad clínica:} En el contexto médico, la exactitud tiene una interpretación directa: la proporción de diagnósticos correctos sobre el total de casos evaluados.
\end{enumerate}

\subsubsection{Métricas Complementarias}

Adicionalmente, se reportan las siguientes métricas para caracterizar el comportamiento del clasificador:

\begin{itemize}
    \item \textbf{F1-Score Macro:} Promedio no ponderado del F1-Score de cada categoría. Verifica que el rendimiento sea equilibrado entre clases y no esté dominado por la categoría mayoritaria.

    \item \textbf{Precisión y Sensibilidad por categoría:} Permiten identificar patrones específicos de error (falsos positivos vs. falsos negativos) para cada diagnóstico.

    \item \textbf{Matriz de confusión:} Visualiza la distribución completa de predicciones, facilitando el análisis de errores clínicamente relevantes (e.g., confusión entre patologías que requieren tratamientos diferentes).
\end{itemize}

\subsection{Aumento de Datos}
\label{subsec:augmentation_clasificador}

El aumento de datos es una técnica que consiste en crear variaciones artificiales de las imágenes de entrenamiento mediante transformaciones controladas. El objetivo es exponer al modelo a mayor diversidad de ejemplos, mejorando su capacidad de generalizar a imágenes nuevas. Las transformaciones se diseñan cuidadosamente para simular variaciones realistas que podrían ocurrir durante la adquisición de radiografías, sin alterar las características diagnósticas relevantes.

\subsubsection{Transformaciones Durante el Entrenamiento}

Se aplican las siguientes transformaciones a cada imagen:

\begin{enumerate}
    \item \textbf{Conversión a tres canales:} Las radiografías, originalmente en escala de grises, se convierten a formato de tres canales para compatibilidad con la arquitectura preentrenada.

    \item \textbf{Ajuste de tamaño:} Todas las imágenes se escalan a 224 $\times$ 224 píxeles.

    \item \textbf{Reflejo horizontal:} La imagen se refleja horizontalmente, simulando variaciones en la orientación del paciente durante la toma.

    \item \textbf{Rotación leve:} Se aplican rotaciones aleatorias de hasta 10 grados en cualquier dirección, representando pequeñas variaciones en el posicionamiento.

    \item \textbf{Desplazamiento y escala:} Se aplican pequeños desplazamientos (hasta 5\% en cada eje) y variaciones de escala (entre 95\% y 105\%), simulando diferencias en el encuadre de la imagen.
\end{enumerate}

\subsubsection{Transformaciones Durante la Evaluación}

Durante la evaluación del modelo, solo se aplican las transformaciones determinísticas (conversión a tres canales, ajuste de tamaño y normalización), sin variaciones aleatorias. Esto asegura que los resultados de evaluación sean reproducibles y comparables.

La Figura \ref{fig:augmentation_clasificador} ilustra ejemplos de las transformaciones aplicadas durante el entrenamiento.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/F4.12_aumento_datos.png}
    \caption{Ejemplos de transformaciones de aumento de datos aplicadas durante el entrenamiento del clasificador. Las transformaciones preservan la integridad diagnóstica de las imágenes mientras aumentan la variabilidad del conjunto de entrenamiento.}
    \label{fig:augmentation_clasificador}
\end{figure}

\subsection{Resumen de la Configuración}
\label{subsec:resumen_clasificador}

La Tabla \ref{tab:resumen_clasificador} consolida los aspectos principales del módulo de clasificación descritos en esta sección.

\begin{table}[htbp]
    \centering
    \caption{Resumen de la configuración del clasificador de enfermedades pulmonares.}
    \label{tab:resumen_clasificador}
    \begin{tabular}{llc}
        \toprule
        \textbf{Aspecto} & \textbf{Elemento} & \textbf{Valor/Descripción} \\
        \midrule
        Preprocesamiento
            & Mejora de contraste & SAHS (asimétrico) \\
        \midrule
        \multirow{4}{*}{Arquitectura}
            & Red base & ResNet-18 \\
            & Conocimiento previo & ImageNet \\
            & Categorías de salida & 3 \\
            & Parámetros ajustables & $\sim$11.2 millones \\
        \midrule
        \multirow{2}{*}{Prevención de sobreajuste}
            & Dropout & 30\% de neuronas \\
            & Aumento de datos & Reflejo, rotación, escala \\
        \midrule
        \multirow{4}{*}{Entrenamiento}
            & Épocas máximas & 50 \\
            & Imágenes por lote & 32 \\
            & Compensación de desbalance & Pesos por categoría \\
            & Optimizador & Adam \\
        \midrule
        \multirow{2}{*}{Parada temprana}
            & Paciencia & 10 épocas \\
            & Métrica monitoreada & F1-Score Macro \\
        \bottomrule
    \end{tabular}
\end{table}
