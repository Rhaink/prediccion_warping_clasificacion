% =============================================================================
% CAPÍTULO 4: METODOLOGÍA
% Sección 4.5: Clasificación de Enfermedades Pulmonares
% =============================================================================

\section{Clasificación de Enfermedades Pulmonares}
\label{sec:clasificacion}

Una vez que las imágenes han sido normalizadas geométricamente mediante el proceso de warping descrito en la sección anterior, el siguiente paso del sistema es la clasificación automática en una de tres categorías diagnósticas: COVID-19, Normal o Neumonía Viral. Esta sección describe las arquitecturas de clasificación evaluadas, la estrategia de aprendizaje por transferencia empleada y la configuración del entrenamiento.

\subsection{Arquitecturas CNN Evaluadas}
\label{subsec:arquitecturas_evaluadas}

Para la tarea de clasificación se evaluaron siete arquitecturas de redes neuronales convolucionales ampliamente utilizadas en visión por computadora. Todas las arquitecturas se inicializaron con pesos preentrenados en ImageNet \cite{deng2009imagenet}, aprovechando el conocimiento transferible de características visuales genéricas.

La Tabla \ref{tab:arquitecturas_evaluadas} presenta las arquitecturas evaluadas junto con sus características principales.

\begin{table}[htbp]
    \centering
    \caption{Arquitecturas CNN evaluadas para clasificación. Todas utilizan pesos preentrenados de ImageNet y se adaptan para clasificación de 3 clases.}
    \label{tab:arquitecturas_evaluadas}
    \begin{tabular}{llcc}
        \toprule
        \textbf{Arquitectura} & \textbf{Referencia} & \textbf{Parámetros} & \textbf{Año} \\
        \midrule
        AlexNet & Krizhevsky et al. \cite{krizhevsky2012imagenet} & 57.0M & 2012 \\
        VGG-16 & Simonyan \& Zisserman \cite{simonyan2014very} & 134.3M & 2014 \\
        ResNet-18 & He et al. \cite{he2016deep} & 11.2M & 2016 \\
        ResNet-50 & He et al. \cite{he2016deep} & 23.5M & 2016 \\
        DenseNet-121 & Huang et al. \cite{huang2017densely} & 7.0M & 2017 \\
        MobileNetV2 & Sandler et al. \cite{sandler2018mobilenetv2} & 2.2M & 2018 \\
        EfficientNet-B0 & Tan \& Le \cite{tan2019efficientnet} & 4.0M & 2019 \\
        \bottomrule
    \end{tabular}
\end{table}

La selección de arquitecturas abarca diferentes paradigmas de diseño de CNNs:

\begin{itemize}
    \item \textbf{Arquitecturas clásicas} (AlexNet, VGG-16): Establecieron las bases del aprendizaje profundo en visión, aunque con alto costo computacional.

    \item \textbf{Redes residuales} (ResNet-18, ResNet-50): Introducen conexiones de salto que permiten entrenar redes más profundas mitigando el problema de desvanecimiento de gradiente \cite{he2016deep}.

    \item \textbf{Conexiones densas} (DenseNet-121): Cada capa recibe entradas de todas las capas anteriores, promoviendo la reutilización de características \cite{huang2017densely}.

    \item \textbf{Arquitecturas eficientes} (MobileNetV2, EfficientNet-B0): Diseñadas para maximizar la precisión con restricciones de recursos computacionales.
\end{itemize}

\subsubsection{Enfoque en ResNet-18 y EfficientNet-B0}

De las siete arquitecturas evaluadas, ResNet-18 y EfficientNet-B0 emergieron como las opciones más adecuadas para este proyecto, considerando el balance entre rendimiento y eficiencia.

\textbf{ResNet-18} ofrece varias ventajas:
\begin{enumerate}
    \item \textbf{Consistencia con el sistema:} Utiliza la misma familia de arquitectura que el modelo de predicción de landmarks, facilitando la integración.
    \item \textbf{Eficiencia computacional:} Con 11.2M parámetros, permite iteraciones rápidas durante la experimentación.
    \item \textbf{Robustez demostrada:} Ha mostrado buen rendimiento en múltiples tareas de clasificación de imágenes médicas \cite{rajpurkar2017chexnet}.
\end{enumerate}

\textbf{EfficientNet-B0} representa una alternativa moderna:
\begin{enumerate}
    \item \textbf{Escalado compuesto:} Balancea uniformemente profundidad, ancho y resolución de la red \cite{tan2019efficientnet}.
    \item \textbf{Alta eficiencia:} Alcanza rendimiento competitivo con solo 4.0M parámetros.
    \item \textbf{Estado del arte:} Demostró resultados superiores en ImageNet con menor costo computacional.
\end{enumerate}

La Tabla \ref{tab:comparacion_resnet_efficientnet} presenta la comparación de rendimiento entre ambas arquitecturas en el conjunto de datos normalizado.

\begin{table}[htbp]
    \centering
    \caption{Arquitectura y rendimiento del clasificador ResNet-18 en el conjunto de datos normalizado geométricamente.}
    \label{tab:comparacion_resnet_efficientnet}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Arquitectura} & \textbf{Accuracy} & \textbf{F1-Macro} & \textbf{F1-Weighted} & \textbf{Parámetros} \\
        \midrule
        ResNet-18 & 98.05\% & 97.12\% & 98.04\% & 11.2M \\
        \bottomrule
    \end{tabular}
\end{table}

Se seleccionó ResNet-18 como la arquitectura del clasificador debido a su balance entre capacidad de representación y eficiencia computacional. Con 11.2 millones de parámetros preentrenados en ImageNet, la arquitectura alcanza 98.05\% de \textit{accuracy} en el conjunto de prueba, con F1-Macro de 97.12\% y F1-Weighted de 98.04\%.

\subsection{Estrategia de Aprendizaje por Transferencia}
\label{subsec:transfer_learning_clasificacion}

El entrenamiento del clasificador emplea aprendizaje por transferencia desde ImageNet, una estrategia que ha demostrado ser efectiva para tareas de clasificación de imágenes médicas donde los conjuntos de datos disponibles son típicamente pequeños \cite{raghu2019transfusion}.

\subsubsection{Adaptación de la Arquitectura}

Para adaptar las arquitecturas preentrenadas a la tarea de clasificación de tres clases, se modifica únicamente la capa de clasificación final:

\begin{enumerate}
    \item \textbf{Carga de pesos:} Se cargan los pesos preentrenados en ImageNet para todas las capas convolucionales y de pooling.

    \item \textbf{Reemplazo del clasificador:} La capa fully connected original (diseñada para 1000 clases de ImageNet) se reemplaza por una nueva capa con la estructura:
    \begin{equation}
        \text{Clasificador} = \text{Dropout}(p=0.3) \rightarrow \text{Linear}(d_{\text{in}}, 3)
    \end{equation}
    donde $d_{\text{in}}$ es la dimensión de las características del backbone (512 para ResNet-18, 1280 para EfficientNet-B0).

    \item \textbf{Inicialización:} Los pesos de la nueva capa se inicializan aleatoriamente mientras que el resto de la red mantiene los pesos de ImageNet.
\end{enumerate}

\subsubsection{Ajuste fino de la Red Completa}

A diferencia del modelo de landmarks que utiliza un esquema de dos fases (backbone congelado seguido de ajuste fino), el clasificador se entrena con ajuste fino completo desde el inicio. Esta decisión se justifica por:

\begin{itemize}
    \item \textbf{Conjunto de datos más grande:} El conjunto de imágenes normalizadas (15,153 imágenes) es significativamente mayor que el conjunto de datos de landmarks (957 imágenes).
    \item \textbf{Tarea más estándar:} La clasificación de imágenes es más similar a las tareas de ImageNet que la regresión de coordenadas.
    \item \textbf{Regularización implícita:} El preprocesamiento CLAHE y la normalización geométrica reducen la variabilidad, actuando como regularización implícita.
\end{itemize}

\subsection{Configuración del Entrenamiento}
\label{subsec:config_entrenamiento_clasificador}

El entrenamiento del clasificador sigue un protocolo estándar de clasificación de imágenes con adaptaciones específicas para el desbalance de clases presente en el conjunto de datos.

\subsubsection{Distribución del Conjunto de Datos}

El conjunto de datos de imágenes normalizadas se divide en tres subconjuntos siguiendo la estrategia de partición estratificada descrita en la Sección \ref{sec:dataset_preprocesamiento}. La Tabla \ref{tab:distribucion_clasificador} muestra la distribución de clases.

\begin{table}[htbp]
    \centering
    \caption{Distribución del conjunto de datos para entrenamiento del clasificador.}
    \label{tab:distribucion_clasificador}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Clase} & \textbf{Train} & \textbf{Val} & \textbf{Test} & \textbf{Total (\%)} \\
        \midrule
        COVID-19 & 2,712 & 542 & 362 & 3,616 (24\%) \\
        Normal & 7,644 & 1,529 & 1,020 & 10,193 (67\%) \\
        Neumonía Viral & 1,008 & 200 & 136 & 1,344 (9\%) \\
        \midrule
        \textbf{Total} & 11,364 & 2,271 & 1,518 & \textbf{15,153} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Manejo del Desbalance de Clases}

El conjunto de datos presenta un desbalance significativo, con la clase Normal representando el 67\% de las muestras mientras que Neumonía Viral solo representa el 9\%. Para mitigar el sesgo hacia las clases mayoritarias, se utilizan pesos de clase inversamente proporcionales a su frecuencia:

\begin{equation}
    w_c = \frac{N}{K \cdot n_c}
    \label{eq:class_weights}
\end{equation}

\noindent donde $N$ es el número total de muestras, $K$ es el número de clases (3), y $n_c$ es el número de muestras de la clase $c$.

Aplicando la Ecuación \ref{eq:class_weights} al conjunto de entrenamiento:

\begin{table}[htbp]
    \centering
    \caption{Pesos de clase calculados para balanceo del entrenamiento.}
    \label{tab:class_weights}
    \begin{tabular}{lcc}
        \toprule
        \textbf{Clase} & \textbf{Muestras (Train)} & \textbf{Peso} \\
        \midrule
        COVID-19 & 2,712 & 1.40 \\
        Normal & 7,644 & 0.50 \\
        Neumonía Viral & 1,008 & 3.76 \\
        \bottomrule
    \end{tabular}
\end{table}

Estos pesos se incorporan en la función de pérdida Cross-Entropy:

\begin{equation}
    \mathcal{L}_{\text{CE}} = -\sum_{c=1}^{K} w_c \cdot y_c \cdot \log(\hat{y}_c)
\end{equation}

\noindent donde $y_c$ es la etiqueta verdadera (one-hot) y $\hat{y}_c$ es la probabilidad predicha para la clase $c$.

\subsubsection{Hiperparámetros de Entrenamiento}

La Tabla \ref{tab:hiperparametros_clasificador} resume la configuración de hiperparámetros utilizada.

\begin{table}[htbp]
    \centering
    \caption{Hiperparámetros del entrenamiento del clasificador.}
    \label{tab:hiperparametros_clasificador}
    \begin{tabular}{ll}
        \toprule
        \textbf{Parámetro} & \textbf{Valor} \\
        \midrule
        Épocas máximas & 50 \\
        Tamaño de lote & 32 \\
        Tasa de aprendizaje inicial & $1 \times 10^{-4}$ \\
        Optimizador & Adam ($\beta_1=0.9$, $\beta_2=0.999$) \\
        Función de pérdida & Cross-Entropy con pesos de clase \\
        Dropout & 0.3 \\
        Parada temprana & Paciencia = 10 épocas \\
        Métrica de monitoreo & F1-Score Macro (validación) \\
        Semilla aleatoria & 42 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Parada Temprana}

Para prevenir el sobreajuste y determinar el momento óptimo de detención del entrenamiento, se implementa parada temprana basado en el F1-Score Macro del conjunto de validación:

\begin{enumerate}
    \item Se monitorea el F1-Score Macro después de cada época.
    \item Si no hay mejora durante 10 épocas consecutivas, el entrenamiento se detiene.
    \item Se guarda el modelo con el mejor F1-Score de validación.
\end{enumerate}

La selección de F1-Score Macro sobre accuracy como métrica de monitoreo se justifica por el desbalance de clases: F1-Macro pondera equitativamente el rendimiento en cada clase, evitando que el modelo optimice solo para la clase mayoritaria.

\subsection{Aumento de Datos}
\label{subsec:augmentation_clasificador}

Durante el entrenamiento se aplican transformaciones de aumento de datos para mejorar la generalización del modelo. Las transformaciones se diseñaron para ser compatibles con las características de las radiografías normalizadas.

\subsubsection{Transformaciones de Entrenamiento}

\begin{enumerate}
    \item \textbf{Conversión a RGB:} Las imágenes en escala de grises se convierten a tres canales replicando el canal de luminancia, requisito de las arquitecturas preentrenadas en ImageNet.

    \item \textbf{Redimensionamiento:} Las imágenes se escalan a $224 \times 224$ píxeles.

    \item \textbf{Flip horizontal} (probabilidad 0.5): Refleja la imagen horizontalmente, simulando variaciones de orientación del paciente.

    \item \textbf{Rotación aleatoria} ($\pm$10 grados): Introduce pequeñas variaciones rotacionales que pueden ocurrir durante la adquisición.

    \item \textbf{Transformación afín aleatoria:}
    \begin{itemize}
        \item Traslación: $\pm$5\% en ambos ejes
        \item Escala: 95\%--105\%
    \end{itemize}

    \item \textbf{Normalización ImageNet:} Se aplican media y desviación estándar de ImageNet:
    \begin{align}
        \mu &= [0.485, 0.456, 0.406] \\
        \sigma &= [0.229, 0.224, 0.225]
    \end{align}
\end{enumerate}

\subsubsection{Transformaciones de Evaluación}

Durante la evaluación y prueba, solo se aplican las transformaciones determinísticas:

\begin{enumerate}
    \item Conversión a RGB
    \item Redimensionamiento a $224 \times 224$
    \item Normalización ImageNet
\end{enumerate}

La Figura \ref{fig:augmentation_clasificador} ilustra ejemplos de las transformaciones aplicadas.

\begin{figure}[htbp]
    \centering
    % [PENDIENTE: Insertar figura de ejemplos de augmentation]
    \fbox{\parbox{0.9\textwidth}{\centering\vspace{3cm}
    [Ejemplos de aumento de datos aplicado al clasificador]\\
    Original $\rightarrow$ Flip $\rightarrow$ Rotación $\rightarrow$ Traslación + Escala
    \vspace{3cm}}}
    \caption{Ejemplos de transformaciones de aumento de datos aplicadas durante el entrenamiento del clasificador. Las transformaciones preservan la integridad diagnóstica de las imágenes mientras aumentan la variabilidad del conjunto de entrenamiento.}
    \label{fig:augmentation_clasificador}
\end{figure}

\subsection{Resumen de la Configuración del Clasificador}
\label{subsec:resumen_clasificador}

La Tabla \ref{tab:resumen_clasificador} consolida la configuración completa del módulo de clasificación.

\begin{table}[htbp]
    \centering
    \caption{Resumen de la configuración del clasificador de enfermedades pulmonares.}
    \label{tab:resumen_clasificador}
    \begin{tabular}{llc}
        \toprule
        \textbf{Categoría} & \textbf{Parámetro} & \textbf{Valor} \\
        \midrule
        \multirow{4}{*}{Arquitectura}
            & Backbone & ResNet-18 \\
            & Preentrenamiento & ImageNet \\
            & Clases de salida & 3 \\
            & Parámetros totales & $\sim$11.2M \\
        \midrule
        \multirow{2}{*}{Regularización}
            & Dropout & 0.3 \\
            & Aumento de datos & Flip, rotación, afín \\
        \midrule
        \multirow{5}{*}{Entrenamiento}
            & Épocas & 50 (con parada temprana) \\
            & Tamaño de lote & 32 \\
            & Tasa de aprendizaje & $1 \times 10^{-4}$ \\
            & Optimizador & Adam \\
            & Pesos de clase & Habilitados \\
        \midrule
        \multirow{2}{*}{Parada Temprana}
            & Paciencia & 10 épocas \\
            & Métrica & F1-Score Macro \\
        \bottomrule
    \end{tabular}
\end{table}

% Referencias temporales para esta sección
% \cite{deng2009imagenet} - Deng et al., ImageNet (CVPR 2009)
% \cite{krizhevsky2012imagenet} - Krizhevsky et al., AlexNet (NIPS 2012)
% \cite{simonyan2014very} - Simonyan & Zisserman, VGG (ICLR 2015)
% \cite{he2016deep} - He et al., ResNet (CVPR 2016)
% \cite{huang2017densely} - Huang et al., DenseNet (CVPR 2017)
% \cite{sandler2018mobilenetv2} - Sandler et al., MobileNetV2 (CVPR 2018)
% \cite{tan2019efficientnet} - Tan & Le, EfficientNet (ICML 2019)
% \cite{rajpurkar2017chexnet} - Rajpurkar et al., CheXNet (arXiv 2017)
% \cite{raghu2019transfusion} - Raghu et al., Transfusion (NeurIPS 2019)
