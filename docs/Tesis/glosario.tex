% =============================================================================
% GLOSARIO ACADÉMICO
% Tesis de Maestría en Ingeniería Electrónica
% Normalización geométrica y detección de COVID-19 mediante landmarks anatómicos
% =============================================================================

\chapter*{Glosario}
\addcontentsline{toc}{chapter}{Glosario}

Este glosario presenta las definiciones de los términos técnicos, conceptos científicos y acrónimos utilizados en la presente tesis. Los términos se organizan alfabéticamente, y los acrónimos se presentan en una sección separada al final del documento.

% =============================================================================
\section*{A}
% =============================================================================

\textbf{Active Shape Models (ASM)}
\\
Método estadístico tradicional de detección de landmarks que aprende patrones de variabilidad de forma a partir de anotaciones manuales, empleando un proceso iterativo de refinamiento análogo a Active Contour Models (Snakes) para ajustar una forma modelo a imágenes. Requieren inicialización cercana a la solución y son sensibles a variaciones significativas de apariencia.

\textbf{Adaptive Wing Loss}
\\
Extensión de Wing Loss para heatmap regression que introduce ponderación adaptativa según el tipo de píxel (foreground vs background), combinando la función Wing con un Weighted Loss Map que asigna mayor peso a píxeles críticos, permitiendo que el entrenamiento se enfoque en regiones relevantes para localización de landmarks. Superó el estado del arte en benchmarks de face alignment (COFW, 300W, WFLW).

\textbf{Alineación geométrica}
\\
Proceso de transformación de imágenes para que estructuras anatómicas correspondientes ocupen posiciones consistentes en el espacio de coordenadas, eliminando variaciones de posición, escala y orientación.

\textbf{AlexNet}
\\
Arquitectura pionera de red neuronal convolucional profunda (8 capas, 5 convolucionales + 3 fully connected) que ganó la competencia ImageNet 2012, marcando el inicio de la era moderna del aprendizaje profundo en visión por computadora. Introdujo el uso de ReLU, dropout y procesamiento en GPU para entrenar redes profundas.

\textbf{Aprendizaje por transferencia} (\textit{Transfer Learning})
\\
Técnica de aprendizaje profundo que reutiliza una red neuronal entrenada en una tarea para resolver otra tarea relacionada, aprovechando el conocimiento previo contenido en los pesos preentrenados. En este trabajo se utiliza ResNet-18 preentrenada en ImageNet como extractor de características para radiografías de tórax.

\textbf{Aumento de datos} (\textit{Data Augmentation})
\\
Técnica que crea variaciones artificiales de las imágenes de entrenamiento mediante transformaciones controladas (reflejo horizontal, rotación, desplazamiento) para aumentar la diversidad del conjunto de datos y mejorar la generalización del modelo.

\textbf{Attention Gates}
\\
Módulo de atención espacial que aprende máscaras de importancia para ponderar selectivamente diferentes regiones de un mapa de características, permitiendo que la red enfoque recursos computacionales en áreas anatómicamente relevantes. Utilizado en STERN para normalización jerárquica de radiografías.

\textbf{Attention Maps}
\\
Visualizaciones que muestran dónde se enfoca la atención de la red durante predicciones, obtenidas directamente de mecanismos de atención (self-attention, coordinate attention, CBAM), útiles para interpretabilidad de decisiones del modelo y validación de que la red se enfoca en regiones anatómicamente relevantes.

\textbf{AUC} (\textit{Area Under the Curve} / Área Bajo la Curva)
\\
Métrica que calcula el área bajo la curva ROC (Receiver Operating Characteristic), proporcionando una evaluación de rendimiento de clasificación binaria independiente del threshold de decisión. Valores cercanos a 1.0 indican excelente discriminación entre clases positivas y negativas.

% =============================================================================
\section*{B}
% =============================================================================

\textbf{BIMCV-COVID19}
\\
Conjunto de datos español de COVID-19 en radiografías de tórax con metadata clínica detallada (información demográfica, marcadores de severidad, evolución temporal), desarrollado por el Biosignal Interpretation and Medical Computing Laboratory de Valencia. Facilita investigación clínica mediante información complementaria más allá de imágenes.

\textbf{B-splines} (\textit{Basis Splines})
\\
Curvas suaves paramétricas definidas por puntos de control, utilizadas para representar deformaciones no paramétricas complejas en transformaciones de imágenes médicas. Ofrecen extrema flexibilidad para modelar deformaciones locales pero pueden requerir regularización para evitar sobreajuste.

% =============================================================================
\section*{C}
% =============================================================================

\textbf{Cabeza de regresión} (\textit{Regression Head})
\\
Componente final de una red neuronal que transforma las características extraídas en predicciones numéricas. En este trabajo, la cabeza de regresión convierte el mapa de características de ResNet-18 (7×7×512) en 30 coordenadas normalizadas que representan los 15 puntos de referencia anatómicos.

\textbf{Características espurias} (\textit{Shortcut Learning})
\\
Patrones no relacionados con la patología (etiquetas hospitalarias, marcadores de lateralidad, artefactos de los bordes) que un modelo de clasificación aprende a explotar como atajos, en lugar de aprender características diagnósticas genuinas. Este trabajo demuestra que imágenes originales sin procesar presentan este problema.

\textbf{CBAM} (\textit{Convolutional Block Attention Module})
\\
Módulo de atención que combina channel attention y spatial attention de forma secuencial, permitiendo que la red aprenda qué características son importantes (channel attention mediante global pooling) y dónde enfocar (spatial attention mediante agregación de canales). Demostró mejoras consistentes en ImageNet-1K, MS COCO y VOC 2007.

\textbf{Centroide}
\\
Punto geométrico que representa el centro de masa de una configuración de puntos, calculado como el promedio de todas las coordenadas. Utilizado en GPA para el paso de centrado que elimina diferencias de traslación entre formas.

\textbf{CLAHE} (\textit{Contrast Limited Adaptive Histogram Equalization})
\\
Algoritmo de mejora de contraste que opera de forma local sobre regiones rectangulares (\textit{tiles}), aplicando ecualización de histograma con un límite de amplificación para evitar realce excesivo de ruido. Utilizado en el preprocesamiento de radiografías antes de la predicción de landmarks.
\\
\textit{Parámetros}: clip limit = 2.0, tile size = 4×4 píxeles.

\textbf{ChestX-ray14}
\\
Conjunto de datos público de 112,120 radiografías de tórax frontales con anotaciones de 14 patologías torácicas diferentes, proporcionado por NIH Clinical Center. Ampliamente utilizado para preentrenamiento y evaluación de modelos de clasificación de enfermedades pulmonares en imágenes médicas.

\textbf{CheXNet}
\\
Modelo de clasificación de patologías pulmonares basado en DenseNet-121 preentrenado en ImageNet, que excede el desempeño promedio de radiólogos en detección de neumonía en radiografías de tórax según evaluación en ChestX-ray14. Estableció una línea base importante para clasificación de patologías pulmonares mediante transfer learning.

\textbf{Conjunto de entrenamiento} (\textit{Training Set})
\\
Subconjunto del dataset (75\% en este trabajo) utilizado para optimizar los parámetros del modelo mediante descenso de gradiente.

\textbf{Conjunto de prueba} (\textit{Test Set})
\\
Subconjunto del dataset (10\% en este trabajo) reservado exclusivamente para la evaluación final del sistema, sin participación en decisiones de entrenamiento o selección de hiperparámetros.

\textbf{Conjunto de validación} (\textit{Validation Set})
\\
Subconjunto del dataset (15\% en este trabajo) utilizado para monitorear el rendimiento durante el entrenamiento y aplicar criterios de parada temprana, sin participar en la optimización de pesos.

\textbf{Conexiones residuales} (\textit{Skip Connections})
\\
Arquitectura propuesta en ResNet que permite que la información fluya directamente entre capas no consecutivas mediante la suma $y = F(x) + x$, donde $x$ es la entrada y $F(x)$ la transformación aprendida. Facilita el entrenamiento de redes profundas al mitigar el desvanecimiento de gradiente.

\textbf{Contorno pulmonar}
\\
Borde que delimita la silueta de la región pulmonar en una radiografía de tórax. En este trabajo se representa mediante 15 puntos de referencia anatómicos distribuidos sobre el contorno.

\textbf{Convolución}
\\
Operación matemática fundamental en redes neuronales convolucionales que aplica un kernel sobre la imagen de entrada mediante producto punto deslizante, extrayendo características locales como bordes, texturas y patrones. Preserva las relaciones espaciales entre píxeles vecinos.

\textbf{Coordinate Regression}
\\
Enfoque de detección de landmarks que predice directamente las coordenadas $(x,y)$ de cada punto de referencia como salida numérica continua de la red, sin representación espacial intermedia. Conceptualmente simple y eficiente computacionalmente, pero enfrenta desafíos de convergencia debido a la naturaleza no lineal del mapeo imagen-coordenadas. Utilizado en este trabajo para detección de 15 landmarks pulmonares.

\textbf{Coordinate Attention}
\\
Mecanismo de atención diseñado para tareas de localización que preserva información espacial procesando de forma separada las dimensiones horizontal y vertical, generando mapas de atención direccionales. Integrado en el modelo de puntos de referencia para preservar información posicional.

\textbf{COVID-19}
\\
Enfermedad infecciosa causada por el virus SARS-CoV-2, caracterizada en radiografías de tórax por opacidades en vidrio esmerilado, consolidaciones y patrones bilaterales. Una de las tres clases diagnósticas clasificadas en este trabajo.

\textbf{COVID-19 Radiography Database}
\\
Conjunto de datos público de 15,153 radiografías posteroanterior de tórax organizadas en tres categorías (COVID-19: 3,616; Normal: 10,192; Neumonía Viral: 1,345), desarrollado por Qatar University y colaboradores.

\textbf{COVID-Net}
\\
Arquitectura CNN diseñada específicamente para detección de COVID-19 mediante principios de diseño humano-en-el-loop, incorporando módulos de expansión-compresión que permiten aprendizaje eficiente de representaciones discriminativas. Alcanzó 93.3\% de exactitud en clasificación de tres clases (COVID-19, neumonía viral, normal) en el conjunto de datos COVIDx.

\textbf{COVIDx}
\\
Conjunto de datos público de radiografías de tórax específicamente compilado para detección de COVID-19, conteniendo 13,975 imágenes de 13,870 pacientes únicos, recopiladas de múltiples fuentes públicas incluyendo repositorios de investigación y datos hospitalarios. Utilizado para entrenamiento de COVID-Net.

\textbf{Cosine Annealing}
\\
Esquema de ajuste de tasa de aprendizaje que varía el valor siguiendo una función cosenoidal, disminuyendo gradualmente desde un valor máximo hasta un mínimo, permitiendo exploración amplia inicial y refinamiento fino posterior. Utilizado para optimizar la convergencia del entrenamiento.

\textbf{CSV} (\textit{Comma-Separated Values} / Valores Separados por Comas)
\\
Formato de archivo de texto plano que almacena datos tabulares donde cada línea representa una fila y los valores de las columnas están separados por comas. Utilizado en este trabajo para almacenar las anotaciones manuales de coordenadas de puntos de referencia anatómicos (archivo \texttt{coordenadas\_maestro.csv} con 957 radiografías anotadas).

% =============================================================================
\section*{D}
% =============================================================================

\textbf{Desbalance de clases}
\\
Fenómeno donde las categorías de un conjunto de datos tienen diferente número de muestras. En este trabajo, la categoría Normal (67\%) predomina sobre COVID-19 (24\%) y Neumonía Viral (9\%), requiriendo compensación mediante pesos por clase durante el entrenamiento.

\textbf{Deformación afín por partes} (\textit{Piecewise Affine Transformation / Warping})
\\
Técnica de transformación geométrica que divide la imagen en regiones (triángulos) y aplica transformaciones afines independientes a cada región, permitiendo deformación local que se adapta a variaciones anatómicas inter-paciente preservando la estructura triangular.

\textbf{DenseNet}
\\
Arquitectura CNN que conecta cada capa con todas las capas anteriores mediante conexiones densas (cada capa recibe como entrada la concatenación de salidas de todas las capas previas), mejorando la propagación de gradientes, la reutilización de características y reduciendo el número de parámetros. DenseNet-121 es utilizado en CheXNet para clasificación de patologías pulmonares.

\textbf{Desvanecimiento de gradiente}
\\
Problema en redes neuronales profundas donde los gradientes se vuelven extremadamente pequeños durante la propagación hacia atrás, dificultando el entrenamiento de capas iniciales. Resuelto en ResNet mediante conexiones residuales.

\textbf{Dropout}
\\
Técnica de regularización que desactiva aleatoriamente un porcentaje de neuronas durante el entrenamiento, obligando al modelo a no depender excesivamente de características específicas y mejorando la generalización. Utilizado con probabilidades de 0.3 y 0.15 en la cabeza de regresión.

\textbf{Domain Adaptation} (Adaptación de dominio)
\\
Conjunto de técnicas que adaptan un modelo entrenado en dominio fuente a dominio objetivo, con acceso limitado o sin acceso a labels en el dominio objetivo, mediante fine-tuning, adversarial training o feature alignment. Crítico en imágenes médicas para mitigar desplazamiento de dominio entre hospitales con diferentes equipos y protocolos.

\textbf{Domain Generalization} (Generalización de dominio)
\\
Enfoque que entrena modelos para aprender representaciones robustas invariantes a cambios de dominio, sin acceso a datos del dominio objetivo durante entrenamiento, mediante aumento agresivo, meta-learning o aprendizaje de características causales en lugar de correlacionales. Complementario a normalización geométrica para robustez ante variabilidad institucional.

% =============================================================================
\section*{E}
% =============================================================================

\textbf{Ecualización de histograma}
\\
Transformación de intensidades que redistribuye los valores de píxeles para utilizar todo el rango dinámico disponible, mejorando el contraste global de la imagen.

\textbf{EfficientNet}
\\
Familia de arquitecturas CNN que optimiza el escalamiento equilibrado de profundidad, ancho y resolución de entrada mediante Neural Architecture Search (NAS), logrando mejor compromiso entre exactitud y eficiencia computacional que arquitecturas diseñadas manualmente. Introduce el concepto de compound scaling para escalamiento óptimo de redes.

\textbf{Eje central}
\\
Línea vertical que conecta los puntos de referencia L1 (superior) → L9 → L10 → L11 → L2 (inferior), representando la línea media del tórax a lo largo de la columna vertebral, utilizada como referencia para la estructura de landmarks.

\textbf{Embeddings} (Incrustaciones)
\\
Representaciones vectoriales de dimensión fija que codifican información semántica de entradas (palabras, parches de imagen, características), aprendidas durante entrenamiento para ser significativas para la tarea. En Vision Transformers, cada parche de imagen se proyecta a un embedding antes de procesamiento mediante self-attention.

\textbf{Escala de grises} (\textit{Grayscale})
\\
Representación de imágenes digitales donde cada píxel codifica únicamente intensidad luminosa (1 canal), sin información de color, con valores típicamente en el rango 0-255. Las radiografías de tórax son naturalmente imágenes en escala de grises que se replican a 3 canales para compatibilidad con redes preentrenadas.

\textbf{Ensamble} (\textit{Ensemble})
\\
Combinación de predicciones de múltiples modelos entrenados de forma independiente (con diferentes semillas aleatorias) mediante promedio, reduciendo la varianza y mejorando la precisión. Este trabajo utiliza ensamble de 4 modelos ResNet-18.

\textbf{Entropía cruzada} (\textit{Cross-Entropy})
\\
Función de pérdida para clasificación multiclase que mide la divergencia entre la distribución de probabilidades predicha y la real, penalizando predicciones que asignan baja probabilidad a la clase correcta. Utilizada con pesos por clase para compensar desbalance.

\textbf{Épocas}
\\
Número de pasadas completas por el conjunto de entrenamiento durante el proceso de optimización. Este trabajo utiliza hasta 50 épocas para el clasificador y 100 para el modelo de landmarks (fase 2), con parada temprana.

\textbf{Error en píxeles}
\\
Métrica para evaluar la precisión de predicción de puntos de referencia, definida como la distancia euclidiana entre las coordenadas predichas y las anotadas manualmente: $\text{Error} = \sqrt{(x_{\text{pred}} - x_{\text{real}})^2 + (y_{\text{pred}} - y_{\text{real}})^2}$.

\textbf{Escalado}
\\
Transformación geométrica que modifica el tamaño de una configuración de puntos. En GPA, se normaliza cada forma para que tenga norma unitaria, eliminando diferencias de escala.

\textbf{Estratificación}
\\
Técnica de división de dataset que mantiene las proporciones de clases en cada subconjunto (entrenamiento, validación, prueba), crítica cuando existe desbalance para asegurar representación adecuada de todas las categorías.

\textbf{Exactitud} (\textit{Accuracy})
\\
Métrica principal de evaluación que mide la proporción de predicciones correctas sobre el total: $\text{Accuracy} = \frac{\text{Predicciones correctas}}{\text{Total}}$. El sistema propuesto alcanza 98.10\% de exactitud.

\textbf{Explainable AI (XAI)} (Inteligencia Artificial Explicable)
\\
Campo de investigación enfocado en desarrollar técnicas que permiten interpretar y explicar decisiones de modelos de aprendizaje profundo, crítico en aplicaciones médicas donde la confianza clínica requiere comprensión de razonamiento del modelo. Incluye técnicas como Grad-CAM, saliency maps, attention visualization y métodos de interpretabilidad post-hoc.

\textbf{Extractor de características} (\textit{Feature Extractor / Backbone})
\\
Componente de una red neuronal (típicamente capas convolucionales) que procesa la imagen de entrada y produce representaciones de alto nivel. En este trabajo se utiliza ResNet-18 preentrenado en ImageNet.

% =============================================================================
\section*{F}
% =============================================================================

\textbf{F1-Score}
\\
Métrica que combina precisión y sensibilidad mediante su media armónica: $\text{F1} = 2 \cdot \frac{\text{Precisión} \cdot \text{Sensibilidad}}{\text{Precisión} + \text{Sensibilidad}}$, proporcionando un balance entre ambos objetivos.

\textbf{F1-Score Macro}
\\
Promedio no ponderado del F1-Score de cada clase, tratando todas las categorías con igual importancia independientemente del número de muestras. Utilizado para evaluar rendimiento equilibrado en presencia de desbalance.

\textbf{F1-Score Ponderado} (\textit{Weighted F1-Score})
\\
Promedio del F1-Score por clase ponderado por el número de muestras de cada categoría, reflejando el desempeño en el contexto del desbalance.

\textbf{Falsos Negativos (FN)}
\\
Casos de una clase positiva que el modelo clasifica incorrectamente como negativos. En detección de COVID-19, un falso negativo es un paciente positivo clasificado como Normal o Neumonía Viral.

\textbf{Falsos Positivos (FP)}
\\
Casos de clases negativas que el modelo clasifica incorrectamente como positivos. En detección de COVID-19, un falso positivo es un paciente Normal o con Neumonía Viral clasificado como COVID-19.

\textbf{Federated Learning} (Aprendizaje Federado)
\\
Paradigma de aprendizaje distribuido donde múltiples dispositivos o instituciones entrenan colaborativamente un modelo compartido sin centralizar datos sensibles, preservando privacidad de pacientes. Relevante en contextos médicos donde compartir datos está regulado por leyes de protección de datos (HIPAA, GDPR).

\textbf{Fill rate} (Tasa de cobertura)
\\
Porcentaje de píxeles no negros en una imagen normalizada geométricamente, indicando qué proporción de la imagen contiene información de la región pulmonar versus fondo. Este trabajo alcanza ~47\% de fill rate.

\textbf{Forma estándar} (Forma canónica)
\\
Configuración promedio de puntos de referencia calculada mediante GPA que representa la forma típica de los pulmones en el conjunto de entrenamiento, utilizada como plantilla de destino para la normalización geométrica.

\textbf{Función de activación}
\\
Transformación no lineal aplicada a las salidas de capas neuronales para introducir capacidad de representación no lineal. Ejemplos: ReLU, Sigmoid, Softmax.

% =============================================================================
\section*{G}
% =============================================================================

\textbf{Global Average Pooling}
\\
Operación de reducción que calcula el promedio de cada canal de características sobre todas las posiciones espaciales, condensando un mapa de características (e.g., 7×7×512) en un vector (512). Utilizado en la cabeza de regresión.

\textbf{GPA} (\textit{Generalized Procrustes Analysis} / Análisis Procrustes Generalizado)
\\
Método estadístico para alinear múltiples configuraciones de puntos eliminando diferencias de traslación, escala y rotación mediante un proceso iterativo que calcula una forma promedio por centrado, normalización y rotación óptima (SVD).
\\
\textit{Parámetros}: tolerancia $\tau = 10^{-8}$, máximo 100 iteraciones.

\textbf{GPU} (\textit{Graphics Processing Unit} / Unidad de Procesamiento Gráfico)
\\
Procesador especializado diseñado originalmente para renderizado gráfico, utilizado en aprendizaje profundo por su capacidad de realizar miles de operaciones matemáticas en paralelo, acelerando significativamente el entrenamiento e inferencia de redes neuronales.

\textbf{Grad-CAM} (\textit{Gradient-weighted Class Activation Mapping})
\\
Técnica de visualización que genera mapas de importancia espacial calculando gradientes de la clase predicha respecto a activaciones de la última capa convolucional, permitiendo interpretar qué regiones de la imagen influyen en decisiones del modelo. Ampliamente utilizada en diagnóstico asistido por IA para validar que modelos se enfocan en regiones patológicas relevantes.

\textbf{Gradiente}
\\
Vector de derivadas parciales de la función de pérdida respecto a los parámetros del modelo, que indica la dirección de mayor incremento. Durante el entrenamiento, se actualiza en dirección opuesta al gradiente (descenso de gradiente).

\textbf{Ground truth}
\\
Anotaciones de referencia creadas manualmente por expertos que sirven como etiquetas verdaderas para entrenamiento y evaluación. En este trabajo, 957 imágenes tienen anotaciones manuales de 15 puntos de referencia.

\textbf{Group Normalization} (Normalización por Grupos)
\\
Técnica de normalización que divide los canales en grupos y normaliza dentro de cada grupo, independiente del tamaño de lote. Utilizada en la cabeza de regresión como alternativa a Batch Normalization para estabilidad con lotes pequeños.

% =============================================================================
\section*{H}
% =============================================================================

\textbf{Heatmap Regression}
\\
Enfoque de detección de landmarks que predice un mapa 2D de probabilidades para cada punto de referencia, típicamente modelado como una distribución Gaussiana centrada en la ubicación verdadera. La ubicación final se obtiene mediante búsqueda del máximo (argmax) o soft-argmax diferenciable. Proporciona generalización espacial superior a coordinate regression pero introduce sobrecarga computacional.

\textbf{Hiperparámetros}
\\
Valores de configuración que definen el comportamiento del modelo y del proceso de entrenamiento, establecidos antes de iniciar el entrenamiento (tasa de aprendizaje, tamaño de lote, número de épocas, etc.), a diferencia de los parámetros que se aprenden automáticamente.

% =============================================================================
\section*{I}
% =============================================================================

\textbf{ImageNet}
\\
Conjunto de datos con más de un millón de imágenes naturales organizadas en 1,000 categorías, utilizado ampliamente para preentrenamiento de redes convolucionales mediante aprendizaje por transferencia.

\textbf{ImageNet-1K}
\\
Versión estándar de ImageNet con 1,000 clases de objetos y aproximadamente 1.2 millones de imágenes de entrenamiento, utilizada como benchmark principal para validación de arquitecturas de visión por computadora. ILSVRC (ImageNet Large Scale Visual Recognition Challenge) impulsa el desarrollo de nuevas arquitecturas mediante competencias anuales.

\textbf{Inductive Biases} (Sesgos inductivos)
\\
Suposiciones incorporadas en la arquitectura de un modelo que facilitan el aprendizaje de ciertos tipos de patrones. CNNs tienen inductive biases de locality (convoluciones procesan regiones locales) y translation equivariance (detección invariante a posición). Vision Transformers carecen de estos biases, requiriendo más datos para convergencia.

\textbf{Inferencia}
\\
Proceso de aplicar un modelo entrenado a nuevos datos para generar predicciones, sin actualizar los parámetros del modelo.

\textbf{Interpolación bilineal}
\\
Método de interpolación que estima el valor de un píxel en una posición no entera promediando los valores de los cuatro píxeles vecinos, ponderados por la distancia. Utilizado durante la deformación afín por partes para obtener transiciones suaves.

\textbf{Internal covariate shift}
\\
Fenómeno donde las distribuciones de las activaciones internas de una red neuronal cambian constantemente durante el entrenamiento a medida que se actualizan los pesos, dificultando la convergencia. Mitigado por Batch Normalization.

% =============================================================================
\section*{J}
% =============================================================================

\textbf{JFT-300M}
\\
Conjunto de datos interno de Google con 300 millones de imágenes etiquetadas de forma semi-supervisada, utilizado para preentrenamiento masivo de Vision Transformers. Demuestra que ViT requiere conjuntos de datos significativamente más grandes que CNNs para alcanzar rendimiento competitivo debido a la ausencia de inductive biases.

% =============================================================================
\section*{K}
% =============================================================================

\textbf{Kernel} (Núcleo convolucional / Filtro)
\\
Matriz de pesos pequeña (típicamente 3×3, 5×5 o 7×7) que se desliza sobre la imagen de entrada durante la operación de convolución, realizando producto punto en cada posición para extraer características específicas. Cada kernel aprende a detectar patrones particulares como bordes, texturas o formas.

% =============================================================================
\section*{L}
% =============================================================================

\textbf{Landmarks} (Puntos de referencia anatómicos)
\\
Puntos de control sobre la silueta pulmonar que representan posiciones geométricas, no estructuras anatómicas específicas. En este trabajo, 15 puntos definen el contorno pulmonar bilateral: eje central (L1, L9, L10, L11, L2 a lo largo de la línea media), contorno izquierdo (L12, L3, L5, L7, L14) y contorno derecho (L13, L4, L6, L8, L15). Estos puntos sirven como base para la normalización geométrica mediante deformación afín por partes.

\textbf{Logits}
\\
Valores numéricos crudos en la capa de salida de una red neuronal antes de aplicar la función de activación softmax. Representan los puntajes no normalizados para cada clase, que posteriormente se convierten en probabilidades mediante softmax.

% =============================================================================
\section*{M}
% =============================================================================

\textbf{Margin scale} (Escala de margen)
\\
Factor de expansión aplicado al centroide de los landmarks para determinar la región de recorte durante la deformación. El valor óptimo validado experimentalmente es 1.05 (5\% de expansión), almacenado en GROUND\_TRUTH.json.

\textbf{Matriz de confusión}
\\
Tabla que presenta la distribución completa de predicciones versus categorías reales, mostrando en la diagonal las clasificaciones correctas y fuera de ella los errores específicos entre pares de clases.

\textbf{MaxPool} (\textit{Max Pooling})
\\
Operación de reducción espacial que selecciona el valor máximo de cada región, utilizada para disminuir dimensionalidad preservando características prominentes y proporcionando invariancia a pequeñas traslaciones.

\textbf{Mecanismo de atención}
\\
Componente de red neuronal que aprende a enfocar selectivamente regiones relevantes de la entrada, ponderando la importancia de diferentes características o posiciones espaciales.

\textbf{MS COCO} (\textit{Microsoft Common Objects in Context})
\\
Conjunto de datos masivo para detección, segmentación y captioning de objetos con múltiples categorías (80 clases) y anotaciones densas (segmentación a nivel de instancia). Ampliamente utilizado para validación de arquitecturas, mecanismos de atención y métodos de detección de objetos en contextos naturales.

\textbf{Multi-head Attention} (Atención multi-cabeza)
\\
Variante de self-attention que ejecuta múltiples operaciones de atención en paralelo con proyecciones lineales diferentes ($h$ cabezas), permitiendo que el modelo capture distintos tipos de dependencias en diferentes subespacios de representación. Las salidas se concatenan y proyectan para obtener resultado final. Componente fundamental de arquitecturas transformer.

% =============================================================================
\section*{N}
% =============================================================================

\textbf{Neumonía}
\\
Inflamación del tejido pulmonar causada por infección, caracterizada en radiografías por opacidades, consolidaciones e infiltrados. Las categorías COVID-19 y Neumonía Viral son dos tipos específicos de neumonía clasificados en este trabajo.

\textbf{Neumonía Viral}
\\
Neumonía causada por virus distintos a SARS-CoV-2, presentando patrones radiográficos similares pero diferenciables de COVID-19. Representa el 9\% del dataset (1,345 imágenes) y la clase minoritaria.

\textbf{NME} (\textit{Normalized Mean Error} / Error Medio Normalizado)
\\
Métrica normalizada de error de localización de landmarks que expresa el error promedio en píxeles como porcentaje de una distancia de normalización característica (distancia entre ojos en facial landmarks, diagonal de imagen en chest X-rays). Permite comparación de rendimiento independiente de resolución de imagen.
\\
\textit{Fórmula}: $\text{NME} = \frac{1}{N} \sum_{i=1}^{N} \frac{\|\mathbf{p}_i - \hat{\mathbf{p}}_i\|_2}{d_{\text{norm}}} \times 100\%$

\textbf{Normal}
\\
Radiografía de paciente sin patología pulmonar aparente, representando la clase mayoritaria (67\%, 10,192 imágenes) en el dataset.

\textbf{Normalización de contraste}
\\
Proceso de ajustar las intensidades de una imagen para mejorar la visibilidad de estructuras relevantes, mitigando variaciones introducidas por diferentes equipos de adquisición y condiciones de exposición.

\textbf{Normalización geométrica}
\\
Proceso de transformación de imágenes a una configuración espacial estándar mediante detección de landmarks y deformación afín por partes, eliminando variabilidad de posición, escala, orientación y deformación local no relacionada con patología.

% =============================================================================
\section*{O}
% =============================================================================

\textbf{OpenCV} (\textit{Open Source Computer Vision Library})
\\
Biblioteca de código abierto especializada en visión por computadora y procesamiento de imágenes, que proporciona implementaciones eficientes de algoritmos para transformaciones geométricas, mejora de contraste, detección de características y manipulación de imágenes. Utilizada en el preprocesamiento y deformación de radiografías.

\textbf{Optical Flow} (Flujo óptico)
\\
Técnica de visión por computadora que estima el campo vectorial de movimiento de píxeles entre frames consecutivos o entre imágenes relacionadas, utilizada para transformaciones no paramétricas de deformación en registro de imágenes médicas. Proporciona flexibilidad extrema pero puede requerir regularización para evitar deformaciones no realistas.

\textbf{Optimizador Adam}
\\
Algoritmo de optimización que adapta la tasa de aprendizaje para cada parámetro combinando momento y estimación de segundo momento de los gradientes. Utilizado en este trabajo con parámetros por defecto ($\beta_1=0.9$, $\beta_2=0.999$).

% =============================================================================
\section*{P}
% =============================================================================

\textbf{Pares simétricos}
\\
Puntos de referencia bilateralmente simétricos que corresponden a posiciones equivalentes en pulmones izquierdo y derecho: (L3, L4), (L5, L6), (L7, L8), (L12, L13), (L14, L15). Utilizados durante Test-Time Augmentation para corregir predicciones después de reflejo horizontal.

\textbf{Parada temprana} (\textit{Early Stopping})
\\
Mecanismo de regularización que detiene el entrenamiento cuando el rendimiento en el conjunto de validación deja de mejorar durante un número de épocas consecutivas (paciencia), evitando sobreajuste y conservando el modelo con mejor rendimiento.

\textbf{Padding} (Relleno)
\\
Técnica que agrega píxeles adicionales (típicamente con valor cero) en los bordes de la imagen o mapa de características antes de aplicar convolución, permitiendo preservar las dimensiones espaciales originales y evitar pérdida de información en los bordes.

\textbf{Patches} (Parches)
\\
Divisiones rectangulares no solapadas de la imagen (típicamente 16×16 píxeles en Vision Transformers) que se procesan como tokens individuales. Cada parche se aplana y proyecta a un embedding de dimensión fija antes de procesamiento mediante self-attention, permitiendo que ViT trate imágenes como secuencias similares a NLP.

\textbf{Píxel}
\\
Unidad básica de una imagen digital, representando un punto con valores de intensidad (escala de grises) o color (RGB). El término proviene de "picture element" (elemento de imagen).

\textbf{PNG} (\textit{Portable Network Graphics})
\\
Formato de archivo de imagen sin pérdida que soporta compresión, transparencia y profundidad de color de hasta 48 bits. Ampliamente utilizado para almacenar radiografías digitales y visualizaciones de resultados por su calidad sin degradación y compatibilidad universal.

\textbf{Planificador} (\textit{Learning Rate Scheduler})
\\
Mecanismo que ajusta dinámicamente la tasa de aprendizaje durante el entrenamiento según una estrategia predefinida (Cosine Annealing, Step Decay, etc.), optimizando la convergencia y mejorando el rendimiento final del modelo.

\textbf{Pooling} (Agrupamiento)
\\
Operación de reducción espacial que disminuye la dimensionalidad de mapas de características preservando información relevante. Tipos: Max Pooling (selecciona máximo), Average Pooling (calcula promedio).

\textbf{Precisión} (\textit{Precision})
\\
Métrica que mide, de todas las predicciones positivas para una clase, qué proporción son correctas: $\text{Precisión} = \frac{VP}{VP + FP}$. Relevante cuando el costo de falsos positivos es alto.

\textbf{Preprocesamiento}
\\
Conjunto de transformaciones aplicadas a las imágenes antes del procesamiento principal (mejora de contraste, redimensionamiento, normalización) para estandarizar la entrada y mejorar la efectividad del modelo.

\textbf{Puntos de referencia} $\rightarrow$ Ver \textit{Landmarks}

\textbf{PyTorch}
\\
Framework de código abierto para aprendizaje profundo desarrollado por Meta AI, que proporciona estructuras de datos tensoriales con aceleración por GPU, diferenciación automática y herramientas para construcción, entrenamiento y evaluación de redes neuronales. Utilizado como base de implementación en este trabajo.

% =============================================================================
\section*{R}
% =============================================================================

\textbf{Radiografía de tórax}
\\
Imagen médica obtenida mediante exposición a rayos X que visualiza estructuras torácicas (pulmones, corazón, huesos), utilizada para diagnóstico de patologías pulmonares.

\textbf{Radiografía posteroanterior (PA)}
\\
Proyección radiográfica donde el haz de rayos X atraviesa el cuerpo del paciente de posterior a anterior, con el detector colocado frente al pecho. Estándar para radiografías de tórax de pie.

\textbf{Región pulmonar}
\\
Área de la radiografía que contiene el tejido pulmonar, delimitada por el contorno pulmonar definido mediante los 15 landmarks en este trabajo.

\textbf{RegNetX032}
\\
Arquitectura CNN de la familia RegNet regularizada mediante búsqueda neural de arquitecturas (NAS), diseñada para optimizar el compromiso entre eficiencia computacional y precisión en tareas de clasificación. Reportada con 98.6\% de exactitud en detección de COVID-19 en literatura reciente.

\textbf{Reflejo horizontal} (\textit{Horizontal Flip})
\\
Transformación de imagen que invierte la imagen a lo largo del eje vertical, utilizada como técnica de aumento de datos y en Test-Time Augmentation. Requiere intercambio de pares simétricos de landmarks para mantener consistencia anatómica.

\textbf{Regularización}
\\
Conjunto de técnicas para prevenir sobreajuste y mejorar generalización, incluyendo dropout, aumento de datos, parada temprana y penalizaciones sobre parámetros.

\textbf{ReLU} (\textit{Rectified Linear Unit})
\\
Función de activación no lineal definida como $f(x) = \max(0, x)$, que elimina valores negativos. Utilizada ampliamente en redes convolucionales por su eficiencia computacional y mitigación de desvanecimiento de gradiente.

\textbf{ResNet} (\textit{Residual Network})
\\
Familia de arquitecturas de redes neuronales profundas que utilizan conexiones residuales para facilitar el entrenamiento. Propuesta por He et al. (2016).

\textbf{ResNet-18}
\\
Variante de ResNet con 18 capas (11.2 millones de parámetros), utilizada en este trabajo como extractor de características para landmarks y como clasificador de enfermedades pulmonares debido a su balance entre capacidad y eficiencia.

\textbf{RGB} (\textit{Red, Green, Blue})
\\
Modelo de representación de color que codifica cada píxel mediante tres canales (Rojo, Verde, Azul). Las radiografías de tórax son imágenes en escala de grises (un canal) que se replican a 3 canales para compatibilidad con redes preentrenadas en ImageNet.

\textbf{Rotación óptima}
\\
Transformación de rotación que minimiza la distancia entre dos configuraciones de puntos, calculada mediante descomposición en valores singulares (SVD). Utilizada en GPA para el paso de alineación rotacional.

\textbf{RT-PCR} (\textit{Reverse Transcription Polymerase Chain Reaction})
\\
Reacción en Cadena de la Polimerasa con Transcripción Inversa. Prueba molecular de laboratorio considerada el estándar de oro para diagnóstico de COVID-19, que detecta material genético viral (ARN) mediante amplificación. Las radiografías de tórax complementan este diagnóstico proporcionando evaluación de severidad pulmonar.

% =============================================================================
\section*{S}
% =============================================================================

\textbf{SAHS} (\textit{Statistical Asymmetrical Histogram Stretching})
\\
Método de mejora de contraste diseñado para histogramas asimétricos que calcula límites de estiramiento diferenciados según la distribución de intensidades por encima y por debajo de la media: $I_{max} = \mu + 2.5\sigma_+$, $I_{min} = \mu - 2.0\sigma_-$.

\textbf{Saliency Maps} (Mapas de relevancia)
\\
Mapas que visualizan la importancia de píxeles individuales calculando gradientes de la función de pérdida o de la clase predicha respecto a la imagen de entrada, mostrando qué regiones son más influyentes en predicciones. Técnica fundamental de interpretabilidad para diagnóstico médico asistido por IA.

\textbf{Self-attention} (Auto-atención)
\\
Mecanismo en arquitecturas transformer que permite que cada elemento de una secuencia (token, parche de imagen) atienda a todos los demás elementos, capturando dependencias de largo alcance sin restricción de campo receptivo local como en CNNs. Calcula ponderaciones de atención mediante productos escalares entre queries, keys y values derivadas de la entrada.

\textbf{Semilla aleatoria} (\textit{Random Seed})
\\
Valor inicial que controla la generación de números pseudoaleatorios, permitiendo reproducibilidad de experimentos. Este trabajo utiliza semilla fija (42) para particiones de datos y diferentes semillas (123, 321, 111, 666) para modelos del ensamble.

\textbf{Sensibilidad} (\textit{Recall / Sensitivity})
\\
Métrica que mide, de todos los casos reales de una clase, qué proporción detecta el sistema: $\text{Sensibilidad} = \frac{VP}{VP + FN}$. Crítica cuando el costo de falsos negativos es alto.

\textbf{Sigmoid} (Sigmoide)
\\
Función de activación que mapea cualquier valor real al rango (0, 1): $\sigma(x) = \frac{1}{1 + e^{-x}}$. Utilizada en la salida de la cabeza de regresión para normalizar coordenadas al rango [0, 1].

\textbf{Silueta pulmonar} $\rightarrow$ Ver \textit{Contorno pulmonar}

\textbf{Skip connections} $\rightarrow$ Ver \textit{Conexiones residuales}

\textbf{Sobreajuste} (\textit{Overfitting})
\\
Fenómeno donde un modelo aprende demasiado bien los ejemplos de entrenamiento, incluyendo ruido y particularidades, perdiendo capacidad de generalizar a datos nuevos. Mitigado mediante regularización, dropout y parada temprana.

\textbf{Softmax}
\\
Función que transforma valores numéricos en probabilidades que suman 1, utilizada en la capa de salida del clasificador para convertir logits en distribución de probabilidad sobre las tres clases.

\textbf{Spatial Transformer Networks (STN)} (Redes de Transformación Espacial)
\\
Módulo diferenciable que permite a redes neuronales aprender transformaciones espaciales globales (affine, perspective, thin-plate spline) de forma de extremo a extremo sin supervisión adicional, mejorando robustez a variaciones de pose. Limitación: transformaciones son globales, sin capacidad de deformación local adaptativa requerida para estructuras anatómicas deformables.

\textbf{Squeeze-and-Excitation (SE)} (Compresión y Excitación)
\\
Mecanismo de atención a nivel de canal que recalibra feature maps mediante global average pooling (squeeze) seguido de transformación no lineal con dos capas fully-connected (excitation), generando ponderaciones adaptativas por canal. Amplifica canales informativos y suprime irrelevantes con sobrecarga computacional mínima. SE-Net ganó ILSVRC 2017.

\textbf{Stride} (Paso)
\\
Parámetro que define el desplazamiento del kernel durante la operación de convolución o pooling. Un stride de 1 aplica la operación en cada posición, mientras que stride de 2 reduce las dimensiones espaciales a la mitad, funcionando como mecanismo de reducción de resolución.

\textbf{Subajuste} (\textit{Underfitting})
\\
Fenómeno donde un modelo es demasiado simple o no se entrena suficientemente, resultando en incapacidad para capturar patrones relevantes tanto en datos de entrenamiento como de prueba. Indica necesidad de mayor capacidad del modelo o más épocas de entrenamiento.

\textbf{SVD} (\textit{Singular Value Decomposition} / Descomposición en Valores Singulares)
\\
Técnica de álgebra lineal que descompone una matriz en tres matrices ($A = U\Sigma V^T$), utilizada en GPA para calcular la rotación óptima entre configuraciones de puntos mediante el método de Schönemann.

% =============================================================================
\section*{T}
% =============================================================================

\textbf{Tamaño de lote} (\textit{Batch Size})
\\
Número de imágenes procesadas simultáneamente durante el entrenamiento. Este trabajo utiliza lotes de 16 (fase 1 landmarks), 8 (fase 2 landmarks) y 32 (clasificador).

\textbf{Tasa de aprendizaje} (\textit{Learning Rate})
\\
Hiperparámetro que controla la magnitud de los ajustes de parámetros durante el descenso de gradiente. Este trabajo utiliza tasas diferenciadas: $10^{-3}$ (fase 1 landmarks), $2 \times 10^{-5}$ (backbone fase 2), $2 \times 10^{-4}$ (cabeza fase 2), $10^{-4}$ (clasificador).

\textbf{Test-Time Augmentation (TTA)}
\\
Técnica que procesa cada imagen de prueba con múltiples transformaciones (original y reflejada) y promedia las predicciones para reducir varianza. Requiere intercambio de pares simétricos de landmarks al procesar imágenes reflejadas.

\textbf{Tiles}
\\
Regiones rectangulares en las que se divide una imagen durante CLAHE para aplicar ecualización local. Tamaño típico: 4×4 u 8×8 bloques.

\textbf{Top-5 Error} (Error Top-5)
\\
Métrica de evaluación en clasificación multiclase que mide el porcentaje de predicciones donde la clase correcta NO está entre las 5 predicciones con mayor probabilidad. Utilizada en competencias de ImageNet para evaluar rendimiento en tareas con muchas clases (1,000 categorías). Valores bajos (e.g., <3\%) indican excelente discriminación.

\textbf{Transformación afín}
\\
Transformación geométrica que preserva líneas rectas y paralelismo, pudiendo incluir traslación, rotación, escalado y sesgo. Queda completamente determinada por la correspondencia entre tres puntos no colineales, propiedad utilizada en warping triangular.

\textbf{Transfer Learning} $\rightarrow$ Ver \textit{Aprendizaje por transferencia}

\textbf{Triangulación de Delaunay}
\\
Método geométrico que conecta un conjunto de puntos mediante triángulos que no se superponen, maximizando el ángulo mínimo de todos los triángulos para evitar triángulos degenerados. Genera 16 triángulos a partir de los 15 landmarks en este trabajo.

% =============================================================================
\section*{U}
% =============================================================================

\textbf{U-Net}
\\
Arquitectura de red neuronal con estructura codificador-decodificador simétrica y conexiones saltadas densas (skip connections) entre niveles correspondientes, diseñada originalmente para segmentación médica con capacidad de aprender con pocos datos etiquetados. La estructura en "U" permite combinar información de contexto global (encoder) con localización espacial precisa (decoder).

% =============================================================================
\section*{V}
% =============================================================================

\textbf{Validación cruzada} (\textit{Cross-Validation})
\\
Técnica de evaluación que divide el conjunto de datos en $k$ pliegues, entrenando $k$ veces usando $k-1$ pliegues para entrenamiento y 1 para validación, rotando los pliegues. Este trabajo utiliza $k=5$ para evaluar estabilidad del clasificador.

\textbf{Verdaderos Negativos (VN)}
\\
Casos de clases negativas correctamente clasificados como negativos.

\textbf{Verdaderos Positivos (VP)}
\\
Casos de una clase positiva correctamente clasificados como positivos. En detección de COVID-19, pacientes positivos correctamente identificados.

\textbf{VGGNet}
\\
Arquitectura CNN que demostró la importancia de profundidad en redes neuronales, utilizando bloques de convoluciones 3×3 repetidas para incrementar capacidad de representación mientras se mantiene un diseño simple y homogéneo. VGG-16 y VGG-19 fueron ampliamente adoptadas como extractores de características preentrenados antes de ResNet.

\textbf{Vision Transformers (ViT)} (Transformadores de Visión)
\\
Arquitectura que aplica mecanismos transformer (originalmente diseñados para NLP) a reconocimiento de imágenes dividiendo la imagen en parches no solapados, proyectándolos a embeddings y procesándolos mediante multi-head self-attention. Captura dependencias de largo alcance globalmente pero requiere conjuntos de datos masivos (JFT-300M) para competir con CNNs debido a ausencia de inductive biases.

\textbf{VOC 2007} (\textit{Visual Object Classes 2007})
\\
Conjunto de datos del desafío PASCAL VOC 2007 para detección y segmentación de objetos con 20 categorías, utilizado como benchmark histórico de visión por computadora. Incluye anotaciones de bounding boxes, segmentación semántica y clasificación de acciones.

% =============================================================================
\section*{W}
% =============================================================================

\textbf{Warping} $\rightarrow$ Ver \textit{Deformación afín por partes}

\textbf{Wing Loss}
\\
Función de pérdida diseñada para regresión de landmarks que combina comportamiento logarítmico para errores pequeños (incentivando refinamiento fino) con comportamiento lineal para errores grandes (estabilidad):
\begin{equation*}
\text{Wing}(x) =
\begin{cases}
\omega \ln\left(1 + \frac{|x|}{\epsilon}\right) & \text{si } |x| < \omega \\
|x| - C & \text{si } |x| \geq \omega
\end{cases}
\end{equation*}
donde $\omega = 10$ píxeles, $\epsilon = 2$ píxeles, $C = \omega - \omega \ln(1 + \omega/\epsilon)$.

% =============================================================================
% SECCIÓN DE ACRÓNIMOS Y ABREVIATURAS
% =============================================================================

\newpage
\section*{Acrónimos y Abreviaturas}

\begin{longtable}{ll}
\toprule
\textbf{Acrónimo} & \textbf{Significado} \\
\midrule
\endfirsthead
\toprule
\textbf{Acrónimo} & \textbf{Significado} \\
\midrule
\endhead
\bottomrule
\endfoot

AdamW & \textit{Adam with Weight Decay} \\
      & Optimizador Adam con Decaimiento de Pesos \\
\addlinespace

ASM & \textit{Active Shape Models} \\
    & Modelos de Forma Activa \\
\addlinespace

AUC & \textit{Area Under the Curve} \\
    & Área Bajo la Curva \\
\addlinespace

BIMCV & Biosignal Interpretation and Medical Computing Valencia \\
\addlinespace

CBAM & \textit{Convolutional Block Attention Module} \\
     & Módulo de Atención de Bloque Convolucional \\
\addlinespace

CLAHE & \textit{Contrast Limited Adaptive Histogram Equalization} \\
      & Ecualización Adaptativa de Histograma con Límite de Contraste \\
\addlinespace

CNN & \textit{Convolutional Neural Network} \\
    & Red Neuronal Convolucional \\
\addlinespace

COVID-19 & \textit{Coronavirus Disease 2019} \\
         & Enfermedad por Coronavirus 2019 \\
\addlinespace

CSV & \textit{Comma-Separated Values} \\
    & Valores Separados por Comas \\
\addlinespace

FC & \textit{Fully Connected} \\
   & Completamente Conectado \\
\addlinespace

FN & Falsos Negativos (\textit{False Negatives}) \\
\addlinespace

FP & Falsos Positivos (\textit{False Positives}) \\
\addlinespace

GPA & \textit{Generalized Procrustes Analysis} \\
    & Análisis Procrustes Generalizado \\
\addlinespace

GPU & \textit{Graphics Processing Unit} \\
    & Unidad de Procesamiento Gráfico \\
\addlinespace

L1 & \textit{L1 Loss} / Error Absoluto Medio \\
\addlinespace

L2 & \textit{L2 Loss} / Error Cuadrático Medio \\
\addlinespace

MS COCO & \textit{Microsoft Common Objects in Context} \\
\addlinespace

NME & \textit{Normalized Mean Error} \\
    & Error Medio Normalizado \\
\addlinespace

PA & Posteroanterior \\
\addlinespace

PNG & \textit{Portable Network Graphics} \\
    & Formato de imagen sin pérdida \\
\addlinespace

OpenCV & \textit{Open Source Computer Vision Library} \\
        & Biblioteca de Visión por Computadora de Código Abierto \\
\addlinespace

ReLU & \textit{Rectified Linear Unit} \\
     & Unidad Lineal Rectificada \\
\addlinespace

RGB & \textit{Red, Green, Blue} \\
    & Modelo de color Rojo, Verde, Azul \\
\addlinespace

RT-PCR & \textit{Reverse Transcription Polymerase Chain Reaction} \\
       & Reacción en Cadena de la Polimerasa con Transcripción Inversa \\
\addlinespace

PyTorch & Framework de aprendizaje profundo de código abierto \\
\addlinespace

SAHS & \textit{Statistical Asymmetrical Histogram Stretching} \\
     & Estiramiento Asimétrico Estadístico de Histograma \\
\addlinespace

SE-Net & \textit{Squeeze-and-Excitation Network} \\
       & Red de Compresión y Excitación \\
\addlinespace

STN & \textit{Spatial Transformer Network} \\
    & Red de Transformación Espacial \\
\addlinespace

SVD & \textit{Singular Value Decomposition} \\
    & Descomposición en Valores Singulares \\
\addlinespace

TTA & \textit{Test-Time Augmentation} \\
    & Aumento en Tiempo de Prueba \\
\addlinespace

VN & Verdaderos Negativos (\textit{True Negatives}) \\
\addlinespace

VP & Verdaderos Positivos (\textit{True Positives}) \\
\addlinespace

ViT & \textit{Vision Transformer} \\
    & Transformador de Visión \\
\addlinespace

VOC & \textit{Visual Object Classes} \\
\addlinespace

XAI & \textit{Explainable AI} \\
    & Inteligencia Artificial Explicable \\

\end{longtable}
