(00:00) Alumno: Ok. Está grabando. Este... Ah bueno, me entró duda con lo que usted dijo de... de las dos clases. Porque, bueno, ahí voy como a la parte de que... ¿cómo vamos a manejar la neumonía? O sea, ¿como neumonía y COVID? ¿O que COVID es parte de la neumonía? ¿Por qué le pregunto esto? Porque al estar pues trabajando con las imágenes y que estuve trabajando con el CLAHE y con el SAS para implementar este... o sea, cambiarles el contraste...

Asesor: Ajá.

Alumno: Me di cuenta de que las de COVID generalmente, ya ve que cuando uno tiene COVID muestra como un... ¿cómo le dicen? Como cristalino, como muy blanco. Se te vuelve muy blanco el... los pulmones. Tanto también por la hum... que se te llena de agua los pulmones y por la inflamación. O sea, sí hay una va...

Asesor: (Interrumpiendo) Pues, eh, depende cómo vengan en el... en el dataset. O sea, ¿en el dataset cómo vienen clasificados?

Alumno: O sea, vienen neumonía y aparte COVID.

Asesor: ¿Y normales aparte?

Alumno: Y sanos, ajá.

(00:46) Asesor: O sea, como quien dice, en el dataset vienen tres clases.

Alumno: De tres clases.

Asesor: Significa que teóricamente, aunque tú sabes que la neumonía es causada por COVID, pero si vienen ya tres clases así... en teoría podríamos, como quien dice, este... establecer tres clases. Pero también podemos simplificarlo, como yo te decía hace más tiempo, pensando que solo hay dos clases. O tienes este... neumonía o tienes... o estás sano. ¿Por qué? Porque finalmente lo que cau... el efecto que produce el COVID, o sea, por lo que se puede... por lo que se nota que en una radiografía hay COVID, es porque causó neumonía.

Alumno: Mjum.

Asesor: Lo que pasa es que efectivamente no es igualita que otros tipos de neumonía, pero es... pero finalmente es neumonía. Entonces por eso podrías decir: "solo va a haber dos clases". Si quisieras simplificarlo. O sea, con neumonía (ya sea causada por otras razones o por COVID), pero neumonía a fin de cuentas, y las que están sanas. Entonces, como quien dice, tienes los dos grupos.

Alumno: Mjum.

(01:50) Asesor: A esos dos grupos, construyes un solo Eigen-space.

Alumno: Ok.

Asesor: Pero, claro, pero estoy hablando de las imágenes que ya pasaron por la alineación, o sea que... que ya fueron warped, o sea que se deformaron, que por cierto a mí me gustaría ver esas imágenes, ¿verdad?

Alumno: Sí, se las puedo mandar.

Asesor: ¿Ah, o sea ahorita no las podemos ver?

Alumno: Es que están en mi compu.

Asesor: ¿En la otra? ¿O cuál?

Alumno: Sí. Es que están en la... en el Linux. En el local.

(02:15) Asesor: Entonces... tendrías que tener, con esas nuevas imágenes ya... ya ajustadas, ya warped, ya etcétera, que ya están todas bonitas... este... haces, construyes un solo Eigen-space. Voy a poner un ejemplo, ¿no? Quiero decir que tenga que tener este número de Eigenfaces que te voy a decir. Pero suponte que fueron... que dijiste: "Pues 10 Eigenfaces son las principales".

Alumno: Mjum.

Asesor: Son las que más variación tienen, este... implican en el conjunto de entrenamiento, entonces voy a usar solo 10. Que serían las 10 que corresponden a las 10 mayores varianzas, eso ya lo habíamos visto. Entonces vas a usar solo 10. ¿Sí? Quiere decir que con... que con esas 10 Eigenfaces... las Eigenfaces son finalmente son imágenes...

Alumno: Mjum.

Asesor: Pero con una combinación lineal de ellas... una combinación lineal quiere decir que usas un ponderante y multiplicas ese ponderante por esta imagen. Más otro ponderante por esta otra. Más otro ponderante por esta otra. 10 ponderantes.

Alumno: Mjum.

Asesor: Quiere decir que con una combinación lineal de ellas puedes recon... puedes hacer alguna, cualquiera.

Alumno: Casi al 100%, bueno, ¿no?

(03:10) Asesor: Bueno, no al 100%... No, sí, las del conjunto de entrenamiento al 100%. Y una externa, pues muy cerca.

Alumno: Mjum.

Asesor: ¿Sí? Pero las características no serían las Eigenfaces. Las características serían los ponderantes.

Alumno: Mjum. Los pesos que se le da a ese... a ese valor. ¿No?

Asesor: Sí. Los pesos. Esos serían las características. Como quien dice, podrías decir: "Bueno, a ver, voy a sacar mis características (o sea mis ponderantes) para cada uno de los ejemplos de entrenamiento". Y entonces tendrías 10 pesos, 10 ponderantes, por cada ejemplo de entrenamiento. Vamos a hablar del ponderante 1. Esa sería la característica número 1.

(03:45) Asesor: Entonces, si tienes en el conjunto de entrenamiento tienes 1,000 imágenes... significa que en la característica 1, pues tendrías 1,000 valores para la característica 1. 1,000 valores para la característica 1.

Alumno: Mjum.

Asesor: ¿Sí? Pero tienes también una ventaja. Que tienes 1,000 valores para la característica 1... entonces con esos 1,000 valores, podríamos realizar la estandarización. Vamos a estandarizar solo la característica 1. ¿Sí? Entonces, de esos 1,000 valores sacas la media. Y la guardas aquí la media. Y le sacas la desviación estándar y también la guardas. Entonces, a cada valor le restas la media y luego esa diferencia la divides entre la desviación estándar.

Alumno: A cada valor... ¿a cada uno de los 1,000 valores?

Asesor: A cada uno de los 1,000 valores.

Alumno: Ok.

(04:30) Asesor: Y eso lo haces con todos. Y con eso obtienes, como quien dice, obtienes valores para esta misma característica (1,000 también), pero ya estandarizados. Ya están estandarizados. O sea, estandarizaste la característica número 1. Bueno, lo mismo va a ser con las demás características, pero ahorita solo vamos a hablar de la característica número 1. Porque no te voy a repetir para las otras características porque es lo mismo.

Alumno: Entonces se podría decir que cada uno de los 1,000 valores se estandarizó. ¿No?

Asesor: Cada uno de los 1,000 valores se estandarizó.

Alumno: Ok.

Asesor: En... en resumen, estandarizaste la característica número 1. Eso fue lo que hiciste, la estandarizaste. Bueno, ya que la estandarizaste... ya que estandarizaste la característica número 1, entonces vas a... aplicas el Criterio de Fisher. ¿Cómo? De esos 1,000 valores, tienes 500 que son para la neumonía y tienes otros 500 que son para los sanos.

Alumno: Mjum.

(05:15) Asesor: Entonces tomas los que nada más son para la neumonía, ¿sí? Y sacas una media número 1 y le pones "Media 1" y la guardas. Para los que son sanos, haces lo mismo y sacas la "Media número 2". Haces lo mismo para la desviación estándar número 1 y la desviación estándar número 2. De estos datos y luego de estos. Entonces ya tienes cuatro datos: Media 1, Media 2, Sigma 1, Sigma 2. Y con esos sacas el Criterio de Fisher.

Asesor: Y entonces... si el criterio, ese... esa Razón de Fisher es grande, significa... eso velo en la tesis...

Alumno: ¿Pertenece a una o a otra? ¿No? No, perdón, nada más dije sin... sin saber nada dije eso.

Asesor: No, pues no... no es eso. O sea, si esa Razón de Fisher es grande, significa que esa característica número 1 separa bien las clases. Si esa... si esa Razón de Fisher es cero o chiquita, significa que esa característica no separa bien las clases.

Alumno: Mmm, ok.

(05:55) Asesor: Con esa Razón de Fisher, puedes usarla como un ponderante. La puedes usar como un ponderante para multiplicar a la característica número 1 en general. O sea, como quien dice, todos los datos de la característica número 1 los podrías multiplicar por esa cosa. Es como si le estuvieras dando una amplitud a esa característica. ¿Sí?

Alumno: Pero eso significaría que esa característica se... ¿es la que separa mejor? ¿La 1? ¿No?

Asesor: No, bueno, eso quiere decir que esa característica separa... ¿Qué tan bien separa? Bueno, por eso le pegaste un ponderante. Le pegas... le pegas un ponderante y con eso... Si separa muy bien, pues el ponderante que le estás poniendo es muy alto, entonces la estás amplificando. Porque todos los datos de esa característica... ya que la estandarizaste, ahora los vas a multiplicar por esa cosa. A cada uno, a cada uno, a cada uno... ¿Sí me entiendes?

Asesor: Estás multiplicando todo... todos los datos de la característica. ¿Sí? O sea, la estás amplificando. Si separaba muy bien, como quien dice la ganancia o la amplificación pues va a ser grande. Si separa mal, la amplificación va a ser chiquita. Eso fue lo que hizo él. Entonces lo hizo con una, con otra, con otra, con otra... Lo hizo con todas las características.

Alumno: Mjum.

(06:50) Asesor: Entonces ahora ya tenía características ya no solo estandarizadas, sino amplificadas de acuerdo a su importancia. Y ahora sí ya las metes al clasificador.

Alumno: ¿Sí, ya me entendiste cómo?

Alumno: Sí, sí le entendí. ¿Y este clasificador cuál usamos?

Asesor: No, pues puede ser el... hasta uno bien simple. Puede ser un KNN. Él usó un KNN. Tú podrías usar un KNN, un Multilayer Perceptron simple. Pero el Multilayer Perceptron aunque es... aunque es Deep...

Alumno: Creo que él sí usó un Multilayer Perceptron.

Asesor: No importa cuál uses. No va a ser mucha la diferencia en la clasificación. Va a ser casi igual. Lo que hace la diferencia es que hayas alineado esas canijas imágenes. Ahora, el problema es que cuando se las das directamente a la red neuronal convolucional (CNN), la red neuronal convolucional en realidad ya está preparada para que las imágenes no estén alineadas.

Alumno: Sí, pues lo hace todo la red.

Asesor: Internamente lo hace. Por eso te digo que no es... no es tan fiable para demostrar que realmente importa mucho la alineación. Aunque se supone que sí importa, porque por la segmentación que dices, porque ya no van a estar los artefactos. Pero también... también sirve porque estas nuevas imágenes son mejores para... este... van a funcionar mejor incluso con un clasificador tan chafa o tan simple como un KNN. Eso es lo que tienes que demostrar.

Alumno: Sí.

Asesor: Ok.

Alumno: Sí, doctor. Me quedó claro.

Asesor: Bueno, pues... entonces...

Alumno: ¿Quiere le mando las imágenes warpedas al ratito?

Asesor: Sí, si quieres ya detén la...

(Fin de la grabación)